{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff920ebe5d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Author: Yulou Zhou\n",
    "#Weight loss function by commonality (and normalize)\n",
    "#padded sequence\n",
    "#for loop to test parameters\n",
    "#for loop to get prev generated chord\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import csv\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from random import shuffle\n",
    "from MyDataset import MyDataset\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import dataloader\n",
    "def collate_fn(batch):\n",
    "    batch.sort(key=lambda x: x['mask'], reverse=True)\n",
    "    #for i in batch:\n",
    "        #print(i['mask'])\n",
    "    return dataloader.default_collate(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_data = MyDataset('relativedata', prevchord = 4)\n",
    "weights = train_data.stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p:  tensor([[  0,   0,   0,  ...,   3,   4,   7],\n",
      "        [ 10,   4,   7,  ...,   8,   4,   7],\n",
      "        [  6,   4,   7,  ...,   6,   4,   7],\n",
      "        ...,\n",
      "        [  6,   3,   6,  ...,   7,   4,   7],\n",
      "        [  0,   0,   0,  ...,   0,   0,   0],\n",
      "        [  0,   0,   0,  ...,   0,   0,   0]])\n",
      "m:  tensor([[  0,   0,   0,  ...,   0,   0,   0],\n",
      "        [  8,   3,   3,  ...,   0,   0,   0],\n",
      "        [ 10,  10,  10,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 11,  11,   1,  ...,   0,   0,   0],\n",
      "        [  0,  10,  11,  ...,   0,   0,   0],\n",
      "        [  1,   3,   6,  ...,   0,   0,   0]])\n",
      "marr:  tensor([[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]], dtype=torch.float64)\n",
      "l:  tensor([[  3,   4,   7],\n",
      "        [ 12,   3,   7],\n",
      "        [  8,   4,   7],\n",
      "        [  1,   3,   7],\n",
      "        [  6,   4,   7],\n",
      "        [ 10,   4,   7],\n",
      "        [  5,   4,   7],\n",
      "        [  8,   4,   7],\n",
      "        [ 12,   2,   7],\n",
      "        [  6,   4,   7],\n",
      "        [ 11,   4,   7],\n",
      "        [  1,   4,   7],\n",
      "        [  1,   4,   7],\n",
      "        [  6,   3,   7],\n",
      "        [  8,   4,   7],\n",
      "        [  1,   3,   9],\n",
      "        [  8,   4,   7],\n",
      "        [ 10,   4,   7],\n",
      "        [  5,   4,   7],\n",
      "        [  6,   4,   7],\n",
      "        [  3,   3,   7],\n",
      "        [  1,   4,   7],\n",
      "        [ 10,   3,   7],\n",
      "        [  3,   3,   7],\n",
      "        [ 10,   4,   7],\n",
      "        [ 10,   4,   7],\n",
      "        [  5,   3,   6],\n",
      "        [  8,   4,   8],\n",
      "        [  3,   3,   7],\n",
      "        [  1,   3,   7],\n",
      "        [  8,   4,   7],\n",
      "        [  1,   4,   7],\n",
      "        [ 10,   4,   7],\n",
      "        [  8,   3,   7],\n",
      "        [  8,   3,   7],\n",
      "        [  8,   3,   7],\n",
      "        [ 11,   4,   7],\n",
      "        [  6,   4,   8],\n",
      "        [  5,   4,   7],\n",
      "        [  6,   3,   7],\n",
      "        [ 10,   4,   7],\n",
      "        [  1,   5,   7],\n",
      "        [ 10,   4,   7],\n",
      "        [  1,   3,   7],\n",
      "        [  3,   3,   7],\n",
      "        [ 10,   4,   7],\n",
      "        [ 11,   4,   7],\n",
      "        [  5,   3,   7],\n",
      "        [  6,   4,   7],\n",
      "        [  4,   4,   7],\n",
      "        [ 11,   4,   7],\n",
      "        [  8,   4,   9],\n",
      "        [  8,   4,   7],\n",
      "        [  1,   4,   7],\n",
      "        [ 10,   4,   7],\n",
      "        [  2,   4,   7],\n",
      "        [ 10,   4,   7],\n",
      "        [  4,   4,   7],\n",
      "        [  1,   4,   7],\n",
      "        [  8,   3,   7],\n",
      "        [  1,   4,   9],\n",
      "        [  6,   4,   7],\n",
      "        [  1,   4,   7],\n",
      "        [  5,   3,   7],\n",
      "        [ 10,   4,   7],\n",
      "        [  2,   4,   7],\n",
      "        [  6,   4,   7],\n",
      "        [  8,   3,   7],\n",
      "        [  8,   4,   7],\n",
      "        [  6,   4,   7],\n",
      "        [  4,   4,   7],\n",
      "        [ 12,   4,   7],\n",
      "        [ 11,   4,   7],\n",
      "        [  8,   4,   7],\n",
      "        [  8,   4,   7],\n",
      "        [  3,   3,   7],\n",
      "        [  1,   4,   7],\n",
      "        [ 11,   4,   7],\n",
      "        [  8,   3,   7],\n",
      "        [  3,   4,   7],\n",
      "        [  8,   4,   7],\n",
      "        [  5,   3,   7],\n",
      "        [  3,   3,   7],\n",
      "        [  1,   4,   7],\n",
      "        [ 12,   3,   7],\n",
      "        [ 11,   4,   7],\n",
      "        [  1,   4,   7],\n",
      "        [  6,   4,   7],\n",
      "        [  8,   4,   7],\n",
      "        [ 10,   4,   7],\n",
      "        [  1,   4,   7],\n",
      "        [ 11,   4,   7],\n",
      "        [  7,   4,   7],\n",
      "        [  8,   4,   7],\n",
      "        [  6,   4,   7],\n",
      "        [ 10,   4,   7],\n",
      "        [  8,   3,   7],\n",
      "        [  6,   4,   7],\n",
      "        [  1,   3,   7],\n",
      "        [  9,   4,   7],\n",
      "        [  3,   3,   7],\n",
      "        [  1,   4,   7],\n",
      "        [  6,   4,   7],\n",
      "        [  1,   4,   7],\n",
      "        [  6,   4,   7],\n",
      "        [ 10,   3,   7],\n",
      "        [  1,   4,   7],\n",
      "        [  6,   4,   7],\n",
      "        [  1,   4,   7],\n",
      "        [  3,   4,   7],\n",
      "        [  6,   4,   7],\n",
      "        [  8,   3,   6],\n",
      "        [  1,   4,   7],\n",
      "        [ 10,   4,   7],\n",
      "        [  8,   4,   7],\n",
      "        [  6,   4,   7],\n",
      "        [  1,   3,   7],\n",
      "        [  1,   4,   7],\n",
      "        [  8,   4,   7],\n",
      "        [ 11,   2,   7],\n",
      "        [  6,   4,   7],\n",
      "        [  9,   4,   7],\n",
      "        [  3,   4,   7],\n",
      "        [  8,   4,   7],\n",
      "        [  3,   4,   7],\n",
      "        [  3,   3,   7],\n",
      "        [ 11,   4,   7],\n",
      "        [ 11,   4,   7],\n",
      "        [ 11,   4,   7],\n",
      "        [  3,   4,   7],\n",
      "        [  0,   0,   0],\n",
      "        [  4,   4,   9],\n",
      "        [  8,   4,   7],\n",
      "        [  1,   4,   7],\n",
      "        [  3,   4,   7],\n",
      "        [ 10,   3,   7],\n",
      "        [  8,   4,   7],\n",
      "        [  6,   4,   7],\n",
      "        [  6,   4,   7],\n",
      "        [  8,   3,   7],\n",
      "        [  9,   4,   7],\n",
      "        [  5,   4,   7],\n",
      "        [  5,   4,   7],\n",
      "        [  8,   4,   7],\n",
      "        [ 10,   3,   9],\n",
      "        [  6,   4,   7],\n",
      "        [ 10,   3,   7],\n",
      "        [  1,   4,   7],\n",
      "        [  8,   3,   7],\n",
      "        [  2,   4,   7],\n",
      "        [  9,   4,   7],\n",
      "        [  1,   4,   7],\n",
      "        [  1,   4,   7],\n",
      "        [  8,   4,   7],\n",
      "        [  9,   4,   7],\n",
      "        [ 10,   3,   7],\n",
      "        [ 10,   4,   7],\n",
      "        [  6,   4,   7],\n",
      "        [ 10,   3,   6],\n",
      "        [  8,   4,   7],\n",
      "        [  5,   5,   7],\n",
      "        [ 11,   4,   7],\n",
      "        [  8,   4,   7],\n",
      "        [  3,   4,   7],\n",
      "        [ 10,   3,   7],\n",
      "        [  8,   4,   7],\n",
      "        [  6,   4,   7],\n",
      "        [  3,   3,   7],\n",
      "        [  8,   4,   7],\n",
      "        [ 11,   4,   7],\n",
      "        [  6,   4,   7],\n",
      "        [  3,   4,   7],\n",
      "        [  6,   4,   7],\n",
      "        [  1,   4,   7],\n",
      "        [  1,   3,   9],\n",
      "        [ 10,   4,   7],\n",
      "        [  1,   4,   7],\n",
      "        [  6,   4,   7],\n",
      "        [  3,   4,   7],\n",
      "        [  1,   4,   7],\n",
      "        [  1,   3,   7],\n",
      "        [  4,   4,   9],\n",
      "        [  5,   4,   7],\n",
      "        [  8,   4,   7],\n",
      "        [  6,   4,   7],\n",
      "        [  8,   3,   7],\n",
      "        [ 10,   3,   7],\n",
      "        [  4,   4,   7],\n",
      "        [  4,   4,   7],\n",
      "        [  4,   4,   7],\n",
      "        [ 10,   4,   7],\n",
      "        [  3,   4,   7],\n",
      "        [  5,   4,   7],\n",
      "        [  6,   4,   7],\n",
      "        [  1,   3,   7],\n",
      "        [ 11,   4,   7],\n",
      "        [  9,   4,   7],\n",
      "        [  6,   3,   9],\n",
      "        [  1,   4,   7],\n",
      "        [ 10,   4,   7],\n",
      "        [ 10,   4,   7],\n",
      "        [  5,   4,   7],\n",
      "        [  3,   4,   7],\n",
      "        [  1,   4,   7],\n",
      "        [  8,   4,   7],\n",
      "        [  3,   4,   7],\n",
      "        [  6,   4,   7],\n",
      "        [ 11,   4,   7],\n",
      "        [  1,   3,   7],\n",
      "        [  1,   4,   7],\n",
      "        [  1,   4,   7],\n",
      "        [  6,   2,   7],\n",
      "        [  8,   4,   7],\n",
      "        [ 12,   4,   7],\n",
      "        [  1,   3,   7],\n",
      "        [  9,   4,   7],\n",
      "        [  1,   4,   7],\n",
      "        [  8,   4,   7],\n",
      "        [  1,   4,   7],\n",
      "        [ 10,   3,   7],\n",
      "        [  5,   4,   7],\n",
      "        [  8,   4,   7],\n",
      "        [  7,   3,   7],\n",
      "        [  7,   3,   7],\n",
      "        [  6,   3,   7],\n",
      "        [  1,   4,   7],\n",
      "        [  5,   4,   7],\n",
      "        [ 10,   4,   7],\n",
      "        [  1,   4,   7],\n",
      "        [  9,   4,   7],\n",
      "        [  8,   4,   7],\n",
      "        [  3,   4,   7],\n",
      "        [  3,   4,   7],\n",
      "        [  6,   4,   7],\n",
      "        [ 11,   4,   7],\n",
      "        [  4,   4,   7],\n",
      "        [  6,   4,   8],\n",
      "        [  8,   4,   7],\n",
      "        [  1,   4,   7],\n",
      "        [  1,   4,   7],\n",
      "        [ 11,   4,   7],\n",
      "        [  5,   4,   7],\n",
      "        [  6,   4,   7],\n",
      "        [  1,   4,   7],\n",
      "        [ 11,   4,   7],\n",
      "        [  5,   4,   7],\n",
      "        [  3,   4,   7],\n",
      "        [  3,   4,   7],\n",
      "        [  1,   4,   7],\n",
      "        [ 10,   4,   7],\n",
      "        [ 10,   4,   7],\n",
      "        [  3,   3,   7],\n",
      "        [  6,   4,   7],\n",
      "        [  7,   4,   7],\n",
      "        [ 11,   3,   6],\n",
      "        [  8,   3,   6]])\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn = collate_fn)\n",
    "c=0\n",
    "for i in data_loader:\n",
    "    print(\"p: \", i['p'])\n",
    "    print(\"m: \", i['m'])\n",
    "    print(\"marr: \", i['marr'])\n",
    "    print(\"l: \", i['l'])\n",
    "    c += 10\n",
    "    if c > 0: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(array):\n",
    "    return [i / sum(array) for i in array]\n",
    "newweights = []\n",
    "\n",
    "def weightloss(weights, eps):\n",
    "    for w in weights:\n",
    "        newweights.append(torch.FloatTensor( normalize([1/(i + eps) for i in w] ) ) )\n",
    "    #print(newweights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, p_embed_dim, m_embed_dim, p_hidden_dim, m_hidden_dim, vocab_size, tagset_size, batch_size = 1):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.p_embed_dim, self.m_embed_dim = p_embed_dim, m_embed_dim\n",
    "        \n",
    "        self.p_embed = nn.Embedding(vocab_size, p_embed_dim)\n",
    "        self.m_embed = nn.Embedding(vocab_size, m_embed_dim)\n",
    "        self.p_embed.weight.data.copy_(torch.from_numpy(np.identity(vocab_size)))\n",
    "        self.m_embed.weight.data.copy_(torch.from_numpy(np.identity(vocab_size)))\n",
    "        \n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.p_lstm = nn.LSTM(p_embed_dim, p_hidden_dim, bidirectional = False)\n",
    "        self.m_lstm = nn.LSTM(m_embed_dim, m_hidden_dim, bidirectional = False)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = nn.Linear((p_hidden_dim + m_hidden_dim) , tagset_size)\n",
    "        self.root2second = nn.Linear((p_hidden_dim + m_hidden_dim) + 1, tagset_size)\n",
    "        self.root2third = nn.Linear((p_hidden_dim + m_hidden_dim) + 1, tagset_size)\n",
    "        \n",
    "        self.p_hidden = self.init_hidden(p_hidden_dim)\n",
    "        self.m_hidden = self.init_hidden(m_hidden_dim)\n",
    "\n",
    "    def init_one_hot(self, vocab_size):\n",
    "        #initialize each embedding\n",
    "        #stack them together (or other ways to have  pretrained embeddings)\n",
    "        #pretrained_weight is a numpy matrix of shape (num_embeddings, embedding_dim)\n",
    "        #we should turn data into torch.from_numpy(pretrained_weight)\n",
    "        #embed.weight.data.copy_(torch.from_numpy(pretrained_weight))\n",
    "        \n",
    "        torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "        \n",
    "    \n",
    "    def init_hidden(self, hidden_dim):\n",
    "        # The axes semantics are (num_layers, minibatch_size, hidden_dim)\n",
    "        return (torch.zeros(1, self.batch_size, hidden_dim),\n",
    "                torch.zeros(1, self.batch_size, hidden_dim))\n",
    "\n",
    "\n",
    "    def forward(self, prev, melody, mask):\n",
    "        \n",
    "        prev_embeds = self.p_embed(prev)\n",
    "        x1 = torch.transpose(prev_embeds, 0, 1) \n",
    "        \n",
    "        #TODO: ensure that melody input is a tensor\n",
    "        \n",
    "        melody_embeds =  self.m_embed(melody) #Error here\n",
    "        x2 = torch.transpose(melody_embeds, 0, 1)\n",
    "        packed = pack_padded_sequence(x2, mask, batch_first=False)\n",
    "        \n",
    "        p_lstm_out, self.p_hidden = self.p_lstm(x1, self.p_hidden)\n",
    "        m_lstm_out, self.m_hidden = self.m_lstm(packed, self.m_hidden)\n",
    "        (h_t, c_t) = self.m_hidden\n",
    "        out_unpacked, _ = pad_packed_sequence(m_lstm_out, batch_first=False)\n",
    "        #print(out_unpacked[-1], h_t[0])\n",
    "        p_fstate, m_fstate = p_lstm_out[-1], h_t[0]\n",
    "\n",
    "        \n",
    "        concat = torch.cat((p_fstate, m_fstate), 1)\n",
    "        tag_space = self.hidden2tag(concat) #REASON: you only need the final state\n",
    "        tag_scores = F.log_softmax(tag_space, dim = 1)\n",
    "        \n",
    "\n",
    "        withroot = torch.cat((concat, tag_scores.max(1)[1].float().view(-1,1)), 1)\n",
    "        second = self.root2second(withroot)\n",
    "        third = self.root2third(withroot)\n",
    "        second_scores = F.log_softmax(second, dim=1)\n",
    "        third_scores = F.log_softmax(third, dim=1)\n",
    "        \n",
    "        #stacked = torch.stack([tag_scores, second_scores, third_scores], dim=0)\n",
    "\n",
    "        return [tag_scores, second_scores, third_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:  12000   phid:  5   mhid:  5   eps:  0.06455417238716951\n",
      "0 tensor(3.9526)\n",
      "[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8] [ 3  8  1  1 10  1  6  1  6  1 12  3 10  3  5  7  4  8  8  7]\n",
      "[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8] [ 1  4 11  4  8  2  4  5  6  7  4 11 11  9  1  3  6  6  3 10]\n",
      "accuracy: 0.17578125\n",
      "100 tensor(2.8315)\n",
      "[1 1 1 1 1 1 8 1 3 1 8 8 3 3 8 1 1 8 8 8] [10  1  1  3  1  2  5 11  8  6  5 11  3  6  8  1  6  4  7  6]\n",
      "[1 3 8 8 3 8 8 3 8 1 8 8 1 8 1 8 8 8 3 3] [ 1 12  8  6  5  1  3  1  4  2  1 11  7  1  1 11  7  1  8  8]\n",
      "accuracy: 0.171875\n",
      "200 tensor(2.7498)\n",
      "[8 8 1 1 8 4 8 1 4 4 8 1 4 1 8 1 1 8 8 1] [11 10  8  1 10 10 10 10  3  2  6  6  8  5 12  8  7  8 11  5]\n",
      "[8 1 8 8 1 8 8 1 4 1 4 8 1 8 8 1 1 1 8 1] [ 7  3  1  4 11  6  8 11 11  3  4 11  2 11  6  3  3  8  1 10]\n",
      "accuracy: 0.173828125\n",
      "300 tensor(2.5503)\n",
      "[ 3  3  1  3  1  1  8  1 11  4  8  3  4  1  3  3  4  8  8  1] [ 1  1 10  1  6  1 11  5  1  6 11  6  5  1 10 10 11  6  3  1]\n",
      "[ 1 11  3  4  3  8  3  4  1 11  1  1  3  3  1  3  3  1  3  3] [ 1  1 12 11  8  8  1 11 10  1  2  1  6  5 10  7  8  7  1  3]\n",
      "accuracy: 0.169921875\n",
      "400 tensor(2.6319)\n",
      "[ 4  3  6 11  1 11  4 11 11 11  3  1  4  1  1  4  3  3 11  6] [11  5  1  1  1  6  6  3  1 11  3  5  3  6 12 11  6  8  6  6]\n",
      "[ 1  4 11  1  3  1 11  1  1  6  4  1  1  1  1 11  3  3  3  1] [ 1  8  6 12  1  6  6  6  1  8  2  9  5  3  6  1 10  3  8  8]\n",
      "accuracy: 0.181640625\n",
      "500 tensor(2.5992)\n",
      "[11 11  4  8  8  4  8  8  1  6 11  8  8  8 11  8  8  8 11  6] [ 1  9  6  8  8  1  5 12  7  1  3  5  1  5  8 12  5  6 11  2]\n",
      "[ 4  8 11  4  8  8  8  1  4  8 11  4  8  8 11  8  4  4  8  6] [ 1  1  8  6  1 10  5  8 11  3  3  6  1  6  6  1  6  4  8  4]\n",
      "accuracy: 0.189453125\n",
      "600 tensor(2.5394)\n",
      "[ 4  3  8  3  3  3  3  3  6  4  3  3  3 11  3  3  3  3  4 11] [ 6  8 10  8  8  3  5  1  5 11  1  1  7 11 10  2  1  3 12  4]\n",
      "[ 3  3  4  6  3  8  3  1  4  4  3  4  4  4  3 11  6  3 11  4] [ 5  8  8  2  3  4  2  3  7 11 11  1  6 11  3  6 11  5  8  4]\n",
      "accuracy: 0.19921875\n",
      "700 tensor(2.4760)\n",
      "[ 3 11  6  8  3  4  3  6  3  3  3  4  6  6 11  4  3  3  4  3] [ 5  8 11  9  7  9  8  1  3  5  4  8  8  1  8  9 11  1  1  6]\n",
      "[ 4  3  4  6  6  6  8  3  3 11  3 11  4  3  3  4  8  6 10  8] [ 2 10  4  6  6  4  1 10  8  9  1  8 12 10 10  2 11  8  3  8]\n",
      "accuracy: 0.146484375\n",
      "800 tensor(2.4544)\n",
      "[ 3  6  3 11  3  3  3  4  3  3  3  8  4  6 11  6  3  4  4  6] [ 8  6  1  1  8 11  5 11  3  3 12  1  3  6  1 11  3  9  1  1]\n",
      "[ 3  3  3  4  4 11  4  3  3  8 11  1  3  4  3  1  6  6  6  8] [ 1 10  4  6  1  8  4  3  3  3 11  1  8  8  8  6  8  8 11  6]\n",
      "accuracy: 0.173828125\n",
      "900 tensor(2.5869)\n",
      "[10  6  3 10  4  8 10  4  8  4 11  1  4  4 10  8  8  8  8 11] [ 3  4  0  8  2  1 10 12  6  4  6  6  4  8 10  8  8  8 11  5]\n",
      "[ 5 11  5 10  4  4  5  4  6  4 11  1  8  1  6  3  4  6  4  3] [ 1 11  7 12 11 11 12  1  1  6  6  1  1  3  1  8  6  4  6  8]\n",
      "accuracy: 0.177734375\n",
      "1000 tensor(2.3965)\n",
      "[10  5  8  4  6  3  1  4 10 10  4  6  3  5  4  4  3  1  4  6] [10  9  8 11 11  6  1  9 10 12 11  1  3 10  1 11  9 11  1 11]\n",
      "[10  6  5 10  4  1  4  3  6  1  6  6 10  5  6  1  3  3  6  3] [ 1  6 10  7  3  1  6 10  8  8 10  8  8  5  6  1  1 10  1  1]\n",
      "accuracy: 0.1953125\n",
      "1100 tensor(2.4356)\n",
      "[ 6 10  3  6  1  3  5  8  8  1  6  4  8  5  9  1  8  4  3  3] [ 1  5  5 11  8  8  8 11  5  8  1  6  3  1  9  3  3  1  8  2]\n",
      "[ 6 10 10  3  3  3  8  6  1  6  3 10  3  1  3  4  4  6 11  3] [ 8  8  8  5  3 12  1  3 12  6  8  3  1  6  8  6  2  1  6  5]\n",
      "accuracy: 0.21875\n",
      "1200 tensor(2.4271)\n",
      "[ 9  3 10 11  6 10 11  1  6  5 10  6 10  6  4  1 10  6 10  8] [ 2  1  6  6  4  8  1  6  6  1  5  8 10  8  1  1  3  1  8  6]\n",
      "[ 2  6  8  4  6  3 10 12  3  6 10  6 10 10  4 10  8  6  1  3] [ 9  3  1 11  8  1 10  7  1  9  5  1  5 10  8 10  3 11 11  1]\n",
      "accuracy: 0.197265625\n",
      "1300 tensor(2.2864)\n",
      "[ 8  6 10  9  1  6  6 11  6  6  8  1 11  1  1  6  6  8  4  8] [ 1  8  8  8  3  3  1  4  4  4 10  3  8  8  6  8 11  3  2  1]\n",
      "[10  6 10  5  3  6  6  4  1  6  6  1  4  6 10 11  6 10  9  8] [ 1  3  3  5  6  8  3  6  1  6  3  4  4  6  3  8 11 10  9  3]\n",
      "accuracy: 0.20703125\n",
      "1400 tensor(2.3513)\n",
      "[ 6  5  1  1  4  3  1 11  1  9  6  1  5  4  4  5  3  4  1  1] [ 1  9  6  1  9  5 10  6  6 11  8  8 12  9  4 10  3  8 10  3]\n",
      "[ 1  1  1  6  1  8 10  1  6  8  1  6  3  1  6  3  6  6  3 11] [ 8  4  8  1  6  3 10  8  8 10  5  5  6  1  8  8  6  6  5  6]\n",
      "accuracy: 0.251953125\n",
      "1500 tensor(2.3101)\n",
      "[ 3  8 10  5  9  4  6  3 10  8  8  8  1  1  9  8  1 10  8  1] [ 3  1  8 12  3  1  1  1  3  8  2  9  6  8 11  3  6 10  1  1]\n",
      "[ 8  8  8  3 10  5  2 10  8  8  6  8  1 11 10  4 11 10  4 11] [ 1  6  8  3 10 12  5  8  8  6  6  6  6  8 10  6 11  6  6  4]\n",
      "accuracy: 0.279296875\n",
      "1600 tensor(2.2934)\n",
      "[11  3  4  8  3  1  8  3 10  9 10  4  2  8  1  2 10  3  3  3] [ 1  6  7 10  8  1  5  6  3  3  1  1  6  3 10  1 10  8  5  6]\n",
      "[ 1  3  4  8  5 10 10 10  3  4  3  6  8  8  4  5 10 10  5  9] [ 3  1  1  3  8 10  3  6 10  6  4  6  8 11  6  3  8  3  3  4]\n",
      "accuracy: 0.263671875\n",
      "1700 tensor(2.2785)\n",
      "[10  9 10  5  1  6  3  6  1  6  4  5  3 10  6  2 11 10  1  1] [12  1  3  6  6  8  6 11  8 11 11  7  2  6  7  5  6 12  8 10]\n",
      "[ 8  8  2 10  1  1  4 10  8  3  5  8  9  1  1  4  4  9  8  6] [ 3  1 11  5  1  6  4 10  1 10  5 10  4 11  3  3  2  4 12 11]\n",
      "accuracy: 0.25390625\n",
      "1800 tensor(2.3053)\n",
      "[10  1  1  8  4  1  8  8  3 11 10  4  6 10 11  8  3  1  4 11] [ 3  8  8  3  8  8  8  5  8 11 12 11  6  9  4  3  8  1  6 11]\n",
      "[10  6  8 10  9 10  6  1  8 10  2  6  8 10 11  1  8  6 10  1] [10 11  3  8  9 10  3  4  8  8  9  2  1  8 11  1  1  6  8  1]\n",
      "accuracy: 0.23046875\n",
      "1900 tensor(2.1500)\n",
      "[ 1  8 10  5 10  5  3 10  8  8 10  1 10  3  6  6  9 10  3  8] [11  6  5  9  8 12  8  3  8  8  3  8  1  5  6  8  2  3  6  8]\n",
      "[10  8 11  8 10 11  1  3  1  8 10  6  7  4  1  1  9 10  6  5] [10  6 11  6 10  6  6 10  1  3  6 11  1  4  3  8  7  3  1 12]\n",
      "accuracy: 0.2578125\n",
      "2000 tensor(2.0909)\n",
      "[ 3  1  8  6  2  6 10 11 11  9 10 10  8  4  1  3  8  5  8 11] [10  8  8  1  6 11  6 10  8  9 10  8  6  8  1  3  3 10  8  6]\n",
      "[ 4  8 10 11  5 11  5  6  6  4  1  6  4  4 10  4  5 11  5 11] [ 1  4  3 11 12  3  1  1  1  4  1  6 11  8 10  3  8 11  8  3]\n",
      "accuracy: 0.24609375\n",
      "2100 tensor(2.2885)\n",
      "[10  8  9 10  8  8  3 10 10 10  6  8  6  8  5 10  6  8  9  5] [ 3  8  7  3  8 10  8  5  3 12  6  2  1  1 12  3  1  6 12  7]\n",
      "[ 2  1 11  5  8 11 10  3  3  2 10  5  6  4  3  3  1  8 10  3] [10  1  1  6  3  4 10  1  1  8  8 12 11 12  8  4  3  9 10  3]\n",
      "accuracy: 0.248046875\n",
      "2200 tensor(2.1993)\n",
      "[ 2  1  5  6  9  8 11 11  6  1  1  8  8  8 10  3  3  6  8  5] [ 2  1  5 12  6  3 11  4  6  1  3  8  8  5  3  1  3  8  1 11]\n",
      "[ 5 10  9  4 11  4  5 11  4  6  1  8 11  6  8  9  6 10  1  1] [ 1 12  3  4  6  9  5  6  4  6  8  6  1  1  1  9  6 12  6  1]\n",
      "accuracy: 0.251953125\n",
      "2300 tensor(2.2290)\n",
      "[ 6 10  8  1 10  8 10 10 10  9  3  6  3  1  2  6 10  1  6  9] [10 10 11  1 12  1  5  3  1 12 10  3  8  5  1  6  3  1  1  1]\n",
      "[ 3  5 11  2  8  8 10 10  3  1  3  8 11 10  4  5  1 10  6  8] [10  8  1 12  8 10  8 10  3  3  8  6  6  5  9 12  8 12  2  8]\n",
      "accuracy: 0.234375\n",
      "2400 tensor(2.3583)\n",
      "[ 6  2  6  5  3  9 10  5  6  8 10  2  4  6  8  9  4  5  8  1] [ 6  4 11  3  3  8 10  7  8  1 10  7 11  1  8  3  1  6  1  2]\n",
      "[11  3  3 10  5  6 10  5  2 11 10  3  6  3 10  6  9  1  6  3] [11  8 10  7  5 11  2  6  7  6  3  7  1  8  3  6  9  6  1  3]\n",
      "accuracy: 0.2109375\n",
      "2500 tensor(2.2781)\n",
      "[10  3  8  5  8 10  6  6  9  8  9  1 10  5  8  6  8  8 11  8] [10  1  8 10  8  5 11  8  6  1  9  8 10  3  1  8  8  1  5  6]\n",
      "[10 10 10  6 10  6  6  6  6  6  9  3  8  5  8  5  8  8  8  6] [10  5  8  8  7 11  3  6  6  8  1  5  5  5  9 12  8  8  1  8]\n",
      "accuracy: 0.287109375\n",
      "2600 tensor(2.2455)\n",
      "[ 3 10  8  1  1  6  6  5  6 10 11  8  1  5  8  8  6  1 10  6] [12  6  1  1  6  6 11  2  9  3  6  1 10  1  8 12  1  6  5  6]\n",
      "[10  8  8  5  5  5  8  3  1  3  5  3  6 10  6 10  8  6  5  3] [ 5  8  8  6 12  8  3  8  1 11  5  5 11  8  1  8  6  1 10  3]\n",
      "accuracy: 0.244140625\n",
      "2700 tensor(2.2506)\n",
      "[ 3 10  6 10 10  1  8  2 10  8  3  8  8  1  1  3 10  8  1  8] [10  3  3 10  2 10  1  7  3  1  1  6  8 10 11  3  5  6  1  8]\n",
      "[ 8  1  5  8  1  8  3  3 10  3 11  3  8 10 10  6  8 10  8  8] [ 3  1 10  3  1 10  5  8  8  3  4 10  8  3 12  1  8  1  5  8]\n",
      "accuracy: 0.306640625\n",
      "2800 tensor(2.3937)\n",
      "[10  8  9  7  1  1  1  1  3  8  5  9  9 10  3  8 10  8  8  6] [10 11  3  9  6  6  8  6  3  3 12  9  1  8  8  4 10  4  8  6]\n",
      "[ 8  5  5  1  9  1  1  8  6  6  8 10  6  4 10 10 10 11  1  1] [ 1 10  3  7  8  6  1  8  8  3 11  5  3  1  3  5  3 11  8 11]\n",
      "accuracy: 0.283203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2900 tensor(2.2298)\n",
      "[ 8  3 10  6  9  1  9  8  5  4  6 11  5  8  3  8 10  6  5  5] [ 1 10 10  3  8  8  7  6  5  1  6 11  8  8  3  3  2  3 11  3]\n",
      "[ 3  1  3  8 11  3  8  4  5  3 11  1 10 10  8 12  9 10  1  9] [ 6  4  8  8 11  1  3  4 10  8 11  1  3  3 11  9  1  3  1  4]\n",
      "accuracy: 0.26171875\n",
      "3000 tensor(2.0991)\n",
      "[ 5  5  1 10  5  3  6  4  1  1  3  8 11  3  3  3 11  6 10  2] [ 5  9  3 10 10  3  1 10 12  1  8  1  4  3  8 10 11  1  3  4]\n",
      "[10  3  3 10  3  1  1  6  8  8  1  6  6  8  1 10  1  2  8  6] [ 8  8  3 10  5 10  3 11  8  8 11  6  6 10  1  7  6 11  3  6]\n",
      "accuracy: 0.298828125\n",
      "3100 tensor(2.1552)\n",
      "[ 6  3  3  3  3  5  5  3  5  1  3  8  9 10  7  3  8  1  8  5] [ 9  3 10  3  3 10  5  8  5 10 10  4  4 12 12 10  1  6  9 10]\n",
      "[ 1  6 10  5  1  1  3  8  5  3  5  1 11 11  6  2  6  9  5  3] [ 1  8  3 10 10  1  3  1  3  3 10  4 11  2  1  3  3  4  8  3]\n",
      "accuracy: 0.275390625\n",
      "3200 tensor(2.1989)\n",
      "[ 6 10 10  8  8  5 10  9  8  8  6 10  2 10  1  5  5 11  1 12] [ 1  5  5 12  8  9 10  7 10  8  8  5  5  6 12  9  3  8  8 12]\n",
      "[10  5  8  3  8  5  9  4  2  8 11  8  2 10  8  2  6  5 11  3] [10 12  8  8  3 12  9  2  1  8 11  1  6  8  1  4 11 12  4 12]\n",
      "accuracy: 0.291015625\n",
      "3300 tensor(2.0278)\n",
      "[ 4  1 10  3  8  6  1  1  6 10  6  6  6  6  1  4  1 10 10  6] [ 3  8  3  3  8  3  1  6 12  3  9  3  6  1  8  6  6 10  1  8]\n",
      "[11  3  3  3 10  4  9 10  3  1  1  5  9  6  8  9  8  1  8  3] [ 1  6  6  3  3  9  9 10  6  1  1  5  6  8  8 10 10  1  1  3]\n",
      "accuracy: 0.279296875\n",
      "3400 tensor(2.1794)\n",
      "[ 1  6  1  1  3  1  1 10 10  1  6 12  1 11  5 10  3  8  4  9] [ 8 10  8  5  3  6  5  5  1  8  1 11  6  4  1  3 10  1  4  4]\n",
      "[ 1  8  6  9  6  6  0  1  1  3  6  5  9  6 10 10 10  4  6  8] [ 6  8  3  6 10  6 10  8  4  0  8  1 11  1  8  5 10  9  6  6]\n",
      "accuracy: 0.263671875\n",
      "3500 tensor(2.1246)\n",
      "[ 8  1  8  4  8  9  6  5 10  6  6  8  8  3  8 10  8  6  6  4] [ 8  1  8  6 10 11  8 10 10  8  8  8  3  8  8  8  8  6  8  9]\n",
      "[ 1  8  1 11  6  6  5  3  8  6  8  6  6 12  6  5  5  5  1  4] [ 1  5  2  3 11  6 10  1  8  6  1 11  1  7 11  3 10 10  6  8]\n",
      "accuracy: 0.322265625\n",
      "3600 tensor(2.0003)\n",
      "[ 0  3  1  8  3  5  1 11  1  1 10  8  4  6  8  6  5  8 11  1] [ 5  8  1 11  5 10  6  1  8  5  8  1  8  1  2 10  9  1  4  3]\n",
      "[ 8  5  3  1  5  1  5  8  2 10  6  3  3  6 11 11 10 10  1 12] [ 1  5  8  6 10  8 10  5  2  1  8  1 12  6 11  9  8 11  8  1]\n",
      "accuracy: 0.296875\n",
      "3700 tensor(2.1657)\n",
      "[ 3  3  5  1  1 10  4  8  9  8  8  3  6  8  6  5  1  1  6  4] [ 3  1  5  1  6  2  7  8  7  3  1  8  1 10  6  6 10  1  1  3]\n",
      "[ 9 10  3  1  8  9  4 11  9 11  8  1  6  5  1 10  6 12  5  9] [ 1 10  8  3  8  4 11 11 10  1  8  1  1 12  1  8 11 10  7 11]\n",
      "accuracy: 0.298828125\n",
      "3800 tensor(2.1354)\n",
      "[ 3  6 10  5  8  6  3  9  6  3  3 10 10  8  7  5  6  8  8  3] [10 10  1  5 11  6  8  9  8  3  3  3  8 10  4 10  6  3  8  6]\n",
      "[ 5 11  8  1  3 10 11  1 12  6  3  8  4  8 11 10 11  5  3  9] [ 9  6 11  1  1  5  4  1 12 10  6  8  4  4  6  5  3  5 10  4]\n",
      "accuracy: 0.287109375\n",
      "3900 tensor(2.2236)\n",
      "[ 1  3  6  8  8  3  4  6 11  6  6  5  3  4  1  1  1  4  5  1] [ 9  8  6  8  3  1  8  6  4  4 11  4  1  3  1  2  1  2 10  8]\n",
      "[10 10  1  3  8  2  7  4  6  5  4 10  5  5  1 11  5  4  3  1] [ 3  3  6  3  1  2  8  9  1  5  6  8  5 10  1  4  5  3  1  6]\n",
      "accuracy: 0.31640625\n",
      "4000 tensor(1.9901)\n",
      "[10  5  5  6  1  8  3  1  3  8  3 10  6 10  8 10 11  9  4  8] [10 10  5 11  6  9  1  1  6  4  8  5  8  6  8  4  6  8  9  3]\n",
      "[ 2 10  6  3  6  9 11  6  1  1  8  5  4  6  5 10  8  5  5  8] [ 1  8  1  3  6  9  6  6  6  1  6 10  8  6  5  8  8 10 12  3]\n",
      "accuracy: 0.23046875\n",
      "4100 tensor(2.0952)\n",
      "[ 8 11  4  6  3  6 11 11  5  1  3  8  9 11  1  5  1  4  3 11] [ 3  1  6  3  6  6  6  8 10  6  1  9  0 11 10  5  6 10  1  6]\n",
      "[ 1  4  1  1 10  4  3  6 10  3  8  6  2 11 10  1  4  6 10  3] [ 1  4  3  1  3  9  5  1 10  5 11  6  3  1 12  3  3  6  5  6]\n",
      "accuracy: 0.2578125\n",
      "4200 tensor(2.1781)\n",
      "[ 5  8  3  3  3 10 11  8  4  3  4  3  9 10  3  1  2 10  1 11] [11  1  3  6  3  2  6 11  8  9 11  6  4  8  1  1  8  5  1 11]\n",
      "[10  4  5 10  3  8  8  3 11  6  6 11  9  5  4  9  8 10  3  6] [ 5  6  9  8  3  3  1  1  6  8  1  6  6  7 12  4  8  8  1  3]\n",
      "accuracy: 0.255859375\n",
      "4300 tensor(2.0824)\n",
      "[ 4 11  5 11  9  1  8  8  6 10 11  8 10  4 10  8  5 10 10 12] [11 10 11  6  9  1 10  8  2  3  6  8  3  3  1  8  5  5 10  1]\n",
      "[ 4 10  3 12  1  4 11  9  1  6  7  8  3 11  4  8 10  6  3  6] [ 4  3 10  2  5  6  6  4  1 11  5  3  1  3  3  1 11 11  2  1]\n",
      "accuracy: 0.28515625\n",
      "4400 tensor(2.0918)\n",
      "[ 2  1  3  9  4  8  2  5  7  6 11 11  1 10  6  1  5  5  1  9] [ 2  1  6  9  9  8 12  7  7  2 10  6  6 10  5  6 10  6  1  5]\n",
      "[ 2 11  6  8  3  1  9  5  3  3  1  3  1  1  1  6 10  3  5  9] [ 9 11  2 11  3  6  9  6  1  8  8  3  8  1  5 11  8  6 11 10]\n",
      "accuracy: 0.291015625\n",
      "4500 tensor(2.1209)\n",
      "[ 4  5  8  3  1  8  8  6  6  8 10  6  4  0  1  4 10  1 11  8] [11  9 10  1  8  8  8  6  1 10  2  6  3  7  3  9  3  1  6  3]\n",
      "[ 4 10  3 10 11  1  1  3  8 11  2  7  4  6  1  8  8  9  5 10] [11  6  3  8  3  1  6  1  6  6 11  9  4  6  8  8  6  3  7  5]\n",
      "accuracy: 0.255859375\n",
      "4600 tensor(2.1091)\n",
      "[ 5  4  5  1  5 10  5 11  6  5  5  8  6  8  1  6  8 11  6  4] [ 1  1 10  1 12 10  5  4  1  5  5  6  9  1  6  8  5  6  1 11]\n",
      "[10  1  1  8 10  3 10 10  6  8 10  9  4  3  6  6  9  8  5  4] [10 12  1  0  3  8  3 10  8  1 11  3  9 12  3  5  3  1 11  9]\n",
      "accuracy: 0.291015625\n",
      "4700 tensor(2.0375)\n",
      "[ 8  5  3  4  8  5  5  3  3  3 10  6  8  4 10  9  1  8 10  4] [ 8  4  8  1  1 12  5  2  6 12  1  6  8  4 12  4  1  1  5  4]\n",
      "[ 6  3  1  1  1 10  6  5  1  1  3  4  3 11  9  1  3 12  1 11] [ 1  8  8  6  1 10  3 12  1  1  9  9  3  4  4  8  3 11 10  4]\n",
      "accuracy: 0.263671875\n",
      "4800 tensor(2.0352)\n",
      "[ 3  4  3 10  4  2  1  1  6  4  6 10  5  3  4  8  3  4  4  8] [ 3  4  3  8  8 12  1  3  6  9  9  3 10 11  4  4 11  3  3  4]\n",
      "[ 0  1  5  1  8  3  1  9  3  3  8  4  5  2  8  6 10  5  6  1] [11  1  6 11  8  3  8  1 10  8 12 11  3  4  5 11  5  8 10  8]\n",
      "accuracy: 0.291015625\n",
      "4900 tensor(2.0138)\n",
      "[ 3  4  3  4 11  8  4  1 10  9  4  3  8 10 10 11  1  4  1  6] [ 1 11  3  8  1  8  4  6  6  5 11 10  1  3  8 11  1  4  1  1]\n",
      "[ 1  3 11  3  1  5 11  6  6  8  1 10  5  8  3  6  8 11 11 11] [ 6  1 11  1  1 10 11 11 11  8  6  1  1  1 11  5  8  1  6  6]\n",
      "accuracy: 0.28125\n",
      "5000 tensor(2.1740)\n",
      "[12  3  6 11  2  3 12  8  3  6  6  5  5  6  2  3  3  3 12 11] [ 8  3  6  6  6  2  8  8 10  8 11  5  5 11  4  1  8  3  2 11]\n",
      "[ 3  1  3  1  5  5  5  5  4  1  3  5  3  1  3  9  3 10  9  6] [11  3 11  3  8  5  4  7  8  6 10 12  7  8  3  4  1 10  6  6]\n",
      "accuracy: 0.25390625\n",
      "5100 tensor(2.0083)\n",
      "[ 3 10  3  1  9 11 11  1 11  3  8  6  3  5  1  1  1  2  9  1] [10  3  1  8  4  6 11  1  1  8  1  1  6 10  6  6  8  9  2  6]\n",
      "[ 5  1  5  1  6  8 11  3  5  5  5  4  3  5  8  1  8  5  9  1] [ 1  6  7  6 11  3 11  6  7  1  8  4 10  4  8  6  2  1  2  8]\n",
      "accuracy: 0.265625\n",
      "5200 tensor(2.1150)\n",
      "[ 5  5 10  3  3  9 10  5  9  3  6 10 11  1 10  9  9  9 10 11] [ 3 10 10 11  3  6 10 11  4  5  1 11  6  1 10  4  4  9  1  1]\n",
      "[10 10  3  9  3 10  6  1  3  4  5  3  5  5 10  3  9  1  4  9] [ 3  3  8 11 11 11  8  3  3 11  5  8  5  7  8  3  1  8  1  8]\n",
      "accuracy: 0.2421875\n",
      "5300 tensor(2.0862)\n",
      "[ 6  8  1  1  8 10  8  5 10  3  9  4  9  4  5  1 10  8  8  6] [ 8  3  8  6  8  3  1 10  3  8  1 11  4 11  5  6  3  1  8 11]\n",
      "[11 10  1 10  1  5  8 10  3  5  5  5  2  6 10  3 10  5  1  6] [ 6  8  6  3  6 10  8  3  6 10  8  5  9 11  1  6  8 10  1  1]\n",
      "accuracy: 0.30078125\n",
      "5400 tensor(2.1231)\n",
      "[10  9  3  5 11  9  5  1 12  8 11  5 10  5  1  8  9 10  1  3] [ 8  5  8  7  1  4 11  4  5  1  6  8 10  3 11  6  4  8 10  3]\n",
      "[ 3  8  5  9  4  1 12  5  5  0  8  1  1 12  9  3  4 10  1  3] [10  3  6  4  4 10  5  5 12 10  1 11  6  1 11 10  1  5 11  8]\n",
      "accuracy: 0.26171875\n",
      "5500 tensor(2.1413)\n",
      "[10 10  3  3  3  1 10  9  3  1  9  4  5  3  3  3 11  4  3  6] [ 5 10 10  8  7  1  8  4 10  3  8  9  5  1 10  3  6  8  3  1]\n",
      "[10  3  1  3 11  3  2 11  3  3  8  1  9  6 10 10  6  1  3  6] [10  8 11  3  4 11  9  1 10  1  8  1  6 11  8 10  6  1 10  7]\n",
      "accuracy: 0.271484375\n",
      "5600 tensor(2.0723)\n",
      "[ 5  5 12  1 11  1  3  2  4 11  6  7  6  3  8 12  8  6  3 10] [ 5 10  3  8  1 11  3  4  3 11  6  7  3  8  4 12  6 10  3 10]\n",
      "[10  3 10  8  6 12  6 11 11  1  8  8  3 12  4 12  5  3  8  2] [ 3  6  8  1  1  2 11  6  4  1  3  9  3  8  9  5 10  8  8 11]\n",
      "accuracy: 0.291015625\n",
      "5700 tensor(2.2133)\n",
      "[ 3  3  6  1 11  5  9 10  6 11 10  6 11  3  1  1  7 10  5  5] [ 3 10 11  6 11 10  4  1  1  1 10  8 11  3  8  1  0  5  5  5]\n",
      "[ 8 10 10  5  8  5  1  8  1 11  5  6  6  4  3  3  4  8 10 10] [ 1  3  3  6  1  5  1  3  5 11  1 11  6  9 10 10  4  8  3 10]\n",
      "accuracy: 0.302734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5800 tensor(2.0472)\n",
      "[ 3  2  8 10  5  4  1 10  1  6  1  5  4  5  8  4  1 11 10 10] [ 1  5  8 10  5  4  1  7  1  8  1  8  3  5  9 11  3 11  3  1]\n",
      "[10 12  8 12  5  1  8  6 10 11  4  8  6  5  9 10  9  8  5  9] [ 4  5  8  2 12  6  8  6  7  6  1  8  8  2  9  5  6  3  5  4]\n",
      "accuracy: 0.28515625\n",
      "5900 tensor(2.1158)\n",
      "[ 1 10 12 10  1 11  5  4 10 11  4 10 11 12  8 10  8  1 10  0] [ 8  8 12  7  1 11  8  4 10  6  4  8  4  5  6  1  1  1  1  3]\n",
      "[ 8  5  3  8  3 10 10 11  1  4  6  4 11  3  3  8 10 10  1  8] [ 3 12  8  6 11  9  6  6 10  7  5  9 11  3  8  6  5  8  1  8]\n",
      "accuracy: 0.298828125\n",
      "6000 tensor(2.2527)\n",
      "[ 8  5  6  2  8 10  3  8  8  9 11  1  5  9 11  5 10  8  3 10] [ 8  5  8  9  6  5  8  8  8  4  4  8 10  7 11  3  3 12  6 10]\n",
      "[ 8  5  3  4  6  5  1  5  3  8 11 10 10  6  6  4  5  1  5  3] [ 8  8  3  9  6 11  8  7 10  1  4  8  5  6  6 11  1  6 10  3]\n",
      "accuracy: 0.326171875\n",
      "6100 tensor(2.2319)\n",
      "[ 5 10  8  6  8  8 12  8  9  3 10  3  3  8  1  5  9  1  3 11] [ 9 10  3  1  3  1  1  3 11  3  6  8  6  1  6  8 11 10  2  6]\n",
      "[10  6  1  5  3  1  5  8 11  3 11  4 11  5  6  4  1  1  1  4] [ 3  6  6  4  3  6  5  1  4  4 11  4  6  7  6  8  3  6  1 11]\n",
      "accuracy: 0.30078125\n",
      "6200 tensor(2.0537)\n",
      "[12  5  3  3 10  3 10  1  3  6  5  4  6 11  8  4  9  8  3  6] [ 5  6  3  1  3  9 10  1  3  3  7  8 11  1  3 11  9  8  8 11]\n",
      "[ 4 12  3  4  1  3 10  6  4  3  8  4  6  1 11  3 10 10  8  4] [ 3  5  8 11  6  1  8  1  9  5  3  4  6  8 11  3 10  6  2  9]\n",
      "accuracy: 0.314453125\n",
      "6300 tensor(2.1386)\n",
      "[ 1  4  4  6 11  3  5  3  4  8  4 10  9  8  9  3  5  3 11 11] [ 1 11  9 11 11 10  5  3  3  1  4 10  9  5  3  8  6 10  8 11]\n",
      "[ 3  3  4  8  6 10  1 10  1  5  6  5  5  4 11  8  3 11  4  4] [ 5 10  6 11  6 12 12  1  1  5  6 10  3 11  6 12 10 11  2  9]\n",
      "accuracy: 0.2734375\n",
      "6400 tensor(2.0144)\n",
      "[ 7  2  1  4  4  3 11 10 10  3  5  1 10 10  1 11 10  1  9 11] [ 2 10 11  3  6 12  6  7 10  8 12  1  5  6 11  3 12 11  9 11]\n",
      "[ 6  4  8  5  3  3 10  3  3  1 10  6 10  3  1 11  5  9  1  1] [ 8  6 12 12  3  8  5  8  6  9  8  6  6  4 11  1 10  2  1  6]\n",
      "accuracy: 0.2734375\n",
      "6500 tensor(2.0812)\n",
      "[10  3  1  5  8 10  1  4  3  4  1  5  4  5  5  1  1  8  9  6] [ 5  3  6 10 10  6  3  9 10  6  1 12 11  2  8  3 10  3  5  6]\n",
      "[ 6 10  1  5 10 10  5 11 10  1 11  5 11  9  5  1  3  8  6 10] [ 1  1  8  2  5 10 10  6  8  8  6  3  6  6  6 10 10 10  5  5]\n",
      "accuracy: 0.2890625\n",
      "6600 tensor(2.1551)\n",
      "[10  8  6  3  5  4  8  5  6 10  3  4  5  9  1  1 11  1  1  1] [ 1  6  8  3 10  6  8 12 11  6  3 12 10  4  1  6  1  6  8  8]\n",
      "[ 5  4 11  2  5 10  1  5  1 10  3  2  7  5  6  3  3  1  1 10] [ 3  4 11 11  8  6  8  5  8  3  8  6 11  3 10  7  1  3  1 10]\n",
      "accuracy: 0.28125\n",
      "6700 tensor(2.0159)\n",
      "[ 3 10 10  6  3  6  2  5  6  6  1  3  1  6  9  8  1  4  3  3] [ 3  3 10  6  0  1  8  7  1  6  1  4  8  5  8  8  6  1 10  3]\n",
      "[10  2  8  6  5 10  2  5  8  6  1  3  3  1  1  6 12  5  8  1] [10  0  8  1  8 12  4 10  8  1  6  1  8  1  1 11  8 12  1  3]\n",
      "accuracy: 0.283203125\n",
      "6800 tensor(2.0382)\n",
      "[11 10  1  6  6 10  6  2  4  6  6  1  4 10  1  1  9  3  5  1] [11  8  3  5  1 10  1  9  4  6 12 10  4  8  1  8  9  3  5  6]\n",
      "[ 4  4  1  5  5 10  6  2  4  1  5  1  1 12  1  1  4  3  5  4] [ 1  6  8  5 10 10 11 11 10  3  5  1  8  7  1 12  5  3 10  3]\n",
      "accuracy: 0.328125\n",
      "6900 tensor(2.1464)\n",
      "[ 1 11 12  6  2  2 10  5  4  1  3  3  2  9  1  3 10  3  3 10] [ 3 11  3 11  2  2  5  8  1  8  3  3 11 11  1  3 10  6  3  5]\n",
      "[ 1  3  5  8  3  1  5 10  1  1  4  4  1  4  1  1  9  3  1  1] [ 8  8  8  1  8  8 10  8  6  6  4  1  1  6  6  4  6  8  1  6]\n",
      "accuracy: 0.28515625\n",
      "7000 tensor(2.1188)\n",
      "[10 10  3  4  5 10  6  6  5  7  3  6 10  9 10  4  1 11  9  3] [10  9  8  6  5  6  1  6  1  5  8  1  1  0 12  1 11  3  9 10]\n",
      "[10  3 10  8  1 10  3  4  8  5  5  1  1  9  9 11 10 10  6  8] [ 1  1  4  1  6  5  8  1  8 10  7  8  1  8 11 11  5 10  6  3]\n",
      "accuracy: 0.30859375\n",
      "7100 tensor(1.9363)\n",
      "[11  8 10  1  1  8  9 10 10 11  8 10  1  3  4  3  6  3  4  9] [ 6  6 10  1  6  3  9 10  5 11  3 10  6  3  6  8  6 10  1  2]\n",
      "[ 3  6 10  6 10 11  2 10 10  8  6  5  6 11 11  1  6 10  1 11] [ 3  6  5  5  5  4 10  1  1  8  1  8  6  7  4  1  3  4  1 11]\n",
      "accuracy: 0.32421875\n",
      "7200 tensor(2.2010)\n",
      "[ 3  6  1  1 11  8 10  4  4  6  5  4  6 10  1  4  8 10  4  6] [10  3  6  6  1  8  1  4  1  8  8  6  7  8  8 11  3 10 11  3]\n",
      "[ 1 11  1  8  1  5  5  6  1  6  1  3  1  3  9  1 10  8  3  4] [ 3 11  1  8  6 10 12  9  6 11  1  3  8  3  9  1  5  6  8 10]\n",
      "accuracy: 0.279296875\n",
      "7300 tensor(2.0822)\n",
      "[ 0 10  5 10  9  5  8  6  8  9 11  8  3  1  3  6  3  6  9  4] [ 1  5  8  3  9 10  8  1  9  6  6  1  8  1  8  6  1  3  9 11]\n",
      "[ 1  6  5 10  2 10  3  3  1  4 12  1  3  4 10 11  9  6  3 11] [ 8  6 10 10  9  1 10 10  8  9  3  3  8  9  9  1  3 11  6  4]\n",
      "accuracy: 0.291015625\n",
      "7400 tensor(2.0284)\n",
      "[ 5  3  5  5  1  5  4 10  1 12  1 10  6  6  6  6  4  1  6  1] [ 3  1  1  5 10  3  4  5  3  7  5  3  6  1 11  6 11  3  1  3]\n",
      "[ 0  1  5 10  3  9  5 10  8  3  6  3  1  3  1  9  1  9  5  1] [10  6  3  3  9 11  5 10  8 11  6 10  6 10  8 11 10  0 10  4]\n",
      "accuracy: 0.26171875\n",
      "7500 tensor(2.1230)\n",
      "[ 5 10 11  8  4 10  1 10  6  3  8  6 11  3  4 10  1 11  5  1] [ 1  8  6  3  6  1 11  3  4  3  8 11  3  3  6  3 12  1  6  4]\n",
      "[ 1 10  3  2  1  3 11  8 10 10 11  3 11  1  1  8  1  8 12  6] [ 1  3  3  0 10  3  4  1  5  6 11  3  9  6  1  1  5  8 12  6]\n",
      "accuracy: 0.306640625\n",
      "7600 tensor(2.0688)\n",
      "[ 1  2  3 11  1  4  2  9 11 10  9  2 10  3 10 10  6  5  8 10] [11  9  3 11  1  4  1  9  2 10  2  4 12  3 10  3 11 10  8  1]\n",
      "[10  8  8  9  4  8  9 11  8  5  9  2  3  1  2  8  4 10  5  5] [ 3  6  1  9  7  8  6 10 10  5  4  5  8  3 11  4  1  3  3  9]\n",
      "accuracy: 0.240234375\n",
      "7700 tensor(2.0982)\n",
      "[ 6  4  4  8  6  5  4  1  1 11 10  6 10 10  1  4  2 10  8 10] [ 6  1 11  8 11 10  4 11  1  6  8  6  1  5  1  4 11 10  1 10]\n",
      "[ 3  2  1  3  1 12  6 11  6 11  8 10  8 12  3  6  1  1  3  6] [ 1  2  8 11  3  9  8 11  6 11  1 10 10  5  1  8  3  6  7 11]\n",
      "accuracy: 0.330078125\n",
      "7800 tensor(2.1868)\n",
      "[ 8  2  2  1  4  5 11  8  1  6  3  6  5  1  3  8  6  1  4  2] [ 8  2  4  1 11  9  1  1  6 10  6  6 12  1  3  1  6  1  9 10]\n",
      "[12  5  5  6  6  5 10  8  1  5  3  8 10  1  1 10  8  3  1  5] [ 8  3 10  4  1 11  5  8  1  5  1 12  5 11  9  5  7  8  3 11]\n",
      "accuracy: 0.283203125\n",
      "7900 tensor(2.1309)\n",
      "[ 3  3 10  3  5  6 11  6  5  3 10  4  9  8 10 10  7 10  3  1] [12  3  3  1  5  6  6  8 10  8  3  4  4  1 10 10  2  8  8  1]\n",
      "[ 2  1  6  6  2  8  3 11  3 12  4  4 10  1  3  6  5  5  9  5] [ 4  7  6  6  0 10  3 11  1  2 11  3  8 11  3  8  1  5 11 12]\n",
      "accuracy: 0.306640625\n",
      "8000 tensor(2.0452)\n",
      "[5 1 5 9 5 6 0 6 8 4 1 8 3 3 4 6 9 5 6 1] [3 1 1 9 3 5 5 6 8 6 7 8 3 3 4 1 6 7 3 6]\n",
      "[ 5 10  1  3  3  3  3  1  8 11  1  4  3  6  6  3  6 10  6  6] [ 3  3  6 10  8  6  1 10  1  3  1 11 11  6  6  8  1 12  6  3]\n",
      "accuracy: 0.271484375\n",
      "8100 tensor(2.1260)\n",
      "[ 5 10 12  8  6  3  1 10  2  8  5 12 11  1  6  6  9 11  8  1] [ 3  3 11  5  1  3  8  6  8  1  5 12  1  1 11  6  9 11  8  6]\n",
      "[ 5  6  5  5  6  1  1  5 11  2  5  8  4  5  8  4 10  8  1  6] [ 1  1 10  7  6  6  6  5  6  1 12  6  6  5  3  5 12  5  1  6]\n",
      "accuracy: 0.2890625\n",
      "8200 tensor(2.1168)\n",
      "[ 1  3  8  4  6  1  6  4  1  1  4  1  4 10  5 12  5  4  8  6] [ 3  1  3  8  6  1  6 11  8  6 11  5  1  3 10  8  5  1  1  6]\n",
      "[ 5  3  4 12  5 10  3  3  1 10  1  8  3  9 10  5  1  9  4  5] [ 9  5  8 12  5  8  3  3  8  8  6  1 10 11  8  6  6  8 11  8]\n",
      "accuracy: 0.353515625\n",
      "8300 tensor(1.9798)\n",
      "[ 1  1 11  1 10  5  8  5  6  5  1  8  9  1  4  3  8  3 10  5] [ 5  1 11  1  5  5  5  6  6  8  1  1  3  1  8  1  1  5  4 10]\n",
      "[ 8  5  1  5  8 10 11 10 10  7 12 10  3 11  4  3 11 10  8  1] [ 8  8  6  1  8  0  4  8  1  5  5  3  3 11  4  3 11  6  8  6]\n",
      "accuracy: 0.326171875\n",
      "8400 tensor(2.0432)\n",
      "[ 1  3  3  8  4  4  8  8  8  6  4  5 10  4  8  6  4 10  9  3] [3 5 8 8 4 4 8 1 5 1 6 4 1 6 8 8 4 3 2 8]\n",
      "[12  1 10  4  2  6  8  3  4  3  4  6  8  8  8 11  1  1  1  1] [ 2  6 10  8 10  1  5  6  9  1  1 11  8  8  8 11 10 11  1  1]\n",
      "accuracy: 0.283203125\n",
      "8500 tensor(2.0996)\n",
      "[2 1 8 4 3 4 4 5 5 8 6 6 1 1 8 4 6 3 1 4] [ 9  1  8  8  3  1  4  3  5  8 11  1  7  1  1  9  1  8  6  3]\n",
      "[ 9  1  5  8  3 10 10  1  5  1  4 10  1  4 10  4 11  3  9  1] [ 2  1  2  8  1  5  3  6 10  1  7  5  1  4  4  3 11  3  4  1]\n",
      "accuracy: 0.287109375\n",
      "8600 tensor(2.1359)\n",
      "[ 3  8  8  1  4 10  5  8  4  4 10  3  6  5 10  8  6  8  6 10] [10  6  8  1  8  5  6  6 11  4  0  5  6  8  3  8  1  6  4  5]\n",
      "[ 8  3  3  7  9  6 11  5 12  8  3  5  5  1  3  1 10 10  8  8] [ 8  3  8  4  5 11  8  5  1  8  1  5  5  1  8 10  9  8  1  3]\n",
      "accuracy: 0.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8700 tensor(2.1482)\n",
      "[ 2  9  4  4  1  8 10  1  2 11 11  5  9 11  3  1  3  5  6  1] [ 5  6  1  8  1  4 10  6  0  6  6 11  8 11 11  6  1  2  6  1]\n",
      "[ 5  2  4  4 10  5  3  4  6  5  1  5  8  1  8  8  3  2  6  8] [ 4  6  8  6 10 10  8  4  1  5  1 10  8  6  1  7  5  2  5  6]\n",
      "accuracy: 0.2734375\n",
      "8800 tensor(2.0941)\n",
      "[ 3  1 10  3 10  3  6 11  6  9  4  1  6 11  8 12 10  1  1 10] [10 11  3  1  5  3  6  9  1  8  9  4  1 11 12  2 10  1  3 10]\n",
      "[12  1  1  1  8  8  3  8  6  6  4  9 10 11 10  2  8  8  3  8] [ 5  1  3  6  3 10  7  8 10  6  4  8  5  6 10  4  6  8  8 10]\n",
      "accuracy: 0.291015625\n",
      "8900 tensor(2.1121)\n",
      "[ 5 11  0  4  9  5  1  4  1  3 12 10  8  1  4  8  1 10  6 12] [10  6  1  4  4  5 11  8  8  3 10 10  1  3  4  1 11  1  6  7]\n",
      "[ 5  3  6 10  2  5  1  6 10  5  9  5 12  5  2  6  3  5  6  5] [10 10  1  3  4  6  6  8 10 10  9  3  7  6  2  1  8 11  8  8]\n",
      "accuracy: 0.25\n",
      "9000 tensor(2.0514)\n",
      "[ 9  6 10  1 11 12  6  4  3  5  6  4 11  1 11  5  5  8  6  3] [ 4 10 10  8 11 10 11  4  8  8  1  1 11  1  9 10  1  8  3  8]\n",
      "[ 9  1  8  1  8  3  3  9  8  1  1  9  1  1 11  3 12  8  1  8] [ 3  1  1  4  3  8  3  4  1  1  5  9  8 11  6  4  8  1  8  8]\n",
      "accuracy: 0.314453125\n",
      "9100 tensor(2.0850)\n",
      "[ 1 10  8  8 10  1  8  9  3  9  1  1  6  1 10  8  9 11  4  3] [ 8  3  3  3  3  5  2  9  8  9  8 11  1  6 10  4  2  1 11  6]\n",
      "[ 1 10  1  1  3 10  4  1 10  3  1  4 10  6 10  1  6  4  8 10] [ 6  5  8  6 10 12 11  1  6 10  6  8 10 11  8  6 10  4  3  6]\n",
      "accuracy: 0.28125\n",
      "9200 tensor(2.1148)\n",
      "[11  5  8  5  1 10  1  4  8 10  1  1  8  8 11 10  2  8  5  3] [ 6  9  8 12  1  3 10  1  3 10  8  1 12  8  1 12  5  8 10  2]\n",
      "[ 5 10 10 10  9 10  1 10  4 11  1  8  3  8  8  1  5  3  9  1] [ 5 10  3 10 11  6  1 10  9  5  6 12  6  8  9  1 10 10  4  3]\n",
      "accuracy: 0.275390625\n",
      "9300 tensor(2.0293)\n",
      "[ 4 10  3  4  3 10 10  1  1  5 12  8  3 10  3  9  9  3  4  6] [10 10  3 11  3 10  5  1  6  8  3  6  8  1  1  1 11  6  4  7]\n",
      "[ 3  5 10 11 11  5  3 10 10  1  3  6  1  1  9  9  8  5  3  4] [ 8  8 10  6  1  1  2  3 10  1  6  6  1  8  2  6  8 10  3  7]\n",
      "accuracy: 0.27734375\n",
      "9400 tensor(2.1495)\n",
      "[ 3  5  6  7  3 10  3 11  3  8  3  5 10  5  6  3 10  1  3  5] [ 8  9  2 11  8  6  8  6  4  3  8  7 10  5  6 10  8  1  3  5]\n",
      "[ 5  6  9  3  3  5  8  1  8  3  8  1  5 10  1  3  9  6  2  5] [10  3  2  3  6  1  8  1 11  3  5  1  3  3  1 11  4  1  6 12]\n",
      "accuracy: 0.28515625\n",
      "9500 tensor(2.0655)\n",
      "[10  6 11  6  1  6  6 10  4  4 10  9  4  2 10 11  6  3  6  2] [ 5  6 11 11  8  5  2  6 11  6  8 11  1  1  3  6  8  8 11  8]\n",
      "[10 10 11  6  1  8  6  4  1 11  3  3 11  2  1  8  1  5  2  1] [3 9 6 5 1 3 8 4 1 8 1 3 8 2 6 1 6 7 0 5]\n",
      "accuracy: 0.34765625\n",
      "9600 tensor(1.9112)\n",
      "[ 3  5  8  3  3  5  1  6  1  8  1 11  8  6 11  4 11  4  9  6] [ 3  1  8  1 10 12  1  6  1  8  6  6  3 11 11  9  6 11  9  6]\n",
      "[ 8  8  8  5  8  5  5  6  6  3  6 11  3  6  8  4 11 11  6  2] [ 8  6  5 12  8 10  5  5  6 11  3  1 10  6  1  9  3  4  5 12]\n",
      "accuracy: 0.28515625\n",
      "9700 tensor(2.0504)\n",
      "[ 5  6  1  3 11  1  8  5  3  9  4  4  3  5 11 11  3  1  1  1] [ 5  8  3  1  8  8  3 11  3 11  4  8 10  7 11  6  3 10  8  8]\n",
      "[ 8  1  3  8  9  8 10  5  8  4  7 10  3 10  3  4  1 11  1  1] [ 8  1  3  5  6  8  3  1  3  8  8  8  8 10 10  4 11  4  1  8]\n",
      "accuracy: 0.28125\n",
      "9800 tensor(2.0154)\n",
      "[ 1 12  6  5  1  6  3  6  1 12  3  4  6  5  5  6  5  4  1  6] [ 1  1  6  8  1  6  4 11  6 11  7  4 11  8  5  8  2  9  1  1]\n",
      "[12  5  9  5  1  4  8  9  3  1  9  8 11  7  5 12  4  2  8  3] [ 2 10  5  5  6  2  3  4  8  1  4  8  6  9 12 12  4  1  4  8]\n",
      "accuracy: 0.3359375\n",
      "9900 tensor(2.0686)\n",
      "[ 8  6  1  4  9  6 11  8  5  6  6  4  6  4  6  2 11  4  1  1] [ 8  6 10  4 11  6  6  3  5 11 10  3  1  4  6  2 11  9  6  6]\n",
      "[ 1  1  1  8  5 11  3  8  5  4 10  1  6  1  6  6  1 10  8  1] [10 10 10  1 12  2 10 10  1  0 10  8  6  3 11  1  1  3  1  8]\n",
      "accuracy: 0.30859375\n",
      "10000 tensor(2.0821)\n",
      "[12  3  9  5  6 11 12  1 11  1 11  1  5  3  6 11  1  1  1  8] [12  1  4  3  8  2 10 10  1  1  6  5  8  8  1 11  6  8 10  8]\n",
      "[ 3 10  2  1  1  8 10  8  1  6  6  1 10 10  8  4 10  8  1 10] [ 3  6 10  6  8  6  1 10  1  1 11  1  8  9  3  1  3  5  6  3]\n",
      "accuracy: 0.28515625\n",
      "10100 tensor(2.0360)\n",
      "[ 3  4  5  6  4 11 12  1  6 12  1  3  5  4  6  9  3  8  1 11] [10  4 10  6  1  1 10  8  1  2  6 12  8 11  6  2  3  3  1  4]\n",
      "[ 3  8  5 10  8 11  2 10 10  2  3  1  8  1  1 11  1 12  1  4] [ 3  3  9 10  3 11  2  3  2  4 11 11 11  3  1 11 11  7  6  5]\n",
      "accuracy: 0.28515625\n",
      "10200 tensor(2.0054)\n",
      "[ 6  9  3 11  1 10  2  6 10  6 10 11 11  5  3  1  1  8  4 11] [ 6  8  3  8  8  3  1  1  8  1  1 11 11 10 11 10 11  1  9  4]\n",
      "[10  4  3 10  1  1  7  6  3  1 10  1  8  8  9  1  9 11  8  4] [12  4 12 10 11  6  2 11  3  8  8  6  8  1  8  5  7  6  8  8]\n",
      "accuracy: 0.314453125\n",
      "10300 tensor(2.1373)\n",
      "[ 8 12 12 11 10  1  1  6  6 12  3  5  6  1  5  6  5 10 10 11] [ 3  5  4  6  3 11  1 11 11  5 10 11 10  8  7 11 12 10  5  6]\n",
      "[10 12  8 12  8 10  5  3  1  9  1  1 10  1  5  6 10  5 10  8] [ 1  3  8  7  8  5  3 10  1  8 11  1  5  6 10  6  1  9  3  1]\n",
      "accuracy: 0.287109375\n",
      "10400 tensor(2.0074)\n",
      "[ 5 10  2  3  4 11  2  3  8  6  3 10  1  9  5 10  1  3  8  8] [ 3  5  4 11  8 11 11  3  8 11  3  1  4  4  1  8  1 10  8  2]\n",
      "[ 5 10  9  5  6  8  2  6 10  1  1  6 10  8  5  9  4  8  6  9] [ 3  6 11  6 11  1 10  4  3  1  4  6 10  8  5  9  6  1  6  4]\n",
      "accuracy: 0.302734375\n",
      "10500 tensor(2.0777)\n",
      "[ 9 10  4 10  4 10 10  1 10  6 10 10  6  6 10  3  6  6  9  1] [11  3  4  6  8 10 10  6  5  1 10  8  6  6  1  3  1  1  4  8]\n",
      "[ 7  3  9  1  6  1  9  1  6 12  3  3  6  6  1  5  6  9 11  1] [12  3  2  1  6  1  4  6  6  5  3  3  1  5  1  1  6  2  6  8]\n",
      "accuracy: 0.26171875\n",
      "10600 tensor(2.1849)\n",
      "[ 0  4 10  5  1  9 10 12  5  9  6 11  9  9  5 10  1  1 10  9] [10  3  8  1  1  2  7  1  8  1  6  4  2  9  1  9  8  6 10  1]\n",
      "[ 8 10  5  1  5  1  5 12 12  4  2  3  3  2 10 11  8  6 10 10] [ 3 10  1  6 10  6  7  6 10  4 11  8  8  3  6 11  1  4 10  1]\n",
      "accuracy: 0.28515625\n",
      "10700 tensor(2.1096)\n",
      "[11 10 10  6  1  1 10  1  1 10  6  9  1  3  4 10  6  6  3 11] [ 1  8  5  1  1  1  8  6  1 10 11  7  6  3  6 10 11  1  8  6]\n",
      "[ 3  1  1  6  1  6 10 10  6  5  6  1  9  5  4  3  8  1  5  8] [ 3  6  8 10 11 11  3 10  6 10  8  1 11 10  4  8  1 10  8 10]\n",
      "accuracy: 0.294921875\n",
      "10800 tensor(2.0977)\n",
      "[ 5  6  9  1  1  5  9 10 10  1  8 11  1  4 11  6  2  3  5  6] [ 6  6  8  8  8  2 11  8 10  6  8 11  1  3 11  4  9 10  5  4]\n",
      "[ 5  6  4  3  1  9  5  8  3  4  5  1  1  1  3  3 11  3  3  1] [ 3  8  1 11  6  9  8 10  1  4  9  8 11  6  8 10  6  7 10  1]\n",
      "accuracy: 0.28515625\n",
      "10900 tensor(2.0707)\n",
      "[ 3  2  3  5  5  5  9 12  6  4  4  5  4  8  6  3  5 11  2  1] [ 9  0  9  5  8  8  8  3  6  6 11 12 11  1  6 10  8  6  3  6]\n",
      "[12 12  8 12 12  5 11  5  1  3 11  4  4  6  3  3  5 12  5  1] [ 9  5  3  8  1  6  9  8  9  5 11  1  1 11  8  1  3 10  6  1]\n",
      "accuracy: 0.2890625\n",
      "11000 tensor(2.0078)\n",
      "[ 3  1  5  1  5  1  1 11  5  5  5  4  1 12  1  3 11 11  4 10] [12  1  8  1 10  1  4  1  5  5 10  1 11  2  1  5 11  5  6  1]\n",
      "[ 5  8 10  3  1  6  6  4  1  1  5 11  8  5  3  6  8  3  3  3] [10  6 10 10  1  6  3  4  6  1  8  1  8  8 10  8  3  3  5  3]\n",
      "accuracy: 0.30859375\n",
      "11100 tensor(2.0724)\n",
      "[ 1  4  1  6  7  3  2 12  3 12  1  4 11  9  8  6 11 11  5  5] [ 1  6  1  8 10  8  2  9  3  2  1  6  5  4 11  8  6  1  5 10]\n",
      "[10  1  6  3  4 10  3 12 10 10  5  8  6  7 10  4  8  1  2  8] [ 5  3 11  3  8  5  3  5  3 12  6 12  4  3 10  4 10 11  4  8]\n",
      "accuracy: 0.306640625\n",
      "11200 tensor(2.0175)\n",
      "[ 3  6  1  8  4  1  4  3  4  4 11  8  1  5 11  1  6  4  8  9] [10 11  8  1  4  6 11 10  6 11  3  6  3  5 11  3  4  4  1  4]\n",
      "[ 8  1  1  4  7  1  1 10  8  1  3  1  1  8  3 10 11  1 10  7] [ 8  3 11  9  7  6  8  6  8  8  7  5  8  8 10  8  1  8 10  5]\n",
      "accuracy: 0.29296875\n",
      "11300 tensor(2.0502)\n",
      "[ 5  8  6  4  6  3  5  1 11  1  5 10 11  2  2  5 11  4  5  4] [ 5  6 11  6  6  8  6  1  1  5  6 10  4  9  2 10  6  9 11  1]\n",
      "[10  4  6  1  1  5  8  5 11  5  1  5  3  9  8  5  1  6 11 10] [ 3  1  6  1  1  9  8 10  1 11  1  1  3  8  8  5  3  6  4 12]\n",
      "accuracy: 0.322265625\n",
      "11400 tensor(2.0239)\n",
      "[ 8 11  4 10  5  3  4  4  8 10 10 11  6  4 11  8  4  6  4  3] [ 1  1  4 12  5 10  1 11  8  8  6 11 10  9  1  8  1  6  8  8]\n",
      "[ 8 10  3  3 10 11  8  6 11  4  8  4  8  4 11 10  1  3  4  5] [ 1 10  3  5  3  1  8  8  4  6  1  4  3  3  3  3  1  8 11  7]\n",
      "accuracy: 0.296875\n",
      "11500 tensor(2.2224)\n",
      "[ 6  1  4  1  1  5  3  8  2 12 11  6  8 11  1 11  6  5  1 10] [ 8  1  9  8  1  3  3  6  0  5  6  4  8  4  8  4  3 10  1 10]\n",
      "[ 3  6  3  6  1  8  8 11 11 11 10 10  4 11  9  1 11  4 10  9] [ 3  8 10  9  6  6  8 11  3  1 10  3  3  6  6  3  6  6  6  6]\n",
      "accuracy: 0.302734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11600 tensor(2.1543)\n",
      "[ 1  8  9  1  7  6  6  6  5  6  6  3  1  5  8 10  4  5  8  5] [ 9  1 10  1  7  8  6  6  7  1 11  8  1  3  1  8  6 10  8  7]\n",
      "[12 10  2  5  5 12  8  7  4  5 11  6  1  4  1 10 11  1 10  5] [ 5  3  9  8  5 10 12  0 11  1  1  1  6  4 11  3  3  1 12 10]\n",
      "accuracy: 0.30078125\n",
      "11700 tensor(1.9408)\n",
      "[ 5 11  8 10  4  1  9  1 11  1  5  1  6  1  3 11  5 11  8 11] [ 5  6  8 12  3  1  6  1 11  1  5  8  8  4 10 11 11 11  8  3]\n",
      "[12  3 10 10  1  3  2  3  6  6  4  4  9  1  5  1  3  8  9 10] [ 5 10  3  1 10 10  7  6  6  1 11  1  6  2  5  7  8 10 10  3]\n",
      "accuracy: 0.291015625\n",
      "11800 tensor(2.0800)\n",
      "[ 1  1  1  1  6  5  0  8  1  6  1  3  4 10  4  1  6 12  1  1] [11  3  6  6  6  6 10  3  6 10  1  3 11 10  4  6  1  5  8  6]\n",
      "[ 9  5 11  3 11  6  5  3  6  3  4 10  5  5  6 10  4  5  6  9] [ 5  1 11  3 11  1 10 11  1 10 11  5  5 10 12 10  9  8  6  1]\n",
      "accuracy: 0.337890625\n",
      "11900 tensor(2.0020)\n",
      "[10  6  5  8  6  4  3  8  4  3  5  4  5 11  3  4  9  2  4  1] [12 11  7  8  9  9  8  8  6  3  5  9  5  1  8  4  8  3  6  8]\n",
      "[10  3  3  1  8  8  4  4  6  8 10  4  3  1  1 12  8  3  4 10] [10  5 10  8  3 11  4  4  6  3 10 11  3  1  6  8 10  3  9  2]\n",
      "accuracy: 0.318359375\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "for iteration in range(1):\n",
    "\n",
    "    P_HIDDEN_DIM = max(int(np.random.normal(30, 20)), 5)\n",
    "    M_HIDDEN_DIM = max(int(np.random.normal(30, 20)), 5)\n",
    "    vocab_size = 13\n",
    "    tagset_size = 13\n",
    "    EPS = random.uniform(0.005, 0.15)\n",
    "    ITER = int(random.uniform(300, 1200))\n",
    "    P_EMBEDDING_DIM = vocab_size\n",
    "    M_EMBEDDING_DIM = vocab_size\n",
    "    \n",
    "    P_HIDDEN_DIM = 5\n",
    "    M_HIDDEN_DIM = 5\n",
    "    \n",
    "    \n",
    "    ITER = 12000\n",
    "\n",
    "    print(\"iter: \", ITER, \"  phid: \", P_HIDDEN_DIM, \"  mhid: \", M_HIDDEN_DIM, \"  eps: \", EPS)\n",
    "    newweishts = weightloss(weights, EPS)\n",
    "    model = LSTMTagger(P_EMBEDDING_DIM, M_EMBEDDING_DIM, P_HIDDEN_DIM, M_HIDDEN_DIM, vocab_size, tagset_size, batch_size = batch_size)\n",
    "    loss_function = nn.NLLLoss(weight = newweights[0])\n",
    "    loss_function2 = nn.NLLLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.2)\n",
    "    \n",
    "    for epoch in range(ITER):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "        for i in data_loader:\n",
    "            # Step 1. Remember that Pytorch accumulates gradients.\n",
    "            # We need to clear them out before each instance\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Also, we need to clear out the hidden state of the LSTM,\n",
    "            # detaching it from its history on the last instance.\n",
    "            model.p_hidden = model.init_hidden(P_HIDDEN_DIM)\n",
    "            model.m_hidden = model.init_hidden(M_HIDDEN_DIM)\n",
    "\n",
    "            # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "            # Tensors of word indices.\n",
    "            p, m, l, mask, marr = i['p'], i['m'], i['l'], i['mask'], i['marr']\n",
    "            #print(m)\n",
    "            tag_scores = model(p, m, mask)\n",
    "            # Step 3. Run our forward pass.\n",
    "\n",
    "            # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "            #  calling optimizer.step()\n",
    "            #print(targets[:1])\n",
    "            loss = 0\n",
    "\n",
    "            loss += loss_function(tag_scores[0], torch.t(l)[0])  \n",
    "            loss += 0.25 * loss_function2(tag_scores[1], torch.t(l)[1])\n",
    "            loss += 0.125 * loss_function2(tag_scores[2], torch.t(l)[2])   \n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            break\n",
    "        if(epoch % 100==0): \n",
    "            print(epoch, loss)\n",
    "            accuracy = 0.0\n",
    "            c = 0\n",
    "            for j in range(2):\n",
    "                for i in data_loader:\n",
    "                    c+=1\n",
    "                    p, m, l, mask, marr= i['p'], i['m'], i['l'], i['mask'], i['marr']\n",
    "                    tag_scores = model(p, m, mask)\n",
    "                    pred = tag_scores[0].max(1)[1].numpy()\n",
    "                    truth = torch.t(l)[0].numpy()\n",
    "                    print(pred[:20], truth[:20])\n",
    "                    accuracy += np.average(pred == truth)\n",
    "                    if (c>=1): break\n",
    "            print(\"accuracy:\", accuracy/c)\n",
    "\n",
    "\n",
    "\n",
    "#     for j in range(1):\n",
    "#         for i in data_loader:\n",
    "#             c+=1\n",
    "#             p, m, l, mask = i['p'], i['m'], i['l'], i['mask']\n",
    "#             tag_scores = model(p, m, mask)\n",
    "#             pred = tag_scores[0].max(1)[1].numpy()\n",
    "#             truth = torch.t(l)[0].numpy()\n",
    "#             accuracy += np.average(pred == truth)\n",
    "#             if (c>=1): break\n",
    "#     print(\"accuracy:\", accuracy/c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[ 3 10 10 11  9  4  1  1 10  8  3  5  8 10 11 10 10  4  3 10] [ 1  8  6 11  4  4  1  1  3  8  4  6  8  4  1  0  3  9  1  3]\n",
      "2\n",
      "[10  3 10  3  3 10 10  1  8  1  6  3 12  5  1 10  3  3  1  8] [10  5  5  3  4 10 12  6  1  8  8  3  3 10  8  3  6  7  6  1]\n",
      "3\n",
      "[ 5  1  1  7  5  4 10  1  9  1  8  3  8 10 11 10 10  8 11  5] [ 2  8  8  2 10  8 12  6  2  8  3 10 11  7 11  1  3  9  4  3]\n",
      "4\n",
      "[10  1 10  4  3  5  3  4  8  3 10  5  9  9 10 10  7  1  1  9] [ 1  1  6  1 10  2  8  4 12  3  8 10  9  4  8  8  8  5 10  1]\n",
      "5\n",
      "[ 7  3  1  6  1 10  5  4 11  5  6 10  4  1 10 10  3  8  5  9] [ 5  3  1  1  1 10  5  6 11  6  2  8 11  5  8 10  3  3  8  5]\n",
      "6\n",
      "[ 9  1  1  1  5  3  3  3  4  1  1 10  4  5 11  3 11  1  3 11] [ 4 11  8  4 12  3  3  3  4  8  9  8 11  4  6  6  9  9  8  6]\n",
      "7\n",
      "[12  8  5  5 10  6 10  6 10 10  9  1  3  1  9  8 10 10  2 10] [12  8  9  7 10 11  2 11  5  3  6 10  6  6 11  1  3  7  2 10]\n",
      "8\n",
      "[ 5  3  9  5  1 11  3  3  3  4  4  1  1  9 11  5 10  1  5  3] [10 10 12  3  8 11 10 12  8  4  4 11  1  2  1  6  6  6 10 10]\n",
      "9\n",
      "[10  3  1 10  5  4  8  3  6  3  8  3  3  9  8  1 10  4  8  5] [ 5  1  6 10  1  5  3  3  6 12  8  8  5  2  8  6  3 11 12 12]\n",
      "10\n",
      "[ 5  1  1  3  1  7  3  8  8  1  5  5  8 11 10  5  3  3  5 10] [10  1 10  6  8  5 10  8  1  8 10 10  1 11 10 10  8  3  5  8]\n",
      "11\n",
      "[ 9  3  7  4  1 10  3  8  8  3  5  5  4  1  1  9 11 10 12  3] [10 10  5  6 11  8  3 10  3 10  1 10  4  6  1  6 11  3  3  8]\n",
      "12\n",
      "[ 6  1 11  6 11  3  9  4  3 10  3  5  3  6 10  6  3 10  3 10] [ 8  1 11 10  3  8  6 11  3 10  6  6  3 10  6  1 10  8  8  8]\n",
      "13\n",
      "[ 9  5  6 11  4  4  1  6  3 10  1 10  1  4  1  9  3  1 10  5] [ 2  1  6  7  4  8  8  1  8 10  3  1  8  1  9  9  5 11 10  8]\n",
      "14\n",
      "[ 6  1  6  1  6  6 10  1  8 10  4  1  8  9  5  1  8  5  9  3] [ 3  3  1  6  2  2  1  8  1  5  4  8  8  4  3  1  5 10  9  1]\n",
      "15\n",
      "[10 12  3  6 11  4  1  5  8  1  3  1  8 10  2  3 10 10 11  2] [ 3 12  3  6  1  1 11 10  8 10  8  3  3 10  0  8 10  8  6  4]\n",
      "16\n",
      "[ 5  9  8  3  6  1 11 10  4  5  6  6  6  6  5  1 11 10  3  8] [ 3  3  8 10  6  3  1 10  6 12  3  6 11 11  5  2 11  5 10  1]\n",
      "17\n",
      "[10  6  3  8  1 10  6  5  6  1  3  1  3  4  8  1  6  4  8  6] [ 3 11  3  6  6  8  2 12  6  6  3  1  3  6  4  6  1  1  3  1]\n",
      "18\n",
      "[10  3  8  6  8  3 12  3  1  5 11  4  8  8  4  8  8 10 11  9] [ 5 10  8  1  6  6  9  5  6  2 11  1  1  5  4  3  3  8 11  4]\n",
      "19\n",
      "[10  3  5  1 10 10  1  8  6  1 10  1  1  6  1 10  1  3  3  3] [ 6  5  1  1 10  3  1  1 11  1  3  1  1  1  8  6  8 12  6  3]\n",
      "20\n",
      "[ 5  1  5  5  5  1  9  4  8  3 11  1  1  8  5  1  4  8  1  6] [ 9  6  5 10  8  9  3  6  1  8  6  8  8 12  8  3 11  1  9  2]\n",
      "21\n",
      "[ 3  4  1  3  5  8  5  6  6  6 10  9  1  4  3  1  3  3  5  8] [ 3  4  1  1  1  8 12  1  3  6  5  2  4  6  1  1  3  8  1  6]\n",
      "22\n",
      "[ 3  3  2  1  4  5  9  9  9  1  6  5  5  2 11  3  8  6  1  6] [ 6  5  4  8  4  2  4  1  1  8  1  3  1  1  1  8 11  6  8  6]\n",
      "23\n",
      "[ 3 10 10  1  8  6 11  6  8  3  1  1  6  7  8  1  5  8  5  3] [10 12  5  9  8 11  6  2  8  8 10  1  6  8 10 11  1  1  2  8]\n",
      "24\n",
      "[ 1  5  1  3  4  4  8  2  8 11  5  1  6 10 11  6  1 11  5  9] [ 1  5 12  3  4  6  1  4  3  4  5  8  8 10 11  6  8  3  4  4]\n",
      "25\n",
      "[ 3  5  3  3 11  4  4  3  8  3  9  5 10 10  3  1 11  1  1  7] [ 3  1  8 10  2  4  4  8  3  3  6  4 10 10  7  8  1  8  4  7]\n",
      "26\n",
      "[ 3  4  5  1  1  9  5  3  8  8  4  8  8 10  6  2  4  6  4  5] [11  4 10  1  1 12 12  3  1 11  8  8 11  8  6 12  4  4  4  8]\n",
      "27\n",
      "[ 5 12 12 11  1 11  4  4  1  1  6  5  9 10  9  1 12 11 11  1] [10  8  1  6  6  8  1  8 11  6  6  3  4  8  4  1 10 11  6  1]\n",
      "28\n",
      "[11 10  3  3 10 11  6  6  1  8  3  5  9  8  6 10  9  8 11  1] [11  8 10  6 10  8  6 11  6  1  8 12  1  3  1  8  7  8  5  3]\n",
      "29\n",
      "[ 3 12  5  6  9  9 12  4  1  6  5  9  3 11 10 10  9  6  3 10] [ 3  1  1 11  6 10 10  4  1 11  9  0  3  3  3 10  8  6  8 10]\n",
      "30\n",
      "[ 1  8  5  0 10  5 10  6  1  8  2  8  5  8  1  1  8  3  3 11] [ 6  1 10 12 10  2 10  6  1  8  9  3 12  6  1  1  5  3  8  6]\n",
      "31\n",
      "[ 1  3  1 10  6  3  5 11  9  3  2 10  1  1  6  8  1  5  6  3] [ 8  1  1  3  6  3  6  3  1  9  1  5  4  6 11  1 11  1  3 10]\n",
      "32\n",
      "[ 3  1  5  1  3  8  8  7  2  3  1  9  5  6  4 10 11 10  3  8] [ 1 10 12  6  8  8  6  2  1  1  1 11  8  1  4  8 11  8  9  3]\n",
      "33\n",
      "[ 6  2  1  6  1  6  3  3  6  1  3 10  9  6  6 10  8  9  3  6] [ 1  9 11  1  8  6  8  3 11 11  8  5 11 11  6  8  3  8 10  6]\n",
      "34\n",
      "[ 8  9  3 10  8 11 10  8  1  4  8  5  5 11  6  1 10  6  8 11] [ 1 11 10  3  8 11  8 10  1  1  6  1  6  4  6  8  3  6  8  6]\n",
      "35\n",
      "[ 3 12  1  8 10  4  4  1  1 10  6  1  3  5 11 10  3  9  1  6] [ 3 10  8  1  3 11  6  1  8 10  6  3  3  7 11  5  8  8  6  1]\n",
      "36\n",
      "[ 6 12  4 11  8  3  8  1  8  5  9 11  6  2  6  4  1  1  1  8] [ 1  3  1  3  1  3  3 10  3  7  9  4  1  6  6  9  6  6  4  3]\n",
      "37\n",
      "[ 2  8  1  6 12  8  4  1  1  4  4  8  6 10  8  5  3  7  3  7] [10  3  1  6  5  3 11  1  1  4  9 10  1  5  8 10  3  2  1  6]\n",
      "38\n",
      "[ 5  5  3  1  3  5 11  1 10 10  6  3  4  6  6  3  6  9 12  2] [ 5  2  8  8  3  2 11 10  5  3  6 10  3  6  1 10 11  4  3  1]\n",
      "39\n",
      "[ 8  5  5  4  4  5  3  5  1  3  1  4  1  9  1 10  8  1 12  9] [ 1  8 10 11  4  8  3  4  6  5  8  8  8  4  8  8  1  1  3 11]\n",
      "40\n",
      "[10  5  5  8  8  1  6  5  3  7  1 10 12  6 12  1  5 11  1  9] [1 8 8 8 1 3 1 5 1 6 6 7 9 6 9 6 8 4 1 1]\n",
      "41\n",
      "[10  1  5  2  3  8  3 12  8  6  5 11  2  3 11 10  0 11 10  4] [10  8  5  4  3  6  3  8  1  6  8 11  9  5  6  1 10 11  3  9]\n",
      "42\n",
      "[5 8 5 4 1 5 8 9 1 6 4 9 4 1 3 1 8 3 8 9] [ 1  6  6  1  1  7  1 11  6  3 11  7  8  1 10  6  1  8  1  8]\n",
      "43\n",
      "[ 3 11 10  4 10  5  3  6  3  3  5  3  3  3  1 11  5  6  9 11] [ 3 11  9  8  7  4 10  3 12  3  5 12 10  3  8 11  8 11  4  1]\n",
      "44\n",
      "[ 5  5  8  5  3  8  3 10  5  8  1  3  9  1  6  9  3  1 10  6] [10  5  3 12  6  1 10  8  3  8  9  3  3 11  6  4  6  8  3  8]\n",
      "45\n",
      "[ 8 10  3 10  3  3 10  3 11 10  8 10  9  1  1  8 10  2 12  3] [12 10 10  1  1  3  1  3  6  6  3  8  8  1  8  3  6  3 10  8]\n",
      "46\n",
      "[10  6  1  2  1 10  1  1  6 10 10  8 11  6 11  4  8 12  2 10] [ 1 11  8  2 10  3 11  6  1  6  1 11  1  8 11 11  1  9  7 10]\n",
      "47\n",
      "[11  5  1  3  1  1  8 11  1  1  3  2  4  1  8  2 10  5  5  8] [ 4  5  3  1  8  6  8 11  6  3 12  4 11  1  1  2  5  5 10  8]\n",
      "48\n",
      "[ 3 10  1  8  3 11  9  8  1  5  3  4  3  8 11  8  1  2 10 10] [11  3  1  3  3  1  9  1  6  7 10  6  3  6  6  3  6  2  8  8]\n",
      "49\n",
      "[ 8 12  8  6  8  8 11  4  8  9  6  3  1  6  1  9 11  9  3  1] [ 3 11  8 11  6  5 11  6  3 11  6  3  6 11  7  9  1  8  5  1]\n",
      "50\n",
      "[ 1  9 10  4  1 10  1 11  5  8  1  5 11  7 10  6  1  5  1 10] [ 6 12  8 11  6  8  3 11  5  8  1  8  6 10  5 11  1  5  6 10]\n",
      "51\n",
      "[ 8  5  5  6  1  4 12  9  8  5 10  1  4  7 11  8 10  1  3  6] [ 4  1 12  6  3 11  9  9  8  8  3  1  1 12 11 10  6  6  6 11]\n",
      "52\n",
      "[ 3  1  5  6  1  4 12  9  1 10  3  3  8  9  1  6  5  6  3  6] [10  1  5  3  6  8  2  8  6  7 12 11  8  4  8  6  5  6  8  1]\n",
      "53\n",
      "[ 1  8  4  1  5  3 12 11  6  5  4  3  4  6  1  3  8  5 10  6] [ 1  8  6  4 10  3  2  8  6  2  8  3  6  1  3  1  5  8 12  1]\n",
      "54\n",
      "[ 5  1  6  3 10  8  3  8  1 10  1  1  3  1  1  8 10 10  3 10] [ 9  1  1  8  3  1  1  3  1  6  0  3 10  1  1  8  3 10  8 10]\n",
      "55\n",
      "[10  3 10 11  1 10 10  1  1 10  8  3  6  4  1  4  5  1  5  1] [ 3  8 10 11 12  3  3  8  1 10  8  5  6  8  1  8  6  4  3  8]\n",
      "56\n",
      "[ 3  5  1  3 10  1 10  4  3 11  8  6  1 11 10 12  1  8  4 12] [ 6  2  6  8  1  8  3  8 10  8  8  9  1  5  2  2  1  8  5  3]\n",
      "57\n",
      "[ 3 10 10  1  3  8 10  8  1  4  4  5 10  8  9  5 10 10  9  3] [ 1 10  5  8 10  1  1  8 11  9  9 10 12  8  4  8  5  6  4  8]\n",
      "58\n",
      "[ 1  5  9  6  3 10  6  8  5  1  2  3  3  1  3  5  5  2 12 12] [ 3 12 12  8 10 10  8  8  5  6  3 11  5  8  3  8  5 11 10 10]\n",
      "59\n",
      "[10  8  4  1 10  7  4  1  1  8  4  5  8  5  4  9  1  3  9 10] [ 5  1  8  3  5  6  5  8 11  8 10 10  1  5 11 11  1  3  1  7]\n",
      "60\n",
      "[ 9 10  1  9 10  3  3 11  3  4  1  4 12  9  1  8  6  1 10  5] [ 1  8  8  4  8  8  3 11 10  9  3  6  9  2 10  8  1  6 10  2]\n",
      "61\n",
      "[ 6  3  5  4  9  1 12  1  3  6  9  2  5  6  9  4  6  6  6  4] [ 1 12  0  6  9  9  9  8  8  1  8 10  1  1  9  1 10 10 11  9]\n",
      "62\n",
      "[11  0  5  3 10  4 11 11  1  3 10  4 10 12  3  3  4  1 10  3] [ 8 10 10  3  6  6 11 10  1  8  1  3  1  3  1 10  8  1  5  5]\n",
      "63\n",
      "[ 3 10  8 11  3  1  6  6  1 12  1  6  8 10  9  8 11  8  3  9] [10  3 10  1  3  1 12  6 11 12 10  3  8  6  3  1  3  1  1  9]\n",
      "64\n",
      "[ 8  1  5  3  5  0  2  4  6  2 11  8  1  4 10  7  8  8  6  3] [10  9  5  8  3  1  4  9  6  3  6 10  1  8 11  6  3  1  6 10]\n",
      "65\n",
      "[ 6  5  5 12  5  5  6  5 11  3  8 12  1  3  8  1  8 10  5  5] [ 1  5  1 11  5  8  6 12 11  6  3 10  8  8  5  1  3  1 10  5]\n",
      "66\n",
      "[ 5 10  1  8  7  1 10  7 11  2 10  5  6  5  9  5  1  1  9  1] [ 5  1  4  8  2  6  1  5 11  2  5  1 11  5 10  4  8  6  4 11]\n",
      "67\n",
      "[10 10  9  3  6  7  5  7  5  6 10  6  6  2  8  1  3 10 11  8] [ 3 12  8  3  7  1  2  1 10  5 10  1  2  9  8  6  3  3  6  1]\n",
      "68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5  4  3  8  3 10 10  8  3  4 10 10 11  6  4  1  6 10 12  5] [ 2  6  3  8  3  8  6  6  1  4  1  8  6  6  4  5  1  8  2 10]\n",
      "69\n",
      "[ 5  1 12  1  1 11  8  5 10  6  8  1  2  6 11  8  3  5  3  9] [10  1  2  4  6  4  8  1  5 10  1 11  8  6  4  9 10  8  3  6]\n",
      "70\n",
      "[ 5  3  7 10  1  1  5 10 10  4  1  1  4  3 10  8  9 10  5 10] [ 8  9 11  0  6 12  9  3 10  4  6  8  6  8  5 10  4  8  5  3]\n",
      "71\n",
      "[ 8  3  1 10  3 10 10  5  1  1  1  3  6  3  1  8  6  1  1  6] [ 1  8  6  8  3 10  8 11  1  1  1  8  7  8 11  8 10 11  6  6]\n",
      "72\n",
      "[ 5  1  6  1  3 10 10  1  0  6  8  7  1  1  3 10  4  8  3  3] [ 5  6 11  8  8  1  3  1  4  8  5  7 11  6 10  5  1  6  8 10]\n",
      "73\n",
      "[10  6 10  1 10 10  5  1  8  1  9  1 11  1  5 12  3  8  8  4] [ 1  8 10  1  3 10 11 11  1  6  8 10 11  1  9  2  3  3 10  1]\n",
      "74\n",
      "[ 9  4 10  3  5  1 10  4  5  3  2  8 11  6  5  3  3 10  8  1] [ 9  6  5  8  7  6  5  6 10  3  3  8  6  6  5  8  5 12  8  8]\n",
      "75\n",
      "[ 4 11  3  1  1  3  3  8  1 10  9  0  3  3 11  1  6  5  4  6] [ 9 11 12  6  6  8 11 11 10  8  8  4 12  3  8  6  6  5 11 11]\n",
      "76\n",
      "[ 8  4 10  1  1  1  8  1  1  6  8  6 10  9  3  9 11  5  4  3] [ 1  3  3  3  8 10  3  1  1 11  3  1  5  9  3  6  4  8  9  1]\n",
      "77\n",
      "[ 0  1  5  1  1  3 10  1  3 10  5 10  3  6  8  4  1  1  9  4] [ 1  1 10  1  3  2  1  8  8  3  1 10  5  6  1  1  8  6 11  4]\n",
      "78\n",
      "[ 3  1 10  3  8 12  1  6  3  1  3  1  9  6  1  1  6 10 10  4] [ 1  4  8  3  8  7  1  9  5  6  3 11  2  6  6  1  1  3  3  9]\n",
      "79\n",
      "[ 2  3  4  4 11 11  1  5  1  5  7  1  2  4  1  4  4  9  1  5] [ 5  8  6  4  6  6  1 10 11 10  4  3  5  9  1  6  4  3 10 12]\n",
      "80\n",
      "[ 5 10  3  4  1 11  8  9  9  9 10  5  3 10 11 11  9  8 10 10] [10  3  5  4 10  6  1  9  9  1  1 12  3  8  2  8  8  8 10  1]\n",
      "81\n",
      "[ 1  1  6 10 11 10  5 10  9  6  2  2  3  4  8  1 11  8  9  3] [ 3  8 11 10  1 10  3 10  2  8  1  9  8  4 10 11  1  8  6  5]\n",
      "82\n",
      "[ 1  5  1 11  3  4  3  4  4  4  5  5  5  1  3  6  8  5  9  9] [ 6  7 11  1 10  4  6  4  8  9  5  3  8  5  3  1  8  2 11  9]\n",
      "83\n",
      "[10  6  9 10  1  9 10 11  1  6  5  1  1  6  6  5  9  3  6 10] [12  1  4  3 11  6 10  6  8  8 10  3  6  6  1 12  1 10  6  8]\n",
      "84\n",
      "[ 1 10  6  1  9  1  1  8  4  3  3  4  4  6 10 10  4  5  3  3] [ 8  5  6  5  2  3 10  1 11  3  1 11  6  1  3  1  8  5  8  3]\n",
      "85\n",
      "[ 9 10  1  5  9  3  5  3  9  1  6  3  9  1  9 11  5  3  1  4] [ 2  3  3 10 11  8  5  8  8 10  8  7  8  1  1  1 10  3  4  8]\n",
      "86\n",
      "[10  8  5  3  4  3  5 12  1  5  5  8  2  5  6  4  4 10  1  6] [ 5  1  5  8 11  8  5 12  1  5  8  3 11  5  2 11 11 10  6  6]\n",
      "87\n",
      "[ 3  1 10  5  6  1  8  3  6 10  3 10  8  9 10 11  4  3  3  7] [ 8  8  3  1  2  3  8  9  8  3  6  1  8 11  3  1  4  8  6  5]\n",
      "88\n",
      "[ 8 10 11  4 10  4 10  3  1  6  7 12  3  8  1 11  9 10  4 10] [12  6  4  4  8  4  3  3 11  1  7  7  3  1  6  1  7  4 11  6]\n",
      "89\n",
      "[ 5  8  6  3  3 10  1  1  6  8  2  8  4  3  6  6 11  6 10  6] [ 1  8  1  3 10 11  3  6 11  8  5  1  6  6  1  6 11  8 10 11]\n",
      "90\n",
      "[ 3  8  6  4 10  4  4  8  6  1  5  2  6 10  8  1  6  1  3  5] [ 5 12  3  9  3  4 10  8  8 10 10  5  6  8  8 10  6  8  8 12]\n",
      "91\n",
      "[ 3  3  3  6 10  3 11  5  4  6  6  3  3  1  1  5  6  3 10  4] [ 3  1  5  1  3  1  8  1  4  6  1  8  8  6  6 10  5  3 10  8]\n",
      "92\n",
      "[ 5  1 10 10  3  1  3  1  4  4  9  1  1  1  3  8 11  9  4  4] [ 1  1  7  5  3  8  0  6  8  8  4  6  1 10  5 10  6  9  9  8]\n",
      "93\n",
      "[ 5  4  8 10  5  6  1  1 10 10  1  9  6  4  4  1  3  6  5 10] [ 8  4  6 10 10  6  6  8  8  5  1  6  1  4  4  6  8  6 12  3]\n",
      "94\n",
      "[ 3  1  1  6  1 11  6  3  6  8 10  1  6  4  1  3  5  8 10 11] [ 1  3  1  1  1 11  6  3  8  1  5  1 11  8  6 10 12  5  3  6]\n",
      "95\n",
      "[ 3 10 10 11  3  2 11 10  1  1  6  5  3  8  1  5  6  5 10  3] [ 3  6  3  6  1 11  1  5  8  9  6  3 10  8  1  4 10  5  3  3]\n",
      "96\n",
      "[ 1  4  1  8  1  6  8  1  9 10  4  1 10  4  5  3 10  9 10  3] [ 1  9  6  8  6  1  8  1  2 10 11  6  3  4 10  8  1  4  1  5]\n",
      "97\n",
      "[10  8  6  4  6  6 10  5  8  5  6  5  7  4  2  4  1 11  9  1] [10  1  6  4  6 11  3  3  8 12  6  5  0  3  7 10  6  6  9  6]\n",
      "98\n",
      "[10  3  3  3  1 10  1  5  5  2  6  3  4  1 10  9 10 11  8  9] [ 5 10  3  8  1  5 11 11  5  8  6  8  4 11  1 11 12 11  5 11]\n",
      "99\n",
      "[ 5 10  9  8  5  1  3 10  3 10  8 10 10 10  3  4  5  6 10 11] [ 8  1  4 12  7  3  3 10  1  3  1 10  7  8  6 10  5 11  5  3]\n",
      "100\n",
      "[11  1  2  1  9  1  3  3 10 11  6 10 11  3  3  2  1  6  5 10] [ 4  1  9 11  1  1  8  1  1  4 11  6  6  8  8  7  6  8  5  5]\n",
      "accuracy: 0.2982421875\n"
     ]
    }
   ],
   "source": [
    "    accuracy = 0.0\n",
    "    c = 0\n",
    "    for j in range(100):\n",
    "        for i in data_loader:\n",
    "            c+=1\n",
    "            print(c)\n",
    "            p, m, l, mask, marr = i['p'], i['m'], i['l'], i['mask'], i['marr']\n",
    "            tag_scores = model(p, m, mask)\n",
    "            pred = tag_scores[0].max(1)[1].numpy()\n",
    "            truth = torch.t(l)[0].numpy()\n",
    "            print(pred[:20], truth[:20])\n",
    "            accuracy += np.average(pred == truth)\n",
    "            if (c>=1): break\n",
    "    print(\"accuracy:\", accuracy/c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model:\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
