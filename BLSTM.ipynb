{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fc99f90f4f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Author: Yulou Zhou\n",
    "#Weight loss function by commonality (and normalize)\n",
    "#padded sequence\n",
    "#for loop to test parameters\n",
    "#for loop to get prev generated chord\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import csv\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from random import shuffle\n",
    "from MyDataset import MyDataset\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p:  tensor([[  5,   4,   7,  ...,  10,   3,   7],\n",
      "        [  6,   4,   7,  ...,   2,   4,   7],\n",
      "        [  6,   4,   7,  ...,   6,   4,   7],\n",
      "        ...,\n",
      "        [  3,   4,   7,  ...,   2,   4,   7],\n",
      "        [  8,   4,   7,  ...,  11,   4,   7],\n",
      "        [  6,   4,   7,  ...,   6,   4,   7]])\n",
      "m:  tensor([[ 10,  10,  10,  ...,   5,  10,   0],\n",
      "        [ 12,  12,  12,  ...,  11,  12,  12],\n",
      "        [ 10,  10,  10,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [  3,   3,   3,  ...,   7,   7,   7],\n",
      "        [ 11,  11,  11,  ...,   4,   5,   5],\n",
      "        [  6,   6,   6,  ...,   6,   6,   6]])\n",
      "l:  tensor([[  5,   4,   7],\n",
      "        [  6,   4,   7],\n",
      "        [  8,   4,   7],\n",
      "        ...,\n",
      "        [  7,   3,   7],\n",
      "        [ 11,   4,   7],\n",
      "        [  8,   4,   7]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 512\n",
    "train_data = MyDataset('relativedata', prevchord = 4)\n",
    "weights = train_data.stats()\n",
    "data_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "c=0\n",
    "for i in data_loader:\n",
    "    print(\"p: \", i['p'])\n",
    "    print(\"m: \", i['m'])\n",
    "    #print(\"mask: \", i['mask'])\n",
    "    print(\"l: \", i['l'])\n",
    "    c += 10\n",
    "    if c > 0: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(array):\n",
    "    return [i / sum(array) for i in array]\n",
    "newweights = []\n",
    "\n",
    "def weightloss(weights, eps):\n",
    "    for w in weights:\n",
    "        newweights.append(torch.FloatTensor( normalize([1/(i + eps) for i in w] ) ) )\n",
    "    print(newweights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:  899 \n",
      "p_hidden:  5 \n",
      "m_hidden:  12 \n",
      "eps:  0.11952454786939987\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "P_HIDDEN_DIM = max(int(np.random.normal(30, 30)), 5)\n",
    "M_HIDDEN_DIM = max(int(np.random.normal(30, 30)), 5)\n",
    "vocab_size = 13\n",
    "tagset_size = 13\n",
    "EPS = random.uniform(0.005, 0.15)\n",
    "ITER = int(random.uniform(300, 1200))\n",
    "P_EMBEDDING_DIM = vocab_size\n",
    "M_EMBEDDING_DIM = vocab_size\n",
    "\n",
    "print(\"iter: \", ITER, \"\\np_hidden: \", P_HIDDEN_DIM, \"\\nm_hidden: \", M_HIDDEN_DIM, \"\\neps: \", EPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([ 0.1260,  0.0383,  0.1074,  0.0512,  0.0763,  0.0788,  0.0444,\n",
      "         0.1133,  0.0418,  0.0943,  0.0625,  0.0634,  0.1023]), tensor(1.00000e-02 *\n",
      "       [ 8.4591,  8.9562,  8.8371,  2.1137,  0.8178,  8.2792,  8.9562,\n",
      "         8.7996,  8.9562,  8.9562,  8.9562,  8.9562,  8.9562]), tensor(1.00000e-02 *\n",
      "       [ 8.1017,  8.7219,  8.7219,  8.6396,  8.7219,  8.7203,  6.8681,\n",
      "         0.6410,  8.0734,  6.6244,  8.7219,  8.7219,  8.7219]), tensor([ 0.1260,  0.0383,  0.1074,  0.0512,  0.0763,  0.0788,  0.0444,\n",
      "         0.1133,  0.0418,  0.0943,  0.0625,  0.0634,  0.1023]), tensor(1.00000e-02 *\n",
      "       [ 8.4591,  8.9562,  8.8371,  2.1137,  0.8178,  8.2792,  8.9562,\n",
      "         8.7996,  8.9562,  8.9562,  8.9562,  8.9562,  8.9562]), tensor(1.00000e-02 *\n",
      "       [ 8.1017,  8.7219,  8.7219,  8.6396,  8.7219,  8.7203,  6.8681,\n",
      "         0.6410,  8.0734,  6.6244,  8.7219,  8.7219,  8.7219]), tensor([ 0.1113,  0.0451,  0.1001,  0.0575,  0.0785,  0.0804,  0.0510,\n",
      "         0.1038,  0.0486,  0.0915,  0.0674,  0.0681,  0.0969]), tensor(1.00000e-02 *\n",
      "       [ 8.4866,  8.7989,  8.7253,  2.9066,  1.2167,  8.3703,  8.7989,\n",
      "         8.7020,  8.7989,  8.7989,  8.7989,  8.7989,  8.7989]), tensor(1.00000e-02 *\n",
      "       [ 8.1541,  8.5451,  8.5451,  8.4944,  8.5451,  8.5441,  7.3095,\n",
      "         0.9607,  8.1358,  7.1311,  8.5451,  8.5451,  8.5451])]\n"
     ]
    }
   ],
   "source": [
    "newweishts = weightloss(weights, EPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, p_embed_dim, m_embed_dim, p_hidden_dim, m_hidden_dim, vocab_size, tagset_size, batch_size = 1):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.p_embed_dim, self.m_embed_dim = p_embed_dim, m_embed_dim\n",
    "        #refer to https://discuss.pytorch.org/t/can-we-use-pre-trained-word-embeddings-for-weight-initialization-in-nn-embedding/1222/2\n",
    "        \n",
    "        self.p_embed = nn.Embedding(vocab_size, p_embed_dim)\n",
    "        self.m_embed = nn.Embedding(vocab_size, m_embed_dim)\n",
    "        self.p_embed.weight.data.copy_(torch.from_numpy(np.identity(vocab_size)))\n",
    "        self.m_embed.weight.data.copy_(torch.from_numpy(np.identity(vocab_size)))\n",
    "        \n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.p_lstm = nn.LSTM(p_embed_dim, p_hidden_dim, bidirectional = True)\n",
    "        self.m_lstm = nn.LSTM(m_embed_dim, m_hidden_dim, bidirectional = True)\n",
    "        \n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = nn.Linear((p_hidden_dim + m_hidden_dim) * 2, tagset_size)\n",
    "        self.root2second = nn.Linear((p_hidden_dim + m_hidden_dim) * 2 + 1, tagset_size)\n",
    "        self.root2third = nn.Linear((p_hidden_dim + m_hidden_dim) * 2 + 1, tagset_size)\n",
    "        \n",
    "        self.p_hidden = self.init_hidden(p_hidden_dim)\n",
    "        self.m_hidden = self.init_hidden(m_hidden_dim)\n",
    "\n",
    "    def init_one_hot(self, vocab_size):\n",
    "        #initialize each embedding\n",
    "        #stack them together (or other ways to have  pretrained embeddings)\n",
    "        #pretrained_weight is a numpy matrix of shape (num_embeddings, embedding_dim)\n",
    "        #we should turn data into torch.from_numpy(pretrained_weight)\n",
    "        #embed.weight.data.copy_(torch.from_numpy(pretrained_weight))\n",
    "        \n",
    "        torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "        \n",
    "    \n",
    "    def init_hidden(self, hidden_dim):\n",
    "        # The axes semantics are (num_layers, minibatch_size, hidden_dim)\n",
    "        return (torch.zeros(2, self.batch_size, hidden_dim),\n",
    "                torch.zeros(2, self.batch_size, hidden_dim))\n",
    "\n",
    "    def forward(self, prev, melody, mask):\n",
    "        \n",
    "        prev_embeds = self.p_embed(prev)\n",
    "        x1 = torch.transpose(prev_embeds, 0, 1) #TODO: DEBUG THIS LINE (probably the last batch)\n",
    "        \n",
    "        #TODO: ensure that melody input is a tensor\n",
    "        \n",
    "        melody_embeds =  self.m_embed(melody) #Error here\n",
    "        x2 = torch.transpose(melody_embeds, 0, 1)\n",
    "        \n",
    "        p_lstm_out, self.p_hidden = self.p_lstm(x1, self.p_hidden)\n",
    "        m_lstm_out, self.m_hidden = self.m_lstm(x2, self.m_hidden)      \n",
    "        \n",
    "        p_fstate, m_fstate = p_lstm_out[-1], m_lstm_out[-1]\n",
    "        \n",
    "\n",
    "        concat = torch.cat((p_fstate, m_fstate), 1)\n",
    "        #print(p_fstate.size(), m_fstate.size())\n",
    "        tag_space = self.hidden2tag(concat) #REASON: you only need the final state\n",
    "        tag_scores = F.log_softmax(tag_space, dim = 1)\n",
    "        \n",
    "\n",
    "        withroot = torch.cat((concat, tag_scores.max(1)[1].float().view(-1,1)), 1)\n",
    "        second = self.root2second(withroot)\n",
    "        third = self.root2third(withroot)\n",
    "        second_scores = F.log_softmax(second, dim=1)\n",
    "        third_scores = F.log_softmax(third, dim=1)\n",
    "        \n",
    "        #stacked = torch.stack([tag_scores, second_scores, third_scores], dim=0)\n",
    "\n",
    "        return [tag_scores, second_scores, third_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMTagger(P_EMBEDDING_DIM, M_EMBEDDING_DIM, P_HIDDEN_DIM, M_HIDDEN_DIM, vocab_size, tagset_size, batch_size = batch_size)\n",
    "loss_function = nn.NLLLoss(weight = newweights[0])\n",
    "loss_function2 = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p, m, l tensor([[  0,   0,   0,  ...,   6,   4,   7],\n",
      "        [  3,   3,   7,  ...,   6,   4,   7],\n",
      "        [  7,   3,   6,  ...,  10,   3,   7],\n",
      "        ...,\n",
      "        [  6,   4,   7,  ...,   6,   4,   7],\n",
      "        [  0,   0,   0,  ...,   0,   0,   0],\n",
      "        [  6,   4,   7,  ...,   1,   4,   7]]) tensor([[ 10,  10,  10,  ...,  10,  10,  10],\n",
      "        [ 10,  10,  10,  ...,  10,   8,   8],\n",
      "        [  1,   1,   5,  ...,   8,   8,   8],\n",
      "        ...,\n",
      "        [  1,   1,   1,  ...,   3,  12,   0],\n",
      "        [  5,   5,   5,  ...,   0,   0,   0],\n",
      "        [ 10,  10,  10,  ...,  10,  10,  10]]) tensor([[  6,   4,   7],\n",
      "        [  6,   4,   7],\n",
      "        [  1,   3,   7],\n",
      "        ...,\n",
      "        [  1,   4,   7],\n",
      "        [  8,   4,   7],\n",
      "        [  6,   4,   7]])\n",
      "[tensor([[-2.5995, -2.4621, -2.5250,  ..., -2.4252, -2.5726, -2.4456],\n",
      "        [-2.6300, -2.4583, -2.5141,  ..., -2.4175, -2.5739, -2.4414],\n",
      "        [-2.6276, -2.4678, -2.4993,  ..., -2.4233, -2.5599, -2.4470],\n",
      "        ...,\n",
      "        [-2.6337, -2.4548, -2.4992,  ..., -2.4524, -2.5251, -2.4461],\n",
      "        [-2.6215, -2.4714, -2.5748,  ..., -2.5600, -2.4437, -2.3867],\n",
      "        [-2.5992, -2.4694, -2.5290,  ..., -2.4306, -2.5649, -2.4434]]), tensor([[-3.7965, -2.9406, -3.6724,  ..., -2.9125, -1.8377, -2.8800],\n",
      "        [-3.7879, -2.9406, -3.6676,  ..., -2.9196, -1.8475, -2.8844],\n",
      "        [-3.7964, -2.9372, -3.6888,  ..., -2.9453, -1.8498, -2.8960],\n",
      "        ...,\n",
      "        [-4.1919, -3.1015, -3.9511,  ..., -3.0304, -1.8357, -3.0626],\n",
      "        [-4.2886, -3.1503, -3.9910,  ..., -3.0447, -1.7149, -3.0750],\n",
      "        [-2.7799, -2.5536, -2.9077,  ..., -2.6704, -2.0971, -2.4891]]), tensor([[-1.9691, -3.8301, -2.2670,  ..., -3.8292, -3.4973, -1.8308],\n",
      "        [-1.9863, -3.8493, -2.2955,  ..., -3.8717, -3.4940, -1.7830],\n",
      "        [-1.9905, -3.8675, -2.3107,  ..., -3.8610, -3.4882, -1.7607],\n",
      "        ...,\n",
      "        [-2.0018, -4.1101, -2.3024,  ..., -4.1854, -3.8127, -1.6853],\n",
      "        [-1.9935, -4.1040, -2.3361,  ..., -4.2340, -3.8386, -1.6328],\n",
      "        [-2.2092, -2.9104, -2.3417,  ..., -2.8481, -2.6599, -2.3156]])]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i in data_loader:\n",
    "        p, m, l, mask = i['p'], i['m'], i['l'], i['mask']\n",
    "        print(\"p, m, l\", p, m, l)\n",
    "        tag_scores = model(p, m, mask)\n",
    "        print(tag_scores)\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(4.2945)\n",
      "10 tensor(3.6387)\n",
      "20 tensor(3.2862)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-fa46db49fbf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m0.25\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mloss_function2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlu/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlu/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(ITER):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    for i in data_loader:\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Also, we need to clear out the hidden state of the LSTM,\n",
    "        # detaching it from its history on the last instance.\n",
    "        model.p_hidden = model.init_hidden(P_HIDDEN_DIM)\n",
    "        model.m_hidden = model.init_hidden(M_HIDDEN_DIM)\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "        # Tensors of word indices.\n",
    "        p, m, l, mask = i['p'], i['m'], i['l'], i['mask']\n",
    "        #print(m)\n",
    "        tag_scores = model(p, m, mask)\n",
    "        # Step 3. Run our forward pass.\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        #print(targets[:1])\n",
    "        loss = 0\n",
    "        \n",
    "        loss += loss_function(tag_scores[0], torch.t(l)[0])  \n",
    "        loss += 0.5 * loss_function2(tag_scores[1], torch.t(l)[1])\n",
    "        loss += 0.25 * loss_function2(tag_scores[2], torch.t(l)[2])   \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        break\n",
    "    if(epoch % 10==0): print(epoch, loss)\n",
    "\n",
    "accuracy = 0.0\n",
    "c = 0\n",
    "#print(\"new\")\n",
    "for j in range(100):\n",
    "    for i in data_loader:\n",
    "        c+=1\n",
    "        p, m, l, mask = i['p'], i['m'], i['l'], i['mask']\n",
    "        tag_scores = model(p, m, mask)\n",
    "        #print(tag_scores[0].size())\n",
    "        pred = tag_scores[0].max(1)[1].numpy()\n",
    "        truth = torch.t(l)[0].numpy()\n",
    "        #print((3 == truth))\n",
    "        #print(pred[30:50], truth[30:50])\n",
    "        accuracy += np.average(pred == truth)\n",
    "        if (c>=1): break\n",
    "print(accuracy/c)\n",
    "\n",
    "\n",
    "# See what the scores are after training\n",
    "# with torch.no_grad():\n",
    "#     inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "#     tag_scores = model(inputs)\n",
    "\n",
    "#     # The sentence is \"the dog ate the apple\".  i,j corresponds to score for tag j\n",
    "#     # for word i. The predicted tag is the maximum scoring tag.\n",
    "#     # Here, we can see the predicted sequence below is 0 1 2 0 1\n",
    "#     # since 0 is index of the maximum value of row 1,\n",
    "#     # 1 is the index of maximum value of row 2, etc.\n",
    "#     # Which is DET NOUN VERB DET NOUN, the correct sequence!\n",
    "#     _, point2 = tag_scores.max(1)\n",
    "#     print(point2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 0.0\n",
    "c = 0\n",
    "#print(\"new\")\n",
    "for j in range(100):\n",
    "    for i in data_loader:\n",
    "        c+=1\n",
    "        p, m, l, mask = i['p'], i['m'], i['l'], i['mask']\n",
    "        tag_scores = model(p, m, mask)\n",
    "        #print(tag_scores[0].size())\n",
    "        pred = tag_scores[0].max(1)[1].numpy()\n",
    "        truth = torch.t(l)[0].numpy()\n",
    "        #print((3 == truth))\n",
    "        #print(pred[30:50], truth[30:50])\n",
    "        accuracy += np.average(pred == truth)\n",
    "        if (c>=1): break\n",
    "print(accuracy/c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
