{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f1eba03f490>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Author: Yulou Zhou\n",
    "#Weight loss function by commonality (and normalize)\n",
    "#padded sequence\n",
    "#for loop to test parameters\n",
    "#for loop to get prev generated chord\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import csv\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from random import shuffle\n",
    "from MyDataset import MyDataset\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import dataloader\n",
    "def collate_fn(batch):\n",
    "    batch.sort(key=lambda x: x['mask'], reverse=True)\n",
    "    #for i in batch:\n",
    "        #print(i['mask'])\n",
    "    return dataloader.default_collate(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "train_data = MyDataset('relativedata', prevchord = 8)\n",
    "weights = train_data.stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p:  tensor([[  0,   0,   0,  ...,   3,   4,   7],\n",
      "        [  4,   4,   7,  ...,   8,   3,   6],\n",
      "        [ 10,   3,   7,  ...,   6,   4,   7],\n",
      "        ...,\n",
      "        [  0,   0,   0,  ...,   0,   0,   0],\n",
      "        [  1,   4,   7,  ...,  10,   3,   7],\n",
      "        [  6,   3,   6,  ...,   7,   4,   7]])\n",
      "m:  tensor([[  0,   0,   0,  ...,   0,   0,   0],\n",
      "        [  1,   1,   1,  ...,   0,   0,   0],\n",
      "        [  6,  10,   6,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [  1,   3,   6,  ...,   0,   0,   0],\n",
      "        [  1,   0,   3,  ...,   0,   0,   0],\n",
      "        [  4,   6,   4,  ...,   0,   0,   0]])\n",
      "marr:  tensor([[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]], dtype=torch.float64)\n",
      "l:  tensor([[  3,   4,   7],\n",
      "        [  1,   4,   7],\n",
      "        [ 10,   3,   7],\n",
      "        ...,\n",
      "        [  8,   3,   6],\n",
      "        [  1,   4,   7],\n",
      "        [  6,   4,   7]])\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn = collate_fn)\n",
    "c=0\n",
    "for i in data_loader:\n",
    "    print(\"p: \", i['p'])\n",
    "    print(\"m: \", i['m'])\n",
    "    print(\"marr: \", i['marr'])\n",
    "    print(\"l: \", i['l'])\n",
    "    c += 10\n",
    "    if c > 0: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(array):\n",
    "    return [i / sum(array) for i in array]\n",
    "newweights = []\n",
    "\n",
    "def weightloss(weights, eps):\n",
    "    for w in weights:\n",
    "        newweights.append(torch.FloatTensor( normalize([1/(i + eps) for i in w] ) ) )\n",
    "    #print(newweights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, p_embed_dim, m_embed_dim, p_hidden_dim, m_hidden_dim, vocab_size, tagset_size, batch_size = 1):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.p_embed_dim, self.m_embed_dim = p_embed_dim, m_embed_dim\n",
    "        \n",
    "        self.p_embed = nn.Embedding(vocab_size, p_embed_dim)\n",
    "        self.m_embed = nn.Embedding(vocab_size, m_embed_dim)\n",
    "        self.p_embed.weight.data.copy_(torch.from_numpy(np.identity(vocab_size)))\n",
    "        self.m_embed.weight.data.copy_(torch.from_numpy(np.identity(vocab_size)))\n",
    "        \n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.p_lstm = nn.LSTM(p_embed_dim, p_hidden_dim, bidirectional = False)\n",
    "        self.m_lstm = nn.LSTM(m_embed_dim, m_hidden_dim, bidirectional = False)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = nn.Linear((p_hidden_dim + m_hidden_dim) , tagset_size)\n",
    "        self.root2second = nn.Linear((p_hidden_dim + m_hidden_dim) + 1, tagset_size)\n",
    "        self.root2third = nn.Linear((p_hidden_dim + m_hidden_dim) + 1, tagset_size)\n",
    "        \n",
    "        self.p_hidden = self.init_hidden(p_hidden_dim)\n",
    "        self.m_hidden = self.init_hidden(m_hidden_dim)\n",
    "\n",
    "    def init_one_hot(self, vocab_size):\n",
    "        #initialize each embedding\n",
    "        #stack them together (or other ways to have  pretrained embeddings)\n",
    "        #pretrained_weight is a numpy matrix of shape (num_embeddings, embedding_dim)\n",
    "        #we should turn data into torch.from_numpy(pretrained_weight)\n",
    "        #embed.weight.data.copy_(torch.from_numpy(pretrained_weight))\n",
    "        \n",
    "        torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "        \n",
    "    \n",
    "    def init_hidden(self, hidden_dim):\n",
    "        # The axes semantics are (num_layers, minibatch_size, hidden_dim)\n",
    "        return (torch.zeros(1, self.batch_size, hidden_dim),\n",
    "                torch.zeros(1, self.batch_size, hidden_dim))\n",
    "\n",
    "\n",
    "    def forward(self, prev, melody, mask):\n",
    "        \n",
    "        prev_embeds = self.p_embed(prev)\n",
    "        x1 = torch.transpose(prev_embeds, 0, 1) \n",
    "        \n",
    "        #TODO: ensure that melody input is a tensor\n",
    "        \n",
    "        melody_embeds =  self.m_embed(melody) #Error here\n",
    "        x2 = torch.transpose(melody_embeds, 0, 1)\n",
    "        packed = pack_padded_sequence(x2, mask, batch_first=False)\n",
    "        \n",
    "        p_lstm_out, self.p_hidden = self.p_lstm(x1, self.p_hidden)\n",
    "        m_lstm_out, self.m_hidden = self.m_lstm(packed, self.m_hidden)\n",
    "        (h_t, c_t) = self.m_hidden\n",
    "        out_unpacked, _ = pad_packed_sequence(m_lstm_out, batch_first=False)\n",
    "        #print(out_unpacked[-1], h_t[0])\n",
    "        p_fstate, m_fstate = p_lstm_out[-1], h_t[0]\n",
    "\n",
    "        \n",
    "        concat = torch.cat((p_fstate, m_fstate), 1)\n",
    "        tag_space = self.hidden2tag(concat) #REASON: you only need the final state\n",
    "        tag_scores = F.log_softmax(tag_space, dim = 1)\n",
    "        \n",
    "\n",
    "        withroot = torch.cat((concat, tag_scores.max(1)[1].float().view(-1,1)), 1)\n",
    "        second = self.root2second(withroot)\n",
    "        third = self.root2third(withroot)\n",
    "        second_scores = F.log_softmax(second, dim=1)\n",
    "        third_scores = F.log_softmax(third, dim=1)\n",
    "        \n",
    "        #stacked = torch.stack([tag_scores, second_scores, third_scores], dim=0)\n",
    "\n",
    "        return [tag_scores, second_scores, third_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:  10000   phid:  15   mhid:  15   eps:  0.005\n",
      "0 tensor(5.0641)\n",
      "[1 1 1 1 4 4 4 3 1 3] [ 8  6 10  1 11 11  4 10  3  5]\n",
      "[1 1 1 3 1 3 3 3 3 3] [ 8  2 11 10 10 11  3  3  8  3]\n",
      "accuracy: 0.15625\n",
      "100 tensor(3.1430)\n",
      "[8 8 8 3 6 8 8 8 6 1] [10  6  6 10  2  3  1  8  8  1]\n",
      "[8 8 8 8 8 1 8 1 8 1] [ 3 11  6  3  3  8  3  6 12 10]\n",
      "accuracy: 0.16796875\n",
      "200 tensor(3.0417)\n",
      "[1 8 1 1 1 1 8 8 1 1] [ 1  4 12 12  6  2  6  2 10  8]\n",
      "[ 5  8  3 11 10  5  4  1  8  8] [10  3  9  8  6 10 11  1  8  5]\n",
      "accuracy: 0.2109375\n",
      "300 tensor(2.9145)\n",
      "[ 3  3 11  3  3  6  5  3  3  4] [10  3 11  1  2 11 11  1  6 11]\n",
      "[1 5 4 5 3 4 6 4 3 3] [ 6 10  3  6  3  2  6  8 11  1]\n",
      "accuracy: 0.169921875\n",
      "400 tensor(2.6716)\n",
      "[ 4  3  9 12 11 10  4 11 12  3] [ 4 10  1  3  3  8  6 11  8  3]\n",
      "[ 3  5  6  9  8 10  4  4  1 12] [ 6  3 10  4  5  8  4  8  6  6]\n",
      "accuracy: 0.150390625\n",
      "500 tensor(2.5634)\n",
      "[ 1  4  4  1 11  4 11  3  3 12] [3 1 1 8 6 8 6 3 6 5]\n",
      "[ 1 11  4 11  6  6  7  3  1  3] [1 8 4 1 5 5 5 1 1 4]\n",
      "accuracy: 0.19921875\n",
      "600 tensor(2.6834)\n",
      "[ 3  9  4 11 11  1  8  8  1 12] [ 8  6 11  1  3  8  5  5 11  1]\n",
      "[ 3 12  9 11  4  9 12  8  6 11] [10  5  4  6  1  8  5  3  1  4]\n",
      "accuracy: 0.1943359375\n",
      "700 tensor(2.6024)\n",
      "[ 8 12  4  8 10 12  1  8 12  2] [10 10 11 10  1  3 11  8  7  2]\n",
      "[ 1  1  2  8  7 11  9  8  9  4] [ 1  8  4  7  3 11 11  8  6  6]\n",
      "accuracy: 0.1943359375\n",
      "800 tensor(2.5630)\n",
      "[ 4 12  3 10  6 10 12  8  6  1] [ 9 10  5  9  3  3 10  1  1  6]\n",
      "[12  8 10  4  7  3  6  9  3 10] [ 5 11  1  8  5  1  6  4  1  6]\n",
      "accuracy: 0.193359375\n",
      "900 tensor(2.7400)\n",
      "[ 6 10  1 10 10  4  6 11  1 10] [ 6  1  9 12  8 11  9  6  6  8]\n",
      "[10  4  1 12  1  2 10  4 11  1] [ 3  1  5 10  8 10  3 11 12  6]\n",
      "accuracy: 0.203125\n",
      "1000 tensor(2.5071)\n",
      "[11 11  9 11 10  4  3  6  3  9] [ 5  7  1 11  8  1 10  1 12  9]\n",
      "[ 9  3  9  1  3  0 10  2  6  9] [4 8 3 1 1 4 3 4 6 4]\n",
      "accuracy: 0.2041015625\n",
      "1100 tensor(2.4559)\n",
      "[ 0  1  1  2  3  8  9  1 10 12] [12  1  8  2  1  8  4  8 10 10]\n",
      "[ 2 11  6 11  6  1 12  6 11 10] [10  4 11 11  2  1  6  3  8  3]\n",
      "accuracy: 0.220703125\n",
      "1200 tensor(2.4093)\n",
      "[11  2  4 11  3  2  9 12  4  2] [ 6 10 11  8  8  1  4  6  9  8]\n",
      "[10  6  9  3  3  9  3  3  3  6] [12 11  3  1  1  8  3 10  6  1]\n",
      "accuracy: 0.2216796875\n",
      "1300 tensor(2.5539)\n",
      "[ 8 10  3  6  1  1  8 10  6  6] [ 8  1  1 11  1  1  1  3  8 11]\n",
      "[ 9 11  8 11  4 10  4  4  8 11] [ 3  6  3  8  2  8 11  4 11 11]\n",
      "accuracy: 0.232421875\n",
      "1400 tensor(2.4149)\n",
      "[ 4  3  6  1  3  3  3 11  6  3] [ 2  8 11  9  3 12  3 11  8  5]\n",
      "[11  8  6  5  8  1 11 12  6 10] [6 8 6 6 1 3 1 8 6 8]\n",
      "accuracy: 0.25390625\n",
      "1500 tensor(2.4286)\n",
      "[ 3  7  8  3  5  7  1 11  4 11] [ 8  5  8  8 10  8  6  6  4 11]\n",
      "[11 12  1  1  6  6  1  2  5  5] [ 6 12 10  6  4  6 11  8 10  8]\n",
      "accuracy: 0.2578125\n",
      "1600 tensor(2.3734)\n",
      "[ 5  6  8  7  1  5  6 10  3  8] [ 5  6  6  5  1 10 11  5  6  6]\n",
      "[ 5  9 11  3  1  1  8  4  5  9] [ 6  7  8  3  8  8  6 11  3  4]\n",
      "accuracy: 0.2861328125\n",
      "1700 tensor(2.4755)\n",
      "[ 7 11  4  4  3  6 10 10  5  1] [10  4 11  3 10  3  5  3 12  8]\n",
      "[ 7 11  8  6 11 11  6  6  1  5] [ 5  1  1 10  1  8  6  6  8  1]\n",
      "accuracy: 0.2421875\n",
      "1800 tensor(2.2694)\n",
      "[11 10  5 12  6  8  1  9 11 10] [ 6  6  2  5  6  3 10  9  6 10]\n",
      "[ 6  5 12 10 10  1 11  8  1  2] [ 6  3 10  1 10 10 11  8 10  2]\n",
      "accuracy: 0.23828125\n",
      "1900 tensor(2.4207)\n",
      "[ 4  4  4  5  5  5  3  6  1 11] [ 4 11  4  4 10 10  8  8  1  1]\n",
      "[ 5  3  6  3  4  5 12  3  4  3] [10  8  6  3 11 12  5  8  4  8]\n",
      "accuracy: 0.236328125\n",
      "2000 tensor(2.3116)\n",
      "[11  5  6  2 11  9  8 10 10  3] [12  1 11  2  6  6  8 10 10 10]\n",
      "[11 11  3  0  5  6  6  2  9  8] [11  6 12 11 12  8  8  7  1  5]\n",
      "accuracy: 0.2529296875\n",
      "2100 tensor(2.5033)\n",
      "[ 5 12  5  8  5  9  4  8  8 10] [11  6  3  3  5  7 11  6  8  8]\n",
      "[ 2 11  3  8  9 12  2  3 12  8] [ 6  6  3 12 11  5 11  1 12  6]\n",
      "accuracy: 0.2724609375\n",
      "2200 tensor(2.2137)\n",
      "[ 9  9  3 12  8  8  8  3  8  4] [ 1 11  9  3  8  1  8  9  5  9]\n",
      "[ 2  4 12 11  5 10  9  9 11  4] [ 5  4  5  6  5  1 11  2  6  4]\n",
      "accuracy: 0.255859375\n",
      "2300 tensor(2.3496)\n",
      "[ 6  0 11  2  3  3  6  5 10  1] [8 8 6 1 3 6 6 3 3 8]\n",
      "[ 3 10  1  8  3 10  3  3  5  2] [ 8  1  1  8 10 10  3 10 12 11]\n",
      "accuracy: 0.2919921875\n",
      "2400 tensor(2.4390)\n",
      "[11 11 11 11  3  5  3  3  6  6] [ 6  8 11  6 11  5 11  8 11  8]\n",
      "[ 6  1 11  5 10  4  1  8 11 10] [ 1 10  8  5 10  6  8  8  6  3]\n",
      "accuracy: 0.291015625\n",
      "2500 tensor(2.3046)\n",
      "[2 8 1 8 4 3 6 6 6 2] [10  6  6  5  1  3  1  8  1  9]\n",
      "[ 9 11  1 10  6  3  8  6  3  7] [8 6 1 8 8 6 3 8 5 3]\n",
      "accuracy: 0.2841796875\n",
      "2600 tensor(2.3012)\n",
      "[11  3  6  0 11  2  3  3  8  6] [ 1  1  6 11 11  9  3  8  3  6]\n",
      "[ 8 10 11  4  3  8  3  5  8  3] [ 1  8  6  1  1  1 10  8  1  3]\n",
      "accuracy: 0.2705078125\n",
      "2700 tensor(2.4432)\n",
      "[ 7  8  7 12  2  1  1  3  5  3] [ 8  5 10  3  1  1  8  3  8  3]\n",
      "[ 2  2  8  2 11 10  8  6  3 11] [ 3  8  6  1  6  3  6  1  3 11]\n",
      "accuracy: 0.2734375\n",
      "2800 tensor(2.3432)\n",
      "[ 3  4  4  4  4  2  6  5 11  2] [ 3  4  3  9  7  1 11 10 11  4]\n",
      "[ 4  2 12 11  6 10  2  5 11  6] [11  6  7 10  3  8  2  5  1  6]\n",
      "accuracy: 0.25390625\n",
      "2900 tensor(2.3217)\n",
      "[ 1 11  1 11  9  9  4  1 10  1] [ 6 11  8  1  2  3  3  1 10  5]\n",
      "[ 4 12  1  3  2  4  4  3 10  5] [ 4  5  1 10  7 11 11  8 10  8]\n",
      "accuracy: 0.275390625\n",
      "3000 tensor(2.2936)\n",
      "[ 3  8 10  9  5 10 10 11 11 11] [ 8  3  3  3  5  8 10  6  1  8]\n",
      "[ 1 12 11  4  5  4  1 10 11  6] [ 1  6  6  1 10  4  1  1  3  5]\n",
      "accuracy: 0.24609375\n",
      "3100 tensor(2.3444)\n",
      "[11 11  4 11 11 11 11 10  9  2] [ 1  8  4 11 12 10  8  5  3  1]\n",
      "[ 2 12 11  4 11  3  3  3  1  3] [ 8  5 11  6  1  8  8 12  1 10]\n",
      "accuracy: 0.2685546875\n",
      "3200 tensor(2.2625)\n",
      "[ 9 11  3  2  5  8  2  9  1  3] [8 4 6 4 6 3 1 3 3 8]\n",
      "[12  2  5  0 11 10  2 10  4  6] [ 5 10 10  8  8  8  2  3  8  1]\n",
      "accuracy: 0.2841796875\n",
      "3300 tensor(2.4053)\n",
      "[10  6  1  5  9  1 10 11  8  8] [ 5 10  8  1  9  6  3  1  8  3]\n",
      "[12  8 11 11 11  4  6 12  5  3] [ 3  3  6 11  5 11  3  5  5  5]\n",
      "accuracy: 0.26953125\n",
      "3400 tensor(2.2293)\n",
      "[11  1  9  1  8  1  1 10  4  4] [11  6  4  8  1  3  6 10  1  8]\n",
      "[ 9  5  6  2  1  3 10  5  2 11] [ 4  8  1  2  8  8 10 12  7 11]\n",
      "accuracy: 0.291015625\n",
      "3500 tensor(2.4033)\n",
      "[ 3  3 11 12  2  4  4 11  5  6] [ 1  8  6 10  4  8  1  6  5  1]\n",
      "[11  2 11  3  6 11  7  3 10  8] [ 5  7  8 10  6  2  5  3  8  6]\n",
      "accuracy: 0.263671875\n",
      "3600 tensor(2.2427)\n",
      "[ 9  5  1  3  5  0 11  5 12  4] [ 6 11  1  1 10  1  1  6  3  1]\n",
      "[ 9  3  3  9  4  1 10  2  5 10] [ 4  5 10  4  4  6  3  3  6 10]\n",
      "accuracy: 0.2841796875\n",
      "3700 tensor(2.2104)\n",
      "[1 6 5 5 3 5 3 9 5 9] [ 6  1 11 12 10 10  3  9 10  2]\n",
      "[ 8  1  3  2  0 12 12  4 11  9] [ 8  6 10  8  6  5 10  4 11  1]\n",
      "accuracy: 0.2626953125\n",
      "3800 tensor(2.2325)\n",
      "[12  3  3 11 10 12  2  3  6 10] [3 8 5 6 1 3 1 8 3 8]\n",
      "[ 8  3  9 10 12  5  7  5 11  6] [11  8  4  8  7  4  8 10  6  6]\n",
      "accuracy: 0.2666015625\n",
      "3900 tensor(2.2730)\n",
      "[ 6  8  2  8  7 10  6  4 12 10] [ 3  3 11  3  6  8  6  6  3  5]\n",
      "[ 1  3  4  1 12 10 11 10  6 12] [ 6  8  6 10 10 10  8  3  8  2]\n",
      "accuracy: 0.2607421875\n",
      "4000 tensor(2.2431)\n",
      "[ 3  3  1 10  1  3  3  4  1  0] [ 3  8  8 10  1  1 10 11  6  4]\n",
      "[ 3  6  3  8 12  3  1  0  8 11] [12  8 10  3  2  1  1 10  8  6]\n",
      "accuracy: 0.2783203125\n",
      "4100 tensor(2.2464)\n",
      "[11  7  4 10  3  6  7  6  6  8] [4 1 8 5 1 8 1 6 6 8]\n",
      "[ 3  7  7  6 10  1  7 11  4  7] [ 3  2  7 11  3  8  5 11 11  3]\n",
      "accuracy: 0.2958984375\n",
      "4200 tensor(2.2828)\n",
      "[ 5  4  4 10 11  5 10 12 10  4] [ 1 11  4  3 11 12  3 10  4  4]\n",
      "[ 9  7  5 11  7  1  3  2 11  4] [ 1  1 11  8  3  8  6  9  3 11]\n",
      "accuracy: 0.2685546875\n",
      "4300 tensor(2.2744)\n",
      "[ 9 11 12  3 11  3  5 10  5  1] [11  8 12 11  1 10  5  3  5  1]\n",
      "[12  2  5 10  3  3  6  5  3  3] [ 5  7  1  3  3  8  1 10  1 12]\n",
      "accuracy: 0.279296875\n",
      "4400 tensor(2.2175)\n",
      "[ 5  3 12  7  5  1  7  4  3 12] [ 6  8  3  1  7  1 11 11  3  8]\n",
      "[ 5  2 10  5  5 11  2  1 10  7] [12 11  1  6 10  6  1  8  9  6]\n",
      "accuracy: 0.2294921875\n",
      "4500 tensor(2.4162)\n",
      "[10  6  7  5  7 10  8  4  2  2] [ 6  1  8  2 10 10  8 11  9 10]\n",
      "[11 11 10 12 10  5 11  9  4  9] [ 3  6  8  8  3 10  8  4  8  4]\n",
      "accuracy: 0.2705078125\n",
      "4600 tensor(2.2205)\n",
      "[10  5 10 10  7  3  2 11  6  1] [ 1  5 10  2  2  3  9  8  6  8]\n",
      "[11  1  6  2  2 10 11  3 10 11] [ 6  8 11  2 11 10 11 10  5  9]\n",
      "accuracy: 0.3046875\n",
      "4700 tensor(2.2620)\n",
      "[10  4  1 11  6  6  4  2  1  4] [10  8  8 11  5  3  9  6  1  1]\n",
      "[ 3 12  1  8  5  0  3  9 10  4] [ 8  5  4  1 10  8  8  6  1  1]\n",
      "accuracy: 0.25\n",
      "4800 tensor(2.4012)\n",
      "[10  4  1 10  8 11 11 10 10  3] [ 3  1  6  1  3 11 11  3 10  8]\n",
      "[ 2  6  9 12  2  5  9 10 10 10] [ 6  3  8  8  7 10  4  6  5  8]\n",
      "accuracy: 0.255859375\n",
      "4900 tensor(2.1710)\n",
      "[ 1  5  1  3  7 12  8  5  5  5] [1 1 8 8 5 8 8 1 8 5]\n",
      "[ 4 10  6  7  5  5 10  5  6  3] [ 9  6 11  6  1 10  4  3 11 10]\n",
      "accuracy: 0.248046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 tensor(2.1910)\n",
      "[ 1  4  7 10 11 10  4  6  4  8] [ 6  3  6  8  1 10  4  3 11 11]\n",
      "[10  9  2 10  5 10 11 11  2 11] [10  4  8  6  4  3  9 11  7  1]\n",
      "accuracy: 0.2734375\n",
      "5100 tensor(2.2483)\n",
      "[ 9  2  8 10  1  1  1 10 10 10] [ 9  8  3  4  8  8  1  2 10  6]\n",
      "[ 1 10 10  0  9 11 10  6  1  1] [ 7  6 10 11  6 11  7  1  3  1]\n",
      "accuracy: 0.279296875\n",
      "5200 tensor(2.1516)\n",
      "[11  1  5  3 10  2  2  1  6  7] [1 8 8 8 3 9 3 8 5 5]\n",
      "[ 4 11  2 10  7  3 12  1  6 12] [9 6 9 6 1 8 8 1 6 8]\n",
      "accuracy: 0.265625\n",
      "5300 tensor(2.1959)\n",
      "[ 5  5 12 10  8  7  8  8  5  1] [ 1  5  3 10  8  1  8  3  5  1]\n",
      "[12 12  5 11  7 12  6  9 10 10] [ 8  8  3  8  1 10  6  6  1 10]\n",
      "accuracy: 0.25390625\n",
      "5400 tensor(2.1457)\n",
      "[11 11 12  9  8  1  4  9  8 11] [ 3  1  1  9  8 10 11  9 10  6]\n",
      "[ 6  4  3  3  1  3  1 11 10 11] [8 9 5 1 1 3 8 6 5 6]\n",
      "accuracy: 0.2890625\n",
      "5500 tensor(2.2829)\n",
      "[10  4  2  6 12  3  9  1  5  6] [ 6 11  9  6 12 10  6  1  5  6]\n",
      "[ 4 11 10  6  2 11  1  4 10  3] [10 11  3  1  1  6  3  4  3  8]\n",
      "accuracy: 0.2724609375\n",
      "5600 tensor(2.1515)\n",
      "[ 3 10  7 11  2  5  1  9  6  5] [ 8  1  0  4  1 12  1 11  5  1]\n",
      "[ 9 10 11  8  3  3 11  6  2 10] [ 4  1  1  3 10  8 11  1  8 12]\n",
      "accuracy: 0.2939453125\n",
      "5700 tensor(2.2795)\n",
      "[ 5 11  8 10 10  6 11  8  6  4] [10 11  8 10  3  6 11  1  6  4]\n",
      "[ 2  5  5  5  1 11 10 10  2  5] [ 4  3  5 10  8  1 10 10  4  5]\n",
      "accuracy: 0.275390625\n",
      "5800 tensor(2.0980)\n",
      "[ 6 11 11  1  6  0  5  5  5  9] [ 6 10  8  6  8  0  6  8  8  2]\n",
      "[ 7  7  6 10 11 11  8  3  9  1] [ 1  3  6 10  4  3 10 11  4  1]\n",
      "accuracy: 0.2578125\n",
      "5900 tensor(2.0648)\n",
      "[12  6  1  9  8  4 10  2 11 12] [12 11  1 11  3  4  3  4 11  7]\n",
      "[ 2  9  4 11 11  2 11  4 11  2] [6 4 4 6 6 4 4 4 6 4]\n",
      "accuracy: 0.3134765625\n",
      "6000 tensor(2.3034)\n",
      "[ 4  8  6  1  4  5  3 11  4  5] [ 4  8  8  6  9  3  5  1 11 10]\n",
      "[11  4  1  4  3  6  4  2  7  6] [11  4 10  1  3 11  4  1 12  1]\n",
      "accuracy: 0.271484375\n",
      "6100 tensor(2.1452)\n",
      "[ 4  6 12 12  9 11 10 10  6 11] [ 9 11 12 10  2 11 10 10  1  3]\n",
      "[ 2  6  2  2 10  6  5  6  3  7] [11  3  6  1  1  3  8 11  8  2]\n",
      "accuracy: 0.28515625\n",
      "6200 tensor(2.1635)\n",
      "[ 6  0  6  5  1  8  2  8  8 10] [6 0 1 1 8 8 5 1 8 8]\n",
      "[12 11  3  1  6 11  0  6  6  3] [12  5 12  6  6  6  0  8  8 10]\n",
      "accuracy: 0.2841796875\n",
      "6300 tensor(2.1742)\n",
      "[ 5  6 11  9  1  2  4  7  1  5] [1 6 1 9 1 1 9 9 8 1]\n",
      "[ 2  1  5 10  1  2  1  1  1  5] [ 1 10  8  3  8  4  8  8  8 12]\n",
      "accuracy: 0.265625\n",
      "6400 tensor(2.2221)\n",
      "[ 4  2  6  3  6  2 12 11  9 12] [11 10  3  8  3  8 10  1  9 12]\n",
      "[12  6 11  5  7  8  2  7  6  3] [ 1  6  6  5  6  8  6 10  6  6]\n",
      "accuracy: 0.27734375\n",
      "6500 tensor(2.1294)\n",
      "[ 6  0 12  1 10 10  9 10 11  3] [ 1 10 10  6  3  1  9  5 11  8]\n",
      "[ 4  7  1  1  5 11 11  2  1  1] [11  1  6 11  5 11  1  4  1  6]\n",
      "accuracy: 0.2978515625\n",
      "6600 tensor(2.1532)\n",
      "[ 9  7  6  2  6  1 10  3  4  2] [ 8  7  1 12  1  8  8  3  1  1]\n",
      "[11  6  1 10  5  4  2  5 11  8] [ 6  1  6  1  6 11  6  3 11  8]\n",
      "accuracy: 0.2861328125\n",
      "6700 tensor(2.0442)\n",
      "[12 12  6  2  4  4  4  8  0  6] [ 5 10  3 10  1  4  4  8  1  7]\n",
      "[ 2 12 12  4  3 11  5  3  4  1] [ 4  3  3  8  8  6  8  5 10  1]\n",
      "accuracy: 0.27734375\n",
      "6800 tensor(2.3286)\n",
      "[ 2  2  1 10 11 10  9 10 10  1] [ 1  6  6  5  8 10  7  3 10  1]\n",
      "[ 3  3  7 11  1  4 11  3  7  6] [ 8  8  5  8  1 11  1  8  8  6]\n",
      "accuracy: 0.283203125\n",
      "6900 tensor(2.3064)\n",
      "[10 11 11  8  4  6 10  4 12  1] [ 3 11  1  8  9  8  5  6  5  1]\n",
      "[10  3  1 10  2  4  4  7 12  5] [10  3  6  5 11 11  4  4  3  1]\n",
      "accuracy: 0.2646484375\n",
      "7000 tensor(2.1392)\n",
      "[ 3  4  4  0 10  6  7  9  6  3] [10  1  2  0  3  8 12  9  1  3]\n",
      "[10  1 11 10  1  2 11  3  9  2] [ 3  8  6  5  6  6 11  3  1  2]\n",
      "accuracy: 0.298828125\n",
      "7100 tensor(2.1829)\n",
      "[ 2  5  6 12 10 11  1  6  4  8] [ 1  1  8 10  3 11  1  1  8  8]\n",
      "[ 9  1 10 12  8  7 11  8  5  1] [ 8 10  8  3  8  5  6  6 12  8]\n",
      "accuracy: 0.271484375\n",
      "7200 tensor(2.2288)\n",
      "[ 6 11 10 12 11 11  1 10 12  5] [ 1  6 10  8  6 11 10 11  1  5]\n",
      "[ 4  1 11  1  7  1  1  5  5 10] [ 8  8  6 10 10  4  1  8  8 10]\n",
      "accuracy: 0.2890625\n",
      "7300 tensor(2.2643)\n",
      "[ 3 11 11  4 10  6  1 11 11 10] [ 8 11  8  6 10  6  1  6  8  8]\n",
      "[ 5  1  4  1 11  1  3  6 10 12] [11 11  4 10  8  1  3 11 10  5]\n",
      "accuracy: 0.2685546875\n",
      "7400 tensor(2.1230)\n",
      "[11 11  2  5  6  3 11  3  7 10] [11  1  9  6  6 10 11  6  5 10]\n",
      "[ 2  2  6  3  4 10  4 11  4  5] [ 2 11  1  8  6 10 10  6  8 12]\n",
      "accuracy: 0.2666015625\n",
      "7500 tensor(2.2044)\n",
      "[11  6  3  3  3  1 10 11  6  2] [ 6  8 10  1  3  8  3  9  1  2]\n",
      "[10  5  3  2  2  1  3  8  6 11] [3 8 3 1 5 3 8 8 6 1]\n",
      "accuracy: 0.2626953125\n",
      "7600 tensor(2.0863)\n",
      "[ 1  2  5  2 11  3  8  1  3  5] [ 6  6  8  4 11 10 10  6 10 12]\n",
      "[ 3  3  2  6  6 10  1  5 10 12] [11 10  9 11  6  3  6  7 10 10]\n",
      "accuracy: 0.259765625\n",
      "7700 tensor(2.0953)\n",
      "[12  1  2  4  8  6  0  6  1  3] [ 5  1 11 11 10  6  9  6  8  8]\n",
      "[12  6 10 11  6  7  6  6  6  3] [12 11  8  6  6 11  6  1  1  3]\n",
      "accuracy: 0.2587890625\n",
      "7800 tensor(2.1630)\n",
      "[ 6  5 11  4 11  1 10  5  6  7] [ 6  8  8  9  6  1  3 10  6  3]\n",
      "[ 1  3  3 10 11  2  5 12  7  7] [ 1  3  1  4  4  2 10  8  1  5]\n",
      "accuracy: 0.2880859375\n",
      "7900 tensor(2.1766)\n",
      "[12 11 11  6  2 10 12  3  7 10] [ 3 11  6 11 11  1  0  3  5  3]\n",
      "[ 3 11  7 11  2  3 12  2  7  6] [10  4  1  6  1  3  6  4  1 11]\n",
      "accuracy: 0.2763671875\n",
      "8000 tensor(2.0922)\n",
      "[12  6 12  4  3 11  8  5 12  3] [ 8 11  5  4  1  4  8 10  8  3]\n",
      "[ 8  3  8  7  2 10  1 12 10  5] [ 2  8  1 12  2  3  8 10  1  1]\n",
      "accuracy: 0.291015625\n",
      "8100 tensor(2.2114)\n",
      "[ 1  8  5  1  6  1  5  2 10  3] [3 8 4 8 1 1 5 1 3 1]\n",
      "[ 4  7 10 11 10  3  4  4  5  1] [ 4  1  1  1  8  3  6  6  3 10]\n",
      "accuracy: 0.2392578125\n",
      "8200 tensor(2.1560)\n",
      "[ 2  2  3  1  6  4  5 11 11  1] [10  9  8  6 11 11 10  3 11  1]\n",
      "[7 6 1 1 1 5 5 3 6 6] [ 7  8  8  8  8 12  1  8  1  6]\n",
      "accuracy: 0.26953125\n",
      "8300 tensor(2.0844)\n",
      "[ 5  6  1 11 10  2 11  6 12  0] [10  6  5  8  6  6 11  6  8  1]\n",
      "[11 10  2  6  6 10  6  2  3  6] [ 3  1 11  4  6  8  6  3  1  6]\n",
      "accuracy: 0.291015625\n",
      "8400 tensor(2.2895)\n",
      "[10  2  6  5 11 11  6  2  5 11] [ 7  6  7 11  1 11  6  2 10  8]\n",
      "[10 10  1  4  3  6  4  1  2 10] [ 5 10  8 11  8  1 10  1  8  8]\n",
      "accuracy: 0.30078125\n",
      "8500 tensor(2.0818)\n",
      "[11  3  1  8  3  6  1  5  2  7] [11  8  1  6  6  1  1  5  1  4]\n",
      "[ 6  3 10  3  6  2  1 10  6  3] [11  8 10  8  6  2  8  3  1  3]\n",
      "accuracy: 0.3056640625\n",
      "8600 tensor(2.1688)\n",
      "[ 6  5 10 10  6 11 11  2  2  3] [ 6  5  8 11  3 11  1  9  8  3]\n",
      "[ 5 10 11  2  4  5  3  5  3  5] [10  3  6  1  3  8  6  5  1 12]\n",
      "accuracy: 0.2958984375\n",
      "8700 tensor(2.2070)\n",
      "[ 9 10 12  7  6  5 11 10  5  3] [11  1  1  2 11  6 11 10  3  3]\n",
      "[11  3  4  3 11 12  2  7  5  3] [ 1  8  4 10  6 10  7 12  8  3]\n",
      "accuracy: 0.2724609375\n",
      "8800 tensor(2.2260)\n",
      "[ 7 11  1 12 10  6 11  8 10  5] [ 2 11 10  1  1  1 11  8  1  5]\n",
      "[11  6  8 12 10  9  3  5  2 11] [ 6  6  3  1  5 11  8  5  4  6]\n",
      "accuracy: 0.30078125\n",
      "8900 tensor(2.1070)\n",
      "[3 4 6 3 3 1 1 3 4 4] [ 3 11 10  3  1  3  1  8  1  6]\n",
      "[1 4 4 0 1 5 6 3 6 2] [ 8  1  4  8  5  6  6 10  1  6]\n",
      "accuracy: 0.28125\n",
      "9000 tensor(2.2268)\n",
      "[ 3  1  6  8  3 12  9  4 12  3] [ 3  5  1  8 10  7  4  5 10  3]\n",
      "[ 7  1  3 10 11 12  5  6  2 10] [ 0  8  1  1  4  5 10  8 11 10]\n",
      "accuracy: 0.2724609375\n",
      "9100 tensor(2.2881)\n",
      "[ 2 11 11  2 12 11  7  4  1  4] [ 6  3 11  6  1 11  2  8  8  4]\n",
      "[ 4 10  6  3  5 11 10  9  1  6] [ 1  9 10  1  1  6  1  6  5  6]\n",
      "accuracy: 0.2783203125\n",
      "9200 tensor(2.0606)\n",
      "[ 2  3  6 10  6 10  3  4  6  6] [ 2  6  8  8 11 10 12  8  1  8]\n",
      "[ 3 11  2 11  4  5 11 11  6 11] [ 1 11  2 11  3  8  6  1  6  1]\n",
      "accuracy: 0.28515625\n",
      "9300 tensor(2.0406)\n",
      "[10  1 10  7 11 10  6  9  3  7] [ 3  8  3  7 11  8  8  4  6 10]\n",
      "[ 5  7  9  2  7 10  7 11  8 11] [ 1  4  4  2  3  3 10  4  8  8]\n",
      "accuracy: 0.298828125\n",
      "9400 tensor(2.1473)\n",
      "[ 2 11  4  5 11  6  1  2 11  2] [ 1  1  4 10  8  1  1  2  6  3]\n",
      "[ 3  1 10  6  8  2  4  6  3  1] [7 9 9 1 1 2 9 1 3 8]\n",
      "accuracy: 0.296875\n",
      "9500 tensor(2.1202)\n",
      "[ 2  0  2  3  5  5 10  2  1  2] [ 9 10  9  3  4  3 10  5  6  7]\n",
      "[10  7 10  2  3 11  5  5  8  4] [12  3  3  1 10  9  6  5 11  4]\n",
      "accuracy: 0.263671875\n",
      "9600 tensor(2.0891)\n",
      "[ 2 11  1 11  2  6  2  2  5  7] [ 1  6  8 11  6  3 11  7  1 12]\n",
      "[ 1  1  8  3  1 10  1  7 12  6] [ 1  1  3  8 10 10  1  8  5  6]\n",
      "accuracy: 0.27734375\n",
      "9700 tensor(2.0955)\n",
      "[ 5 10  3  1  7  1  6  3  6 12] [ 8  5 10  8 10  1  6  8  6  1]\n",
      "[ 7  8  2 10  3 10 11 12  2  5] [11  8  2  6  1 10  7  8  2 10]\n",
      "accuracy: 0.2861328125\n",
      "9800 tensor(2.1191)\n",
      "[ 6  7  3 10  3  2 11  2 10  3] [ 6  7  3  5  3  9 11  2  8  3]\n",
      "[11  9  3  3  5 10  5 10  1  8] [ 4  9  4  1  6  5 10  1  6  8]\n",
      "accuracy: 0.2939453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9900 tensor(2.2195)\n",
      "[ 1 11  5  3 10 10  6  3  5  7] [ 3 11 10  8 10  1  8 12 10 10]\n",
      "[ 9  6  2  9  8 11  4  3  1  2] [ 9  3  1  9  8  8  1  8 10 10]\n",
      "accuracy: 0.283203125\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "for iteration in range(1):\n",
    "\n",
    "    P_HIDDEN_DIM = max(int(np.random.normal(30, 20)), 5)\n",
    "    M_HIDDEN_DIM = max(int(np.random.normal(30, 20)), 5)\n",
    "    vocab_size = 13\n",
    "    tagset_size = 13\n",
    "    EPS = random.uniform(0.005, 0.15)\n",
    "    ITER = int(random.uniform(300, 1200))\n",
    "    P_EMBEDDING_DIM = vocab_size\n",
    "    M_EMBEDDING_DIM = vocab_size\n",
    "    \n",
    "    P_HIDDEN_DIM = 15\n",
    "    M_HIDDEN_DIM = 15\n",
    "    EPS = 0.005\n",
    "    ITER = 10000\n",
    "\n",
    "    print(\"iter: \", ITER, \"  phid: \", P_HIDDEN_DIM, \"  mhid: \", M_HIDDEN_DIM, \"  eps: \", EPS)\n",
    "    newweishts = weightloss(weights, EPS)\n",
    "    model = LSTMTagger(P_EMBEDDING_DIM, M_EMBEDDING_DIM, P_HIDDEN_DIM, M_HIDDEN_DIM, vocab_size, tagset_size, batch_size = batch_size)\n",
    "    loss_function = nn.NLLLoss(weight = newweights[0])\n",
    "    loss_function2 = nn.NLLLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.2)\n",
    "    \n",
    "    for epoch in range(ITER):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "        for i in data_loader:\n",
    "            # Step 1. Remember that Pytorch accumulates gradients.\n",
    "            # We need to clear them out before each instance\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Also, we need to clear out the hidden state of the LSTM,\n",
    "            # detaching it from its history on the last instance.\n",
    "            model.p_hidden = model.init_hidden(P_HIDDEN_DIM)\n",
    "            model.m_hidden = model.init_hidden(M_HIDDEN_DIM)\n",
    "\n",
    "            # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "            # Tensors of word indices.\n",
    "            p, m, l, mask, marr = i['p'], i['m'], i['l'], i['mask'], i['marr']\n",
    "            #print(m)\n",
    "            tag_scores = model(p, m, mask)\n",
    "            # Step 3. Run our forward pass.\n",
    "\n",
    "            # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "            #  calling optimizer.step()\n",
    "            #print(targets[:1])\n",
    "            loss = 0\n",
    "\n",
    "            loss += loss_function(tag_scores[0], torch.t(l)[0])  \n",
    "            loss += 0.5 * loss_function2(tag_scores[1], torch.t(l)[1])\n",
    "            loss += 0.5 * loss_function2(tag_scores[2], torch.t(l)[2])   \n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            break\n",
    "        if(epoch % 100==0): \n",
    "            print(epoch, loss)\n",
    "            accuracy = 0.0\n",
    "            c = 0\n",
    "            for j in range(2):\n",
    "                for i in data_loader:\n",
    "                    c+=1\n",
    "                    p, m, l, mask, marr= i['p'], i['m'], i['l'], i['mask'], i['marr']\n",
    "                    tag_scores = model(p, m, mask)\n",
    "                    pred = tag_scores[0].max(1)[1].numpy()\n",
    "                    truth = torch.t(l)[0].numpy()\n",
    "                    print(pred[10:20], truth[10:20])\n",
    "                    accuracy += np.average(pred == truth)\n",
    "                    if (c>=1): break\n",
    "            print(\"accuracy:\", accuracy/c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[12  7 11 12 11 12 10 10 11  4  7 11 10  3  7  9  4 11 10  3] [ 8  3  9  1 11  1  1  3 11  4  5  6  5  8  2  9 12  6  6 10]\n",
      "2\n",
      "[10  7 10 12  6 10 10  3  8  4  7  6 10  2  7  5 11  9  5  3] [ 3 10 10  6  1  5  5  8  8  4  6  1  3  1  5  5 11  6  8  3]\n",
      "3\n",
      "[ 8  5  0  1  5  9  4 10 10 11  3 11  8  9  1 11  3  3  4 10] [ 1 10  8  8  5  4 11  3 10  8  3 11  8  9  8  9  8 10  4  3]\n",
      "4\n",
      "[12  3  5  8  6  3 10  3  5  6  2 11 11  7 11  2 10  7  0 11] [ 5  8  5 11  1  8  1  8 10  6 11  6 11 10 11  9  3 10 10  6]\n",
      "5\n",
      "[ 1 10  3  6  6  1  3 12  4  4  2  3  6  3  8 11  5  2 10 11] [ 8 10  3  6  6 11  8 12  8  8 11 12  1  3  8  6 10 11  8 11]\n",
      "6\n",
      "[ 2  4  3  5 12  7  8  3  6  1  1  6  5  2  1  7 12 11 11  3] [ 2  1  8  9 10  8  8  6  1  1  3  1  2  3  8  1  1  6  4  5]\n",
      "7\n",
      "[10  1 12 11 10 10  3  3  8 10 10 10 10  9 11 11  5  7  3 12] [10  8  3 11  5 10  9  1  8 10 10  5  3  9  1  6  6 12  5  1]\n",
      "8\n",
      "[10  3  1 10  6  4 12 10 10  1 10  8 10  9  4  8  2 10 10  3] [10  8  8  1  8  6  7  1  3  8  8  8  5  2 11  3  2  8  8  6]\n",
      "9\n",
      "[ 5 10 11 10  6  7 12  8  3  1  1 10  7  0  4  2  0  2  2  2] [ 1 10  6  5  8  7  1  8  3  1  1 11  1  0  4  1  1  5  4  1]\n",
      "10\n",
      "[ 2  5  3 12  1 10 12  3  1  9  1  6 11  3  5  4  6  4  4  3] [ 2  6  8 12  6  8  6  8  8  1  1  6  3 10 10  4  6  4  8  8]\n",
      "accuracy: 0.2828125\n"
     ]
    }
   ],
   "source": [
    "    accuracy = 0.0\n",
    "    c = 0\n",
    "    for j in range(10):\n",
    "        for i in data_loader:\n",
    "            c+=1\n",
    "            print(c)\n",
    "            p, m, l, mask, marr = i['p'], i['m'], i['l'], i['mask'], i['marr']\n",
    "            tag_scores = model(p, m, mask)\n",
    "            pred = tag_scores[0].max(1)[1].numpy()\n",
    "            truth = torch.t(l)[0].numpy()\n",
    "            print(pred[:20], truth[:20])\n",
    "            accuracy += np.average(pred == truth)\n",
    "            if (c>=1): break\n",
    "    print(\"accuracy:\", accuracy/c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model:\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
