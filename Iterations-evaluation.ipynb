{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11d7670f0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Author: Yulou Zhou\n",
    "#Weight loss function by commonality (and normalize)\n",
    "#padded sequence\n",
    "#for loop to test parameters\n",
    "#for loop to get prev generated chord\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import csv\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from random import shuffle\n",
    "from MyDataset import MyDataset\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "#train_data = MyDataset('relativedata', prevchord = 6)\n",
    "test_data = MyDataset('parsedtest', prevchord = 6)\n",
    "weights = train_data.stats()\n",
    "#data_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "data_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "c=0\n",
    "for i in data_loader:\n",
    "    print(\"p: \", i['p'])\n",
    "    print(\"m: \", i['m'])\n",
    "    #print(\"mask: \", i['mask'])\n",
    "    print(\"l: \", i['l'])\n",
    "    c += 10\n",
    "    if c > 0: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "for iteration in range(1):\n",
    "\n",
    "    #model = LSTMTagger(P_EMBEDDING_DIM, M_EMBEDDING_DIM, P_HIDDEN_DIM, M_HIDDEN_DIM, vocab_size, tagset_size, batch_size = batch_size)\n",
    "    model = torch.load('230modelc5')\n",
    "\n",
    "\n",
    "\n",
    "           # model.zero_grad()\n",
    "\n",
    "\n",
    "    accuracy = 0.0\n",
    "    c = 0\n",
    "\n",
    "    for j in range(10):\n",
    "        for i in data_loader:\n",
    "            c+=1\n",
    "            p, m, l, mask = i['p'], i['m'], i['l'], i['mask']\n",
    "            tag_scores = model(p, m, mask)\n",
    "            pred = tag_scores[0].max(1)[1].numpy()\n",
    "            truth = torch.t(l)[0].numpy()\n",
    "            if(c<10): print(pred[:20]-truth[:20])\n",
    "            diff = abs(pred - truth)\n",
    "            accuracy += np.average( ((diff == 0) + (diff == 3) +  (diff == 4) + (diff ==7) + (diff == 9) + (diff == 8) ))\n",
    "            if (c>=1): break\n",
    "    print(\"accuracy:\", accuracy/c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
