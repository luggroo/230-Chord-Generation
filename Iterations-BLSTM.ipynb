{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe45c4cd610>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Author: Yulou Zhou\n",
    "#Weight loss function by commonality (and normalize)\n",
    "#padded sequence\n",
    "#for loop to test parameters\n",
    "#for loop to get prev generated chord\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import csv\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from random import shuffle\n",
    "from MyDataset import MyDataset\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p:  tensor([[  0,   0,   0,  ...,  10,   3,   7],\n",
      "        [  6,   4,   7,  ...,   2,   4,   7],\n",
      "        [  1,   4,   7,  ...,   6,   4,   7],\n",
      "        ...,\n",
      "        [  7,   3,   7,  ...,   2,   4,   7],\n",
      "        [  1,   4,   7,  ...,  11,   4,   7],\n",
      "        [  8,   4,   7,  ...,   6,   4,   7]])\n",
      "m:  tensor([[ 10,  10,  10,  ...,   0,   0,   0],\n",
      "        [ 12,  12,  12,  ...,   0,   0,   0],\n",
      "        [ 10,  10,  10,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [  3,   3,   3,  ...,   0,   0,   0],\n",
      "        [ 11,  11,  11,  ...,   0,   0,   0],\n",
      "        [  6,   6,   6,  ...,   0,   0,   0]])\n",
      "l:  tensor([[  5,   4,   7],\n",
      "        [  6,   4,   7],\n",
      "        [  8,   4,   7],\n",
      "        ...,\n",
      "        [  7,   3,   7],\n",
      "        [ 11,   4,   7],\n",
      "        [  8,   4,   7]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 512\n",
    "train_data = MyDataset('relativedata', prevchord = 6)\n",
    "weights = train_data.stats()\n",
    "data_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "c=0\n",
    "for i in data_loader:\n",
    "    print(\"p: \", i['p'])\n",
    "    print(\"m: \", i['m'])\n",
    "    #print(\"mask: \", i['mask'])\n",
    "    print(\"l: \", i['l'])\n",
    "    c += 10\n",
    "    if c > 0: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(array):\n",
    "    return [i / sum(array) for i in array]\n",
    "newweights = []\n",
    "\n",
    "def weightloss(weights, eps):\n",
    "    for w in weights:\n",
    "        newweights.append(torch.FloatTensor( normalize([1/(i + eps) for i in w] ) ) )\n",
    "    #print(newweights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, p_embed_dim, m_embed_dim, p_hidden_dim, m_hidden_dim, vocab_size, tagset_size, batch_size = 1):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.p_embed_dim, self.m_embed_dim = p_embed_dim, m_embed_dim\n",
    "        #refer to https://discuss.pytorch.org/t/can-we-use-pre-trained-word-embeddings-for-weight-initialization-in-nn-embedding/1222/2\n",
    "        \n",
    "        self.p_embed = nn.Embedding(vocab_size, p_embed_dim)\n",
    "        self.m_embed = nn.Embedding(vocab_size, m_embed_dim)\n",
    "        self.p_embed.weight.data.copy_(torch.from_numpy(np.identity(vocab_size)))\n",
    "        self.m_embed.weight.data.copy_(torch.from_numpy(np.identity(vocab_size)))\n",
    "        \n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.p_lstm = nn.LSTM(p_embed_dim, p_hidden_dim, bidirectional = True)\n",
    "        self.m_lstm = nn.LSTM(m_embed_dim, m_hidden_dim, bidirectional = True)\n",
    "        \n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = nn.Linear((p_hidden_dim + m_hidden_dim) * 2, tagset_size)\n",
    "        self.root2second = nn.Linear((p_hidden_dim + m_hidden_dim) * 2 + 1, tagset_size)\n",
    "        self.root2third = nn.Linear((p_hidden_dim + m_hidden_dim) * 2 + 1, tagset_size)\n",
    "        \n",
    "        self.p_hidden = self.init_hidden(p_hidden_dim)\n",
    "        self.m_hidden = self.init_hidden(m_hidden_dim)\n",
    "\n",
    "    def init_one_hot(self, vocab_size):\n",
    "        #initialize each embedding\n",
    "        #stack them together (or other ways to have  pretrained embeddings)\n",
    "        #pretrained_weight is a numpy matrix of shape (num_embeddings, embedding_dim)\n",
    "        #we should turn data into torch.from_numpy(pretrained_weight)\n",
    "        #embed.weight.data.copy_(torch.from_numpy(pretrained_weight))\n",
    "        \n",
    "        torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "        \n",
    "    \n",
    "    def init_hidden(self, hidden_dim):\n",
    "        # The axes semantics are (num_layers, minibatch_size, hidden_dim)\n",
    "        return (torch.zeros(2, self.batch_size, hidden_dim),\n",
    "                torch.zeros(2, self.batch_size, hidden_dim))\n",
    "\n",
    "    def forward(self, prev, melody, mask):\n",
    "        \n",
    "        prev_embeds = self.p_embed(prev)\n",
    "        x1 = torch.transpose(prev_embeds, 0, 1) #TODO: DEBUG THIS LINE (probably the last batch)\n",
    "        \n",
    "        #TODO: ensure that melody input is a tensor\n",
    "        \n",
    "        melody_embeds =  self.m_embed(melody) #Error here\n",
    "        #print(melody_embeds.size())\n",
    "        x2 = torch.transpose(melody_embeds, 0, 1)[:8]\n",
    "        \n",
    "        p_lstm_out, self.p_hidden = self.p_lstm(x1, self.p_hidden)\n",
    "        m_lstm_out, self.m_hidden = self.m_lstm(x2, self.m_hidden)      \n",
    "        \n",
    "        p_fstate, m_fstate = p_lstm_out[-1], m_lstm_out[-1]\n",
    "        \n",
    "\n",
    "        concat = torch.cat((p_fstate, m_fstate), 1)\n",
    "        #print(p_fstate.size(), m_fstate.size())\n",
    "        tag_space = self.hidden2tag(concat) #REASON: you only need the final state\n",
    "        tag_scores = F.log_softmax(tag_space, dim = 1)\n",
    "        \n",
    "\n",
    "        withroot = torch.cat((concat, tag_scores.max(1)[1].float().view(-1,1)), 1)\n",
    "        second = self.root2second(withroot)\n",
    "        third = self.root2third(withroot)\n",
    "        second_scores = F.log_softmax(second, dim=1)\n",
    "        third_scores = F.log_softmax(third, dim=1)\n",
    "        \n",
    "        #stacked = torch.stack([tag_scores, second_scores, third_scores], dim=0)\n",
    "\n",
    "        return [tag_scores, second_scores, third_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:  10000   phid:  18   mhid:  10   eps:  0.02806\n",
      "0 tensor(5.4374)\n",
      "[7 7 8 5 7 7 7 7 7 7 8 7 7 7 7 7 8 7 7 7] [ 7  8  1  9  3  6  3 10 11  3  1  4  3  8  8 10  1  6 10  2]\n",
      "[7 7 7 7 8 7 7 8 7 7 7 7 7 7 7 7 7 7 7 7] [ 3  1  8 10  3  1  1  1  3 10  7  6  3  8  1  6  1  3  1  8]\n",
      "accuracy: 0.025390625\n",
      "100 tensor(3.7759)\n",
      "[6 6 6 6 8 8 8 6 8 8 8 6 6 6 6 8 8 6 6 8] [ 4  1 11  8  1  1  8  8  3  5  3  1  3  6  5  8 10  8  4  8]\n",
      "[1 1 6 1 6 6 6 1 6 8 6 8 6 8 6 8 1 8 6 6] [10  1 11  8  1  8  1  6  6  7  1  6  1 12 11  1  1 10  1  3]\n",
      "accuracy: 0.1904296875\n",
      "200 tensor(3.5928)\n",
      "[1 1 6 1 6 6 6 8 6 6 1 6 6 6 6 6 6 8 6 1] [ 1  1 12  6  9  6  8  8 11  1  8  8  8  1 10 10  9 10  3 12]\n",
      "[6 6 1 6 6 1 1 6 1 8 1 6 6 6 1 6 6 6 1 8] [10  8  1  4  8 11  8  9  4  3  8 11 10  3  6 10  3 10  8  6]\n",
      "accuracy: 0.1708984375\n",
      "300 tensor(3.6221)\n",
      "[6 6 8 8 6 6 8 8 6 8 8 8 8 0 8 8 8 8 8 8] [ 6  2  8  3  4  8  1 10  5  8  3  1  3  8  6  3  8  6  3  6]\n",
      "[ 8  8  8  6  8  6  6  6  8  8  6  8  8  6  8  8 11  8  8  8] [ 8  3  5  7 10  8  1  8 10  8  3  5  3  6  3 10  4 10 10  3]\n",
      "accuracy: 0.2177734375\n",
      "400 tensor(3.6321)\n",
      "[ 8  1  8  6  8  4  8  1  8  3  6  8  8  4  8  4  4 11  8  6] [ 8  1  5  2  8  4  1  1  3  8  3  8 11  4  6  6  6  8 10  6]\n",
      "[ 6  1  6  6 11  8  8  8  8  8  4  8  4  4  8 11  8  1  6  8] [ 6  1  6  8 11  3 10  6  3 11  2  3  9 10  4  1  1  8 11 12]\n",
      "accuracy: 0.1748046875\n",
      "500 tensor(3.4278)\n",
      "[ 1  8  1  8 10  1  8  6  3  1  4  4  3  6  3  8  3  1  3  1] [ 6  6  8 10 11  6  1 10  3  9  6  9  3  1  6  4  1  3 12 11]\n",
      "[ 4  3  1  3 10  3  1  4  3  1  6  1  3  6  8  6 10  3  3  3] [ 7  3  1  8  8  3  6  1  1  6  3  6 10 10  1  6 12 10  9  1]\n",
      "accuracy: 0.169921875\n",
      "600 tensor(3.4546)\n",
      "[ 1  6 10  3  3 11  3 10  3 11  3  3 11  3  4  6  3  6 11  3] [ 6  3 10  6  1  9  1  5  5  4  3  1 11 10  4  8  6  3 12  1]\n",
      "[10  6  6  3 11 11  1  3 10  6 10 10 11  1  8  1  6  6  3  3] [ 6  3  6  8  6 11  6 11 11  3  1  1  9  1  9  8  3  8 12  2]\n",
      "accuracy: 0.1806640625\n",
      "700 tensor(3.2094)\n",
      "[ 8 11 11  6  5 10  8 10  6  8 10  8  1  4 10  3 10  0  1  8] [ 2  1  1  8 10  8  8  1 10  3 10  1  1  6 12  8  8  1  8  8]\n",
      "[11  1 11  8  8  6  0  3  8  1  8 10  9  1 10  6  3  8  0 10] [ 9  8  1  8  8 11  6 10  1  1  1  8  5  8 10  1  8 10  6 10]\n",
      "accuracy: 0.2373046875\n",
      "800 tensor(3.3572)\n",
      "[10  6  6  6  8  5 10  8  1  6  6  6 10  1  6  6  3  4  3  3] [ 6  1  6  6  4 12  8  8  1  3  8  8  2  6  6  3  1 11  5  5]\n",
      "[ 9  4 11  0  6 10  5  3  1  6  6  8  5  1  6  6  2  8  0  8] [ 1 11  1  8  6  8  7  5  6  1  1 10  1  1  8 11 10 10  8  6]\n",
      "accuracy: 0.2333984375\n",
      "900 tensor(3.2037)\n",
      "[10 10  1  8  6  4  5 10  6 10  6 10 11  0  6  8  6  8  3  8] [ 3  5  1 12 11 11  6  5  4  8  1  8 11  1  3  8 11  8  8  3]\n",
      "[ 8 10  6  3 10  0  1  6  6  5  1  3  6  6  6 10  6  6  8 10] [ 3  3  8  8  7  1  3  8  1  5 10  3  4  6  6  1  2 12  8  8]\n",
      "accuracy: 0.208984375\n",
      "1000 tensor(3.2316)\n",
      "[ 3  1 11  0  1 10  6  9  6  3  3  1  2  6  6 11  1  3  6  3] [ 3  8 11  8  1 10  1  1  6  8  8 11  2  3 11  8  1  1  4  1]\n",
      "[ 1  1  6  5 10  9  8 11  3  1  3  3  8  6  6  3  6  6 11 10] [ 8  1  3 10  8  1  8  8  8  1  8  3  3 11  1  8 11  6  4  3]\n",
      "accuracy: 0.21484375\n",
      "1100 tensor(3.1310)\n",
      "[ 6 10 10  3  6 10  1 10  3 10 10  9  8  3  8 11 10  9 11  5] [ 1  8 10  8 11  8  8  8  1 12  5  9  1  8  1  9  1  4  6  3]\n",
      "[11 10  3  1  6  8  3 10  8 10  3  8  6  1 11  6  8  6  4  8] [11 10 11  6  6 11  8  4  8  8  8  6  6  1  6  6  6  6  7  1]\n",
      "accuracy: 0.2509765625\n",
      "1200 tensor(3.2549)\n",
      "[ 8  0  3  6  6  6  6 10  8  8  9 11 11  9  8  4  6  4  6  4] [ 6  8  1 11  6 11  8  8  4  1  1  6  6  9  3  1 11  1  6  4]\n",
      "[ 1  4  3  4  9  6  6  8  6  6  3 10 10 11  3  3  6  8  0 10] [ 8  6  8  3  9  1 11 11  8  6  9  5  5  5  8  8  8  3  3 12]\n",
      "accuracy: 0.2255859375\n",
      "1300 tensor(3.2118)\n",
      "[11  1  6 11  6 11 10  4  8 10 10  4  2  2  8 10  8  5  8  1] [ 3  6  6  1  1 11  8  9  5 10 11 11 10  9  1  8 11  8  9  6]\n",
      "[ 6  6  8  8  0  3  0  3  5  3 10  6  6  0  3  5 10  9  3 10] [ 9  4  6  5  8 11  8  3  5  6  1  6  6 10  8 10 10  6  5  5]\n",
      "accuracy: 0.18359375\n",
      "1400 tensor(3.1958)\n",
      "[ 8  8  6  8  4  8  5 10  0  5 10  6  6  8 10  8  8  0  6  8] [3 8 6 3 8 8 0 3 0 5 1 1 8 8 3 8 1 9 3 6]\n",
      "[ 3  3  8  3  3  6  1  9 10  8  8  8  1  6  9  3 10  9  9  5] [ 3  6  5  6 10  8 11  6  3  6  3  1  6  6  2  8 12  9  9  5]\n",
      "accuracy: 0.2373046875\n",
      "1500 tensor(3.0792)\n",
      "[ 8  0 11 11  1  7  6  4 11 10 11  8  1  8  8  6  1  5  6 11] [11  6  4  1  3  7 11  4 11  8  6  5  6 11  3  1 12  5  6  4]\n",
      "[ 8  4  4  8  9  2  6  0  6 10  6  6  6  5  1  8  1  8  6 10] [ 8  4  3  1  2  1  8  1  8  7  1  8  8 10  3  1  1  1 11  3]\n",
      "accuracy: 0.2568359375\n",
      "1600 tensor(2.9374)\n",
      "[ 6  5  6  8  9 11  3  6 11  1 10  8  7  8  9  9  6 10  1  6] [ 1  5 10  8  9  4 10  1  1  3  8  6  3  1  2  2  1 10 10  6]\n",
      "[ 6 10  8 10  6  6  8  1  8  4  3  3  2  8  9 11  6  3  6  1] [ 1  1  8  1  1  1  7  3  8 11  8  1  7  9  9  8  1 11  1 12]\n",
      "accuracy: 0.2705078125\n",
      "1700 tensor(3.0260)\n",
      "[ 1  6 11  9 11  5  8  3  3  8 10  6  8 10 10  8 10  8  8  6] [ 8  4 11  4 11 10  1 10  4  3 12  8  3 10 12  1  6  8  5 12]\n",
      "[11  8 10  4  8  8  3  8  6  8  5  3  8  8  8  1  6  4  6 10] [11  8 10 11  6 11  1  8  6  1  8  3  6 11  5  6  1  6  6 10]\n",
      "accuracy: 0.2783203125\n",
      "1800 tensor(3.0695)\n",
      "[ 0  6  6  8 10  4  8  6  1  8  0  4  3  3  1  6  3  4  0  1] [ 8  6  6  8  8 11  5 11  1  1  8  9  8  1  6  1  8  6  4  1]\n",
      "[ 8 10  6  3  6 11  5 11  6  8 10 11 10  3  6 10  8 11  6  6] [ 1 10  8  8 11  3  4  1  6  8  8  1  6  3  8  3  5  6  4 11]\n",
      "accuracy: 0.29296875\n",
      "1900 tensor(3.0242)\n",
      "[11  3  4 11  1  1  2  6  8  6  6  3  4  3  2  3 11  3  3  3] [11  3  6  6  8  8  9  6  6  6  6  8  6  8  9  1  4  3  8 10]\n",
      "[ 4  3 11  8 10  1  6  8  1  3 11 10 10  5  6  3 11  1  6  5] [ 4  3  4  8 10  1  1  8  6  8  6  8  8  7  6  3  4  8  1 12]\n",
      "accuracy: 0.2978515625\n",
      "2000 tensor(2.8244)\n",
      "[10 10  5  8  0  6  1  6  8  4  3 11  6  8  9  8  4  6  3  1] [ 1  3  5 10  3  6  6 11  3 10  8  8 11  8  2  3  2 11  3  6]\n",
      "[ 7  8  1  1  6  1  1  6 10  8  8  6  3  8 11  3  6  8  6  8] [12  3  6 10  6  1 10  6  3 11  1  6  5  3 11  8  1  5  9  3]\n",
      "accuracy: 0.2744140625\n",
      "2100 tensor(2.8772)\n",
      "[ 6  9  8  8  8  9  8  8  3 11  0  1 10  1  3  6  1  6 11  3] [ 1  6  6  8  3  2  3  7  5 11  7  3  3  6  8  8  6  6  3  8]\n",
      "[ 3  4 12  6  0 11  6  6  6  5  8  1 10  8  8  1  6 11  8  0] [ 8 11  8 11  9  4  3  6 11 12 11  1 10  8  8  1  6  4 10  6]\n",
      "accuracy: 0.265625\n",
      "2200 tensor(2.9762)\n",
      "[ 6 11  2  3  6  4  8  8  3 11  3  6  1  8 11  0  1  8  3  6] [ 1  2  9  9 11  6  1  1  8 11  3  1  1  3  4  4  3  3  3  1]\n",
      "[ 3  1  9 10  4  1  1  5  3  3  5  6  1  6 10  3  5  6 11  2] [ 8 10  2  1  9  3  8  5  8  8  3  6  8 11  5 12  5  1  4  2]\n",
      "accuracy: 0.283203125\n",
      "2300 tensor(2.9967)\n",
      "[ 8  6 11 10 12  8  1  1 11  5  6  3  6  8  2  8  4 11  6  6] [ 8  1  4  8  5  8  1  1  6  5  8 11  6  3  4  3 12  8  1  6]\n",
      "[10  5  8  4  6  8  1  8  6 11  8 10  1  8 11  8 11  6  6 11] [ 3  5  8 11 10  1 11 10  8  6  8 10  1  3 11  2  9  8 11  6]\n",
      "accuracy: 0.29296875\n",
      "2400 tensor(2.9058)\n",
      "[ 1  3  1  6 10  2  3  1 11  5 11  3  6  8  6  9  8  1 11 10] [ 3 10  8  3 10  6 10  1  1  3  1  3  4  7  8  7 12  1  4 10]\n",
      "[ 4 10 11  8 10  3  6  8  6  1 11  1  8  6  1  1  9  2 11  3] [ 6  5 11  5  7  3  5  3  1  1  1  6  3  1  1  1 11  7  6  8]\n",
      "accuracy: 0.2998046875\n",
      "2500 tensor(3.2053)\n",
      "[11 11 10  8  1  1  9  8  8  8  1  3  2  3  8  1  6  3  8  1] [ 6  8  8  5  1  1  4  3  3  8  6 10  9  1  3  1 11  1  3  1]\n",
      "[ 6  1  6  6  3  8 11  8  3  1  4 11  9  2  4  5  6  1 11 11] [ 1  6  6  3  1  1  6  1 10  4 11  6 11  6 11 12  8  1  8 12]\n",
      "accuracy: 0.2900390625\n",
      "2600 tensor(2.6634)\n",
      "[ 5  6  1  8  4 10  5  6 11 10  1  3  1 10 12  1  3  8 10 12] [ 1  6  8 10 11 10 11 11  1  5  8  3  1  3  2  1  8 10  5  3]\n",
      "[ 8  1  8 11  0 10  6  1  8 10  1  8  8  1 11  3 10  4  6  3] [ 1  8  3  9 11 10  6  3  8 10  1  3  8  4 11  3  3  9  6  3]\n",
      "accuracy: 0.2734375\n",
      "2700 tensor(3.1845)\n",
      "[ 5  5 10  0  8  6 10  8  8  0  0  1 11  2 11  8  1 10  6  4] [ 6  5  1  3  3  8  1  8  1  1  3  6  1  1 11  3  1 10  6  8]\n",
      "[ 5  6 10  0  6  4  6  8  8 10  4  1  8  4 10  1  6  4 11  3] [ 3  6  3  4  6 11  6  3 10  3  9  1  2  3 10  6  1 11 11  8]\n",
      "accuracy: 0.322265625\n",
      "2800 tensor(3.2235)\n",
      "[10  6  4  0  8  8  0  8  1 10  4  6  6  8  1 10 11  4  8  9] [10  6  9  6  1  8  1  8  6  6  8  5  8  3  1  8  1  9  1  2]\n",
      "[ 7  3 12  4  1 11  6  1  8  2  9  6  0  4  8  0  6  4  5  4] [ 1  6  7  9  1  4  6  1  8  2  6 11  0  6  1  1  1  9  5  4]\n",
      "accuracy: 0.2734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2900 tensor(2.8114)\n",
      "[ 8  5  4  1  6  8  0  3  0 12 10  1  5  9  6  8  5  4  3  3] [ 8  5 11  1  3 10  4  8  6 12 10  1 12  4  6 10 10  4 10 10]\n",
      "[ 8 11 11  1 10  2  1  1  1  5  3  8  5  6  8  8  0 11  3  1] [ 4 11 11  3  6  2  8  8  3  5  3  5  8  4  8  8  8  6  1  9]\n",
      "accuracy: 0.3037109375\n",
      "3000 tensor(2.8014)\n",
      "[ 1 10  6  6  8  5  6  6 10  3  9  6  3  3  2  6  8 10  8  6] [ 1  6  8  6  3 12  6  8 10  8  9  6  1  3  9  1  1  3  3  3]\n",
      "[ 6 11 10 10  6 11  1  6 11 10  6  2  5  6  6  1  1 10  1 11] [ 3  6  1 10  1  6  1  1  9 10  6  8 12  1 10  8  6  6  7  4]\n",
      "accuracy: 0.2958984375\n",
      "3100 tensor(3.1264)\n",
      "[ 5 11  5  7 11  3 10  3  1  1  1 11  6 11  1 11 10  1  3 10] [ 2  6  1  5 11  6 12  8  8  8  1  6  1  8  2  6 10  8  1  7]\n",
      "[ 1  6  5 10 10  5  5  0  8  4  8  1  6  4  4 11  0  6  1  2] [ 8  3 10  8 10  5 10  3  3  9  3  1 11  4  1  6  1 11  1  6]\n",
      "accuracy: 0.2802734375\n",
      "3200 tensor(2.7762)\n",
      "[10  4  1  5  6  1  6  1  1  1  6  6 11  8 11  6  1  8  1  1] [ 3  9 10  8  8  3  8 11  1  8 11  1 11 12  4  8  1 11  3  1]\n",
      "[ 6  2  5  1  1 10  1  5  8  9  1  1  2  6  3  6  1 11  1  2] [ 9 10 12  3  8  3  1 10 10  2  6  8  6  1  6  1  6 11  1  5]\n",
      "accuracy: 0.3115234375\n",
      "3300 tensor(2.8984)\n",
      "[ 1 10  8  1 11  5 11  1  4  6  4  8  6  8  2  4  4  1 12  3] [10  8  8  6  8  7 12  8  8  8  4  1  8  8  9  4 11  1  8 10]\n",
      "[10  1  8  8 10 10  4  5  4  6  4 10  1  8  4  6 11  6 12  1] [ 1  6  8  8 10  1 11 12  1  8  9  1  1  8  1  5  9 11  8  8]\n",
      "accuracy: 0.310546875\n",
      "3400 tensor(2.6828)\n",
      "[ 6  8 11  6 11  3  5  1  6  8  6  6  1 11  1  8  3  1  6  8] [ 3  5 11  6  3  8  1  1  6  1  8  8  6  7  8  3  8 11  1  1]\n",
      "[ 6 10  5  4  1  6  6  1  3 11  6  6  6  8  3  7  5 11  1  8] [ 8 10  5  9  1  1  4  1 10 11  5  1  1  1  8  5  8 11  6  8]\n",
      "accuracy: 0.2958984375\n",
      "3500 tensor(2.8162)\n",
      "[ 1  6  8  1 12  6  4  1  9  1 10  0  4  1  6 11 10  1  6  6] [ 6 11  6  1 12 11  9  5 12  6 10 10  4  1  1  6  3  1  6  4]\n",
      "[ 6  6 11  1  0  6  6 10  6  1 10  1  1  1 11 11 11  3  1  4] [ 6  6  1  1  1  6  6  1  1  1  3  8  1  0 11  4 11  6  1  8]\n",
      "accuracy: 0.298828125\n",
      "3600 tensor(2.8267)\n",
      "[11  6 11  9  3  1  6  8  5  1  1 10  6  1  6 10  1  6 11  1] [11  1  6 11  3  1 11  6 12 10  3  3 10  8  1  3  1  1  1  3]\n",
      "[ 0 11  6  6  1  1  6  0 10 11  8  6  1  2  8  1  8  1  0  2] [ 8  6  8  3  6  1  6 10 10 11 10  6  1  8  5 10  6  1  1  3]\n",
      "accuracy: 0.2919921875\n",
      "3700 tensor(2.9341)\n",
      "[ 5  4  6 11 12  2 11  6  6 11  5  5  3 10  8 10  3  8  4  0] [ 4  1  1  1  5 11 11 10 11  8  1  3  3  8  1  3  8  8  4  1]\n",
      "[ 3 11  1 11  6  8  6 10 11  5  8  8 10  1  7  3  1  9  4 11] [10  6  1 11  3  5 11  5  6 10  1  3  3  1  3  8  1  4  4 11]\n",
      "accuracy: 0.3017578125\n",
      "3800 tensor(3.2330)\n",
      "[ 6  6  2  6  4  0  5  8 11  9 12  2  6  4 10  6  3  6  6  8] [10  6  9  6 11  5  1  8  4  4  3  2  8  4  3  6  1  6  6  3]\n",
      "[ 1  5  8  5 10  6  8  4  1  1  6 12  6  6  9  5 11 11 10 11] [ 6 10 11  3 10  1  8  4  3  1  6  7 11  3  4 10 11  3  8  8]\n",
      "accuracy: 0.267578125\n",
      "3900 tensor(2.9528)\n",
      "[ 1  1  3  7  1  1  5  4  6  3 10  1  8 10  8  0  6 10  4 10] [ 1  8  8  5 11  1 10  3  1  7  8  1  8 10  6  5 11  5  1  1]\n",
      "[ 8 10  5  8  6 10  4  4  1  1 11 11 10 10 12 10  8  8 12  1] [ 8  1 12  1  1  3  4  4  1  1 11  8  3  1 10  6  1  8  3  8]\n",
      "accuracy: 0.333984375\n",
      "4000 tensor(2.9490)\n",
      "[6 6 1 1 1 6 1 4 8 6 6 4 8 1 0 4 1 4 1 3] [11  1  3 10  3  1  6  1  4 10  6 11  6  6  0  4  3  4  5 10]\n",
      "[ 8  1  6  3  6  1  5  5 11 11  8  6  8  2  5  6 11 11  1  6] [ 3  1  8  5  6  1 10  5  6  6 10  8  8  7 12  6  1  4  8  8]\n",
      "accuracy: 0.2919921875\n",
      "4100 tensor(2.9033)\n",
      "[ 9  8  8  6  1  6  3  6  4  0  4  5  1  1  1  3  4 11  8  1] [ 1  3  3 11  1  6 10  6  4  1 11  6 10  1  6  6  6 11  6  6]\n",
      "[ 1  1  3  8  8  4  6 11  3  6  2  9  6  6 11  6  8 11  1  6] [ 8  1 10  3  3 11  1  6  5  6 10  6  1  6  6  6  8  6  9 11]\n",
      "accuracy: 0.310546875\n",
      "4200 tensor(3.0546)\n",
      "[ 3  2  3  6  7 11  1  1 10  4  3  6  6  1  4 10  5  8 11  3] [ 8 10  3  6  5  8  8  1 10  1  3  6 11  1 11  8  3  1  1  3]\n",
      "[ 5  3  8  8 10 10  5 10  8  4 12  8 11  6  1  6  2  3 11  6] [ 3  8  8  8  6  8  4  8  3 11 10  3  4 11  1  6  7  3  8  6]\n",
      "accuracy: 0.30078125\n",
      "4300 tensor(2.6824)\n",
      "[ 1  6  1  6 11  5  6  5  8  4  9 11 10  4 11  1  5  1  8  7] [ 1 11  1 10  1  8 10  2 11  6  4  4 10  1  6  1  6 10  8  5]\n",
      "[ 5  3  6  0 10 10 11  9  4  4  8  5  4  8  4 10 10  8  1  8] [12 10  6  0  3  6 11  1  6 11  5  5  6  8  4 12  5  4  1  6]\n",
      "accuracy: 0.318359375\n",
      "4400 tensor(2.9284)\n",
      "[ 6  3  3 11  3  1  6  8  4  6  6 11 11 12 11  6 10  2  8  4] [ 8  8  3 11  1  1  3  6  4  6  6  1 11 10 11  6 10 12  3 11]\n",
      "[ 3  8  4  1  4  1  4  2  8  1  9 10  4  3  3  7  3  4  3  4] [3 3 9 8 4 6 4 2 6 1 4 3 4 6 1 8 6 9 6 4]\n",
      "accuracy: 0.3154296875\n",
      "4500 tensor(3.0113)\n",
      "[ 1  3 11  6  6 11  8  8 10 10  6  1  6  8  1  4  6 11  1  8] [ 3  3  1  1 10  6  3  8 10  6  6  1  3  8  8  4  6 11  8  6]\n",
      "[ 4  2 11 10  1  6  7  8  8  2  5  5  5 11  6  1  6  4  8  1] [ 8  0  4  6  1  1  7  1 10  5  5 12  5 11  6  8  6  4  5  1]\n",
      "accuracy: 0.30078125\n",
      "4600 tensor(2.8316)\n",
      "[10  6  3  8  2 10  8  3  1 11  6  6  1  2 10  6 11  7  3  9] [ 5  8  3  8  9  3  1  8  1 11  6  3  8 10  5  6  4  5  2  1]\n",
      "[ 8 11  6  8 10  1  2  4  9  5  5  5  3  2  8 11  3  5  6 11] [ 3 11  6 11  5  8  2  7  9  5 10 12 12  1  8  6  3  6 11 11]\n",
      "accuracy: 0.2978515625\n",
      "4700 tensor(2.6606)\n",
      "[ 3  1  3 10  8  1  3  6  4  5  8  8 11 11  2 11 10  4  6  0] [10  4  1 11 11  6  3  8 11  1 10  1  7  1 12  4  3  8  3  1]\n",
      "[ 3  6  1 12 11  1  0  1  1  8 11  8  8  8  6  5 10  8  9 11] [10  1  9  5  4  8  0 10 11  5  6  3  5  3  1  5 12  8 10 11]\n",
      "accuracy: 0.3203125\n",
      "4800 tensor(2.8885)\n",
      "[ 9  1  6  9  2  4  8  8  6  8  8  1  4 11  6  1  4  3  8 11] [ 8  1  6  9  9  6  3  8 10  5  8  1  6 11  3  8  1  3  1  6]\n",
      "[11 11 12  1  0  8  8  6  4  6  8  6  9 11  9  1  3  1  1  6] [ 6 11  3  1  9  1  3  6  6  6  8  5  4 11  8  1  3  6  5 11]\n",
      "accuracy: 0.3154296875\n",
      "4900 tensor(3.0403)\n",
      "[ 1  6 12  6  4  1  8  3  8 11  1  5  8  8  8  8  2  8  4  6] [12 11  3 10  3  3  8  1  6  6  8  7  8  5  8  8  6  5  8  6]\n",
      "[ 8  1  4  5  5  0 11  6  1  2  1  6  6 12  8  1  3  4  9  4] [ 1  1  4  6 12  1  6 11  8  7  1 11 11  8  8  1  5  9  4  6]\n",
      "accuracy: 0.271484375\n",
      "5000 tensor(2.8185)\n",
      "[ 9  6 12  4  1  7 12  9  1 11 11  5  1  6  6  0  6  1  9  6] [ 9  6  5 11  1 11  3 11  6  1  1  8  2  6  6 11  8  1  6  1]\n",
      "[ 4  8  5  6  0  1  4  1  6  5 12  8  6  6 10 10  6  5 11  9] [ 6  5 10  1  6  6  1 10  6 10  3  6  6  6  3  8  6  5  6  2]\n",
      "accuracy: 0.298828125\n",
      "5100 tensor(2.9191)\n",
      "[ 6  2  3  8  3  6 12 10  3  8  8  5 10  5  5  8  6  8  9 10] [11  6 10  3  3  8  3  1 12  3  1 10  5  3  8  3  4  3 11 11]\n",
      "[ 6  2  6  9  0  6  7 12  1  6  1  6  8  8  8  3  1 12  5 11] [ 3  9  1  8  4  6 12  7 10 11  6  1  1  1  8  8  5  5 10 11]\n",
      "accuracy: 0.2998046875\n",
      "5200 tensor(2.6064)\n",
      "[ 4 10  2  5 10  8  6  2  3  5  6  4 10 10  6  1 12 12  4  8] [ 9 10  6 10  5  3  1 11  8  7  6  6 10  3  6  6 10  5 11  1]\n",
      "[ 1  4  4 11 10 10  3  1  8  4  8  8  8 11 11 11 12  4  1  6] [ 8  4  6 11  6  5  8  1 12  4  1  6  8  4 11  4  3  4  3  6]\n",
      "accuracy: 0.3125\n",
      "5300 tensor(2.6343)\n",
      "[11 11  6 11  3  6  8  4  6 11  1  8  8  1  0  8  1  6  1  3] [ 4  6  6  9  8  6  3  8  1  3  8  8 10  8 11  3  8  8 10  3]\n",
      "[ 3  1  6  6 10  3  4  9  8  6  8  6 10  6  4  5  1  1  3 10] [10  6  8  8  5  3  4 10  8  8  8 10  3 11  9  5  8  8 10  1]\n",
      "accuracy: 0.326171875\n",
      "5400 tensor(2.9012)\n",
      "[11  1  1  3  6  6  6 11  1  4  6 10  5  9  1 12  6  3  8  6] [ 6  1  9 10  6  6  3  6  1 11  6  1  5  9  1  5  1 12  6  3]\n",
      "[ 7 11  6  6  1  9  1 11  3  1  2  1  1 11 12  3  9 10  4  4] [ 4  6  6  1  6  4  1  6 10  1  4  3  1  1  3 10  9 10  4  6]\n",
      "accuracy: 0.306640625\n",
      "5500 tensor(2.9072)\n",
      "[ 8  1  1 10 11  6  8  8  1  8  2  8  6  6  6  5  4  6  6 10] [ 3 10  8  3  6 10 10  8  1  8  5  3  3  6  8  5  6  6  6  3]\n",
      "[11  7  6 11  6  4  4  3  1  6  4  0  1 11  1  9  1 10  3  2] [ 8  2 11  6  1 10  4  3  6 10  4  6  8  4  1  8  8  3 10  6]\n",
      "accuracy: 0.3251953125\n",
      "5600 tensor(2.9689)\n",
      "[ 3  6  1  3  6  0  4  8  4 10  1  8  5  1  5  6  8  9 12  4] [10  1  8  3  3  5 11  1  6 12  8 10 10  1  3  6  6  8  6  1]\n",
      "[11  6  6  5  8 10  8  8  9 11 11  3  6  5  6  9  8  2  6  5] [ 4  6  8  5  1  5  5  3  9  4  6  8  1  6  8  2  8  5  1 12]\n",
      "accuracy: 0.30078125\n",
      "5700 tensor(2.9074)\n",
      "[ 9  1  6  1  6  8  1 11  2  1  6  3 11  4  5 11  8  1  6  6] [ 9  8  6  3  1  1 10 11  9  6 11 10  6  9 10  8  9  6  6 11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  4  6  3  6  8 10  7  6 12 11  1  8  6  1  1  3  6 10  0] [ 1  9  8  3 11  1 11  9  6  5  1  1  3 11  1  6  5 11 10  0]\n",
      "accuracy: 0.3134765625\n",
      "5800 tensor(2.8075)\n",
      "[ 1  6  9  8 12  1  6  2  9 12  8  6  8  6  1  5  9  4 10 10] [10  6 12  8  5  1  8  9  6  8  3  1  3  6  1  3  4  4  5 10]\n",
      "[ 2  1  3  1  8  1  6  4  3 10  5  7 10  1  6  4  4  8 10  2] [12  3  8  1  3  0  8  2 10  8  1  7  8  8  3  1 11  8  8  4]\n",
      "accuracy: 0.3310546875\n",
      "5900 tensor(2.7979)\n",
      "[ 0  3  3  3 10  1  3 11  8  9  1  1  1  8  8 11  3  2 12 10] [10  8  3  3  1  1  8 11  3  9  1  5  6 10  3  1  8  9  7  6]\n",
      "[ 1  8 11  4  3  6  0  5  0  1 11  1  1 10  8  5 11  3 11 11] [ 8  4  4  4  1  3  5  5  1  8  8  8  1 10  1  5  6 10  6  1]\n",
      "accuracy: 0.296875\n",
      "6000 tensor(2.9932)\n",
      "[ 1  9  1  1 11 11  2  1  8  4  6  1  1  1  8 10  1  6  6  6] [ 1  1  1 10  6  8  9  8  8  6  8  3  3 10  6  3  3  1  1  1]\n",
      "[ 6  6  4  8  8  1 10  4  8  1  2  6 11  8  6 10 11  3  5  1] [11 11  4  8  8  1 12  4  1  8  9  6  1  5  8  3  3  3 12  1]\n",
      "accuracy: 0.3154296875\n",
      "6100 tensor(2.6802)\n",
      "[ 1  3 11  6  2  1  1  1 11  4 12  3  6  1  8  5  3  4  8 10] [ 6  8  1  8  1  6  1  1  6  4 12  6  6  6  3  5  3 11  6 10]\n",
      "[ 9  2 10  8  8  1 11 12 11  1  3  8  6  8  6 11  8  8  6 12] [ 8 11  3  8  1  6 10  8  6  8  8  8  1  8  1 11  8  8  3  5]\n",
      "accuracy: 0.2880859375\n",
      "6200 tensor(2.6850)\n",
      "[ 6  1  6  8  3  4  2  6  6  6  8 11  3  0  5  0 12 11  8  4] [ 1  8  6 10  3 10 10  1  6  8  3  6  3  1  1  1  5 11  3  6]\n",
      "[ 6  9  4 10  5  3  6  8  4  8  4  3 11  6  6  4 10 10  6 11] [ 3  6  4 10  5 10  1 10 11  1 11  3  8  6  6  3 11  3  8  1]\n",
      "accuracy: 0.2783203125\n",
      "6300 tensor(2.7875)\n",
      "[ 3 11  2 12  2  8  1  8  3 11  1 10 10  1 10  1 10  9  6  3] [10  6  6  8  6  1  6  6  3 11 10  3 10  1 10  1  3  4  6  3]\n",
      "[ 1  8  3 10  6 12  8  4  2  1  1  5  3  1  6  6  4  6  8 10] [ 6  3  5  8  6 12  8 11  2  6  3  5  8  8  6  8  4  1  3  1]\n",
      "accuracy: 0.2861328125\n",
      "6400 tensor(3.0699)\n",
      "[ 6 10  4  1  8  8  1  5  9 10  1  8 10  3  1  5  1  4 11  3] [ 6  8 11  8  3  3  1  5  9 10  1  1  8  3  3  3  1  9  8  3]\n",
      "[ 6  8  2  8 10  1  3  1  5  8  9  3 10  1  1  8  1  6  5  1] [ 1  1  1  8  8  3  8  5  6  8  9  6 10  3  6  8  8  8 10  1]\n",
      "accuracy: 0.3193359375\n",
      "6500 tensor(2.8527)\n",
      "[ 6 10 11  1  4  8  5  8  6  5  5  1  1  8 10  2  6  6 10  0] [ 6  4  4  1  4  8  1  8  3  2 12 11  6  8  8  5  1  1  1  3]\n",
      "[ 1  4  0  9  6 10  5 11 10  8  5  6 10 10  8 10  6 12  3  1] [ 3 11  1  9 11  2  3  1  8 11  5  1  3 10  8  3 11 11  8 10]\n",
      "accuracy: 0.2958984375\n",
      "6600 tensor(2.8506)\n",
      "[ 8 12  3  1 11  5 10  6  8  5  8  6  5  8 12  9 11 11  3  3] [ 1  6 10  1 11  1  5 10  3 10  3  6  5 11  3  9 11 11  8 11]\n",
      "[ 4  8 11 10  8 11  3  6 11  1 11 11  1  1  4  4  6  8  5  6] [ 4  1  6 10  8 11  3 11 11  6 11 11  6  1  4  4  1  8  5 10]\n",
      "accuracy: 0.3291015625\n",
      "6700 tensor(2.7098)\n",
      "[ 8  4  8  7  8  8  5  6  4  2  6  1  4  2  6  1  2  9 11  2] [ 3 11  8  8  1  5  1  6  6  6  1  1  1  6  6 10  9  4  6  6]\n",
      "[ 3  6  3  2  9 11  5  6 10  2  0  8  6  6  6  1  9  8  6 10] [11  6 10  4  7 11  1  6 10  1  1  8  2  1  6  6  9  1  6  1]\n",
      "accuracy: 0.3046875\n",
      "6800 tensor(3.0395)\n",
      "[11  2  8  5  8  4  8  5  6 11  5  3  6  6  5  2  6  6  3 10] [ 8  1  1  5  8  3  8  8 10  6  3 11  3  8 12  0  8  6  3  3]\n",
      "[ 8  6  8  1  6  1 11  6  3  6  1  1  8  1  8  1  8  8 11  0] [ 8  6 10  6  6  1  6  1  6  6  1  9  8  0  8 10  8 11  4  3]\n",
      "accuracy: 0.291015625\n",
      "6900 tensor(2.8560)\n",
      "[ 8  1  1  5 11 10  5  2  1  1  1 10  6  4  4  4  1 10  8 11] [ 8  1  6  5  6 12  1  6  1  1  8 10  8  3  9 11  4 10  1 11]\n",
      "[12  6  6  1  4 10  5  8  0  5  1  6  8  4  1  3  7 11 10  6] [ 5  8  1  1  6  1 12  6  3 10  1  1  1  4  4  3 12  1 10  8]\n",
      "accuracy: 0.322265625\n",
      "7000 tensor(2.7856)\n",
      "[ 7  1 11  1  5 10  9  6  2  5 11  4  9  6  1 10  8  3 10  8] [ 6  6 11  8  8  3  8  1  6  1 11  4  9  6  1 10  3  3  3  8]\n",
      "[ 3 10  2  8  1  1  4  3 12  7  6  5  9 10  3 10  8  4  0  8] [ 3  3  8  3  6  6 10  3  5 11  6  1  4  3  3  5  3  8  1  8]\n",
      "accuracy: 0.3583984375\n",
      "7100 tensor(2.6339)\n",
      "[ 4 10  6  1  9 11 11 11  3  3  8 10  3 11  8  6 12  8 10  8] [ 4  6  1  1  9  6 11 11  3 11  8  5  3 11  8  1 10  8 10  1]\n",
      "[10 11  6 11  4  8  8  6  6  3  6 10  9  8 10  6 11  4  5  3] [12  8  8 11  3  8  3 11  1 10  6  8  4  8  3  8  6  4 10  1]\n",
      "accuracy: 0.2783203125\n",
      "7200 tensor(2.7110)\n",
      "[11 10  6  8  2  9  6  1  6  3  5 11  1  1 10  1 12  6  6  5] [11 10  1  1  9  4  6  8  6 10 12  6  6  6 10  1 10  1  1 10]\n",
      "[ 8  9  4 10  1  9 10  1  3  0  0 10  5  1 10 12 10 12 10  4] [ 3  9  6  3  3  2  6  8  3  1  3 12 10  6  6 12 10  7 10  4]\n",
      "accuracy: 0.2978515625\n",
      "7300 tensor(2.9057)\n",
      "[ 5 11  5  5 12  6  8  6  9 10  6 10 10 10  4  4  7  6 11  5] [ 5 11  4  5  2  1  3  1  9 10  3  2  8  3  6  4 12  6  6  3]\n",
      "[ 5  6  1 11  5  4  0  5 10  6  1  6  4  8  9  1 10  8  4  5] [ 1 11  3 11  8  9  9  5 10  1  1  6  6  8 11  3 10  8  9  3]\n",
      "accuracy: 0.330078125\n",
      "7400 tensor(2.4090)\n",
      "[ 5  8  5  8  4  4  1  5  5  1  4  1  2 11  8  5  3  1 10 11] [ 8  6  5  5  4  6 10 12 10  5 11  1  6  4  3  5  8  1  5 11]\n",
      "[ 8 11  1  5 11  6  8 12  8  1  7  6  6  8 11 11  3  6  1  8] [ 1 11  1  6  1 11 10 10  8  1  5 11  6  8  8  4  3 10  3  3]\n",
      "accuracy: 0.3271484375\n",
      "7500 tensor(2.6833)\n",
      "[ 1  0 11 10  1  1  8  8  4  1 10  1  1  6  1  8  6  8  5  8] [ 3  0  1 10  6  3  8  8  4  1 10  1  1  1  8  8 11  6  3  1]\n",
      "[ 6 11  3  8  5 10  9  6 11 10  6  6 11  8  1  6  8  8  6 11] [ 6  1  8  1  8  3  1  6  4  5  8  3 11  8  6  6 12 10  1 11]\n",
      "accuracy: 0.3193359375\n",
      "7600 tensor(2.7423)\n",
      "[ 1 12  8  1  4  8  9 10  6  8  5  8  8  4  1  8 11 10 10  8] [ 1 12  1  8  4  8 11 10  1  8 10  1  8  6  6  8  1  1  1  1]\n",
      "[ 8 10  8  9 10  8  4  0  6  8  1  3  6  9  6  6  6  8 10  1] [ 1  6  3  4 10  1  4  1  8  1  1  3  5  4  6  1  7  3 10  1]\n",
      "accuracy: 0.3134765625\n",
      "7700 tensor(2.8643)\n",
      "[ 5  5  9 10  1  7  3  7 11  1 11  8  1  3  8  3  7  2  8  8] [ 5 10  9  3  1 10  6 11  6  1  6  3  1  5  1 10  8  6  3  3]\n",
      "[12  5 11  5  1  8 10  1 10  8  1  6  8  4  0  3  8 10  5  9] [ 3 10 11 12  8  1  8  1 11  1 12 11  8  6 10  3 10 10  5 11]\n",
      "accuracy: 0.296875\n",
      "7800 tensor(2.6659)\n",
      "[11  2  6  8  8  2  5  3  8  8 10  8  5  5 10  6  6  6  9  1] [ 6  2  6  8 10 12  5  3  1  1  3  9  4 12 10  1  1  8  2  3]\n",
      "[ 6  7  8  4  1  1  5  4  6 10  1  8  5  5  2  6  2 10  0  7] [ 6  7  1 11  1  1  1  4  6  5  6  8 10  1 12  1  1  3  1  9]\n",
      "accuracy: 0.314453125\n",
      "7900 tensor(2.9103)\n",
      "[ 0  0  3  2  2  7  2  1 10  1 12 12 11 10  6  1  4  8  1 11] [ 7  6  1  2  9  3  9  1  5  5  5  5 11  8  1  1  9  8  6  4]\n",
      "[10  6  8  0  5  8 11  8  6 12  8  8  4  4  4  6  8  6  8 11] [10  8  5  6  1  8  1  8  3 12  8  1 11 11  4  6  3  1  8  1]\n",
      "accuracy: 0.2802734375\n",
      "8000 tensor(2.6555)\n",
      "[ 3 10 12  6  1  1  5  6  3  6  6  1  4  4  1  5  3  8  3  1] [ 3  5 12  1 11  6  2  6  1  5 10  1  1  4 10  1  3  5  3  6]\n",
      "[11  6  7  9  1 10 10  1  6  1 10 11  8  2  6 10  6  1 11  5] [ 4  3  8  9  1  5  1  8  6  8 10  6  8  7  6  3  6  8 11  3]\n",
      "accuracy: 0.296875\n",
      "8100 tensor(2.6740)\n",
      "[ 4  3  5  1  9  3 10  8  3 10  6  1 10 10  6  1  6  6  8 10] [ 1  3  5  1  4  7 10  8 11  3  6  1 10 10  8  8  1  6  3  3]\n",
      "[ 1  8 11  6  6  8  6  0  5  9  8 10  8  8  4 10 10  1  5 10] [ 8  3 11 11  6  8  1  6  0  1  1 10  8  3  4  3 12  8 12 10]\n",
      "accuracy: 0.3251953125\n",
      "8200 tensor(2.7495)\n",
      "[11  1  8  4  8  6 10  1  1  2  8 11  6  8  1 11  5  1  6  6] [11  6 12  3  8 10  6  8  1 12  6  4  1 12  6 11  4  1  6  6]\n",
      "[ 1  1  4  6  4  1  5  8  6  8  8  8  6  8  1 11 12  1 10 11] [ 1  1  9  1  9  9  6  3  6  8  8  1  1  8  1  6  7  1 10 11]\n",
      "accuracy: 0.3125\n",
      "8300 tensor(2.7497)\n",
      "[ 5  8  6  5 10  2  8  1  6  6  1  8  1  4  6  1  6  1  4  6] [12  1  8  5 10 10  1  1  8  6  1  5  1  4  1  1 10  3  8  6]\n",
      "[12  3  6  6  6  4  9  1  6  1  4  3 11 11  8  3 11 11  3  8] [ 2  1  3  8  6 11  4  1 11  6  8  5  1  4  8  8 11 11 10  5]\n",
      "accuracy: 0.3251953125\n",
      "8400 tensor(2.5054)\n",
      "[ 5  6  8  0  6  8  3 12 10  4 10  1  4  8  1 11  1  6  6  6] [ 8  1 12 11  1  3  8  3  5 11  6  1  6  3  1  4  6  8  1 10]\n",
      "[ 5  3  6  8  1  1 10  3 10 11  4  1  1  4  1  6  8  6  6  6] [ 7  3 11  8  1  1  6  3  8  8  9  3  1  9  8 11  3  6  1  7]\n",
      "accuracy: 0.302734375\n",
      "8500 tensor(2.8045)\n",
      "[ 9  8  1  4  6  6  4 11  7  1 12  6 10  8  8  1  8  3  8  5] [ 2  8  1  4 11  1 10 11  1  6  8  3  7  1  3  6  4  8  3  3]\n",
      "[ 4  6 11  8  6  6  8  8 12 11  8  8 11  4 10  6  1  5 10 10] [ 9  6  1  1  3  6  3  3  5  3  1 10 11  4  5 10  1  5  5 10]\n",
      "accuracy: 0.314453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8600 tensor(2.7940)\n",
      "[10  8 11 11  2  1  3  6  2  1  8 11  1 11  6  6  8  5  8 12] [ 5  3  4  1  9  0  8  6  8  1  3  8  1  8 11  8  8  5  8 10]\n",
      "[ 4 11  6 10  8 10 12  1  6  1  8  6  1  1  6  6  8 11 10  7] [ 4  1  6  3 10 10  6  3  6  1  6  8  3  4  6  6  8  8 10  4]\n",
      "accuracy: 0.314453125\n",
      "8700 tensor(2.7795)\n",
      "[ 6  3  6  8  1  8  1 11  7  8  8  6  8 10  1  8  8  8  6  3] [ 8 10  1  4  3  1  1  9  8  5  8  5  8 10  1  8  8  8  6 10]\n",
      "[ 3  6  6  4  4  6  4  9  3 12  6  3  4 10  5  2  8  5  1  5] [ 3 11  6  4  4 11  4 11  1  3  3  3  8  5  3 11  1  3  8  6]\n",
      "accuracy: 0.3330078125\n",
      "8800 tensor(2.6917)\n",
      "[ 2  8 11  1  8 10  8  5  5  4 10  6  8  6  1  5  6  6  1  2] [ 3  8  4  8  1  8  8  7 10 11  3 10  5  1  1  5  1  1  1  2]\n",
      "[10  1  5  1 10  6  4  0  6  8  8  2  8  1  5  5  5 11  2  8] [ 8  8 12  1  7  1 11  1  1  3  1 11  1  8  1 10  5 11  2  1]\n",
      "accuracy: 0.32421875\n",
      "8900 tensor(2.8389)\n",
      "[ 1 11 12  3  6  1  2  0  3  4  7  4 10  1  1  9  1  8  6  1] [ 4 10  3 10  6  8  2  2  3  4 10  6  6  1  5  9  6  5  1  1]\n",
      "[ 1  8  3  3  1  8  8  3 11  8  8 10  8  6  3  8  1  6  8  1] [ 8  1  8  5  4 10  6 10 11  3  8  1  8  8  8  3  1  6  8  1]\n",
      "accuracy: 0.3427734375\n",
      "9000 tensor(2.7909)\n",
      "[11  1 10  4  9  5 11 12  7  8  7  5  6  3  6 11 10  3  1  6] [ 1  1  5 11  1  7  1  1  5  3  6  1  6  3  6  6  8  3  8  6]\n",
      "[ 4  6 10  8  6  5 11  1  8  3  8  1  6  9  3  5 10  5  6  8] [ 4  6 10  8 11  1 11  5  3 10  6  8  1  4  3  8 10  5  1  8]\n",
      "accuracy: 0.33203125\n",
      "9100 tensor(2.7365)\n",
      "[ 6  6  8 11  6 11  6  1 11  8  1  1  2 10  8  6 11  1  4 10] [ 6  6 10  3  8  4  6  8  6  8  3  5 10  5 12  6  6  3  4  5]\n",
      "[ 8  6  6  6 10  6  2  1  8 12  1  6  2  6  6  3  8  3  2  8] [ 1  2  1 10  3  1  2  1  8  2  8  6  1  1  6  3  3  5  9  1]\n",
      "accuracy: 0.33984375\n",
      "9200 tensor(2.7018)\n",
      "[ 5  8  8  1 11 11  7  6  8  1  8  4  6  0  6  2  8  4  4  5] [ 3  1  5  1  6  8  7  1  8  1  3  1 11  1  6  4  5  4  1 10]\n",
      "[ 8  9 12 11  5  5  3  1  4  3 11 11  2  6  5  3  4  8  4 12] [ 3  4 12 11  1  5  8  3  4 11  1  1 10  3 10  3  4  6 11 12]\n",
      "accuracy: 0.3125\n",
      "9300 tensor(2.6435)\n",
      "[ 3  6  5 10  2  8  8  8  1  1  0  6 11  7  9  6 11 10  1 11] [ 1 11  3  6 11  6  6  1  8  3  0  6  1  1  9  3  1  5 10  9]\n",
      "[ 8  8  1 11  6  1 11  6 10 11 10  1 10  6  3 11  3 12  8  4] [ 8  8  6  4  8  6  4  6  3  6  6  1 12  6 10  6  3  7  1  6]\n",
      "accuracy: 0.34765625\n",
      "9400 tensor(2.9988)\n",
      "[ 1 12  7  4 10  8  1  8  8  2  6  5  8 12  0  5  8  3 12  1] [ 1  5  7  4  7  6  8  1  6  2  6  5  8  7  0  5 10  5  3  8]\n",
      "[ 6  8  1  6  8 11  6  7  3 11  1 10  5  7  9 10  1  1 10  7] [ 6  8  6  8  3  6  6  5  3 11  3  8  5 12  4  3  1  8  8  3]\n",
      "accuracy: 0.31640625\n",
      "9500 tensor(2.7479)\n",
      "[ 6  8  6  4  2  4  0  8 11  4  6  8 10  1  8  1 11  1  3  7] [ 6  3  1  6  2 11 10  8 11 11  3  3  1  3  8  8  1  8  3 12]\n",
      "[10  8  8  4  9  4  8  3 11  1  6  8  1  6 10  8 11 11  0 10] [ 8  8  6  9 10  4  8  1  4  8  6  5  8  8 10  1  1 11  1  3]\n",
      "accuracy: 0.3134765625\n",
      "9600 tensor(2.7709)\n",
      "[ 1  4  6  4 11 10  2 11  3  8  8  2  8  0 12  4  9  8  3  6] [ 6  1 11  7  3  3  5  5  8  8  5  9  4  6 10  4  8  6  1 11]\n",
      "[ 8  1  1  3  1  8  9 11  8  5  6  5  5  8  8  8  1  8  1 10] [ 8 11  8  5  6  5 11  8  8 12  6  8  3  1  1  3  8  3  5 10]\n",
      "accuracy: 0.2939453125\n",
      "9700 tensor(2.5317)\n",
      "[10  3  8  8  9  6  1  8  6  1  8  4  1  6  1 10  8 12  5  8] [ 6 10  2  8  4  6  1  3  6  1  8  8 10  6 11 12  8  8  8  3]\n",
      "[ 1  3  8  3  1  1  6  8  1 11 11  0 11  6 11 11 12 10  4  6] [ 1  3  3 10  8  8  3  1  1 11  8  9 11  8  6  6  3  6  6 11]\n",
      "accuracy: 0.3525390625\n",
      "9800 tensor(2.6323)\n",
      "[ 1  4  9  1  8  8  6  8  1 10 11  8  9 11  8  6  8  6  4  1] [ 8  4  8  1  8 10  1  8  3  3  3 10  9  3  8  1  1  6 11  3]\n",
      "[ 1  8 10  8  3  8  6 10  3  9  1  8  6  1  8  2  8  5 11  1] [ 6  8  3  1 10  3  8  3  3  4  1 10  1  1  1  1  8  5 11  6]\n",
      "accuracy: 0.302734375\n",
      "9900 tensor(2.4487)\n",
      "[ 1  1  3  4  9  3  5 10  7  6  6  2 11  8  1  1  3  6  1  4] [ 8  8  6  8  9  8  1  8  7 11  6  1  6  1  8  8 10  6  1 11]\n",
      "[ 6  5 11  1  1  9  5 11  9  6  6 11  8 10  8  6  6  3  5 10] [ 6 12 12  1  2  3  3  6  8  3 10 11  8  2  6 11  6  3 12  3]\n",
      "accuracy: 0.30859375\n",
      "[ 1  5  9  6 10  3 10  7  4  6 11 11  6  5  1  1  5  5  4  6] [ 1 10  9  6  8  3 10  1  6  6 12  6  1  3  1  1  1 10  8  1]\n",
      "[ 8  2 11  6 10  8  1 10  4  4  9 11 10  8  4  8 10  3 11  8] [ 8  2  8 11 10  3  6  3  1 11  4  6 10  3  4  8 10  3  8  3]\n",
      "[ 8  1  1  5  3 11  6  8  5  6  3  6  6 10  6 10 11  3  1  6] [ 8  6  5  5 10 11  6  6  9  6 10  6  6  1  6  3 11  8  8  3]\n",
      "accuracy: 0.31953125\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "for iteration in range(1):\n",
    "\n",
    "    P_HIDDEN_DIM = max(int(np.random.normal(25, 30)), 5)\n",
    "    M_HIDDEN_DIM = max(int(np.random.normal(35, 30)), 5)\n",
    "    vocab_size = 13\n",
    "    tagset_size = 13\n",
    "    EPS = random.uniform(0.005, 0.15)\n",
    "    ITER = 10000\n",
    "    P_EMBEDDING_DIM = vocab_size\n",
    "    M_EMBEDDING_DIM = vocab_size\n",
    "    P_HIDDEN_DIM = 18\n",
    "    M_HIDDEN_DIM = 10\n",
    "    EPS = 0.02806\n",
    "\n",
    "    print(\"iter: \", ITER, \"  phid: \", P_HIDDEN_DIM, \"  mhid: \", M_HIDDEN_DIM, \"  eps: \", EPS)\n",
    "    newweishts = weightloss(weights, 0.005)\n",
    "    model = LSTMTagger(P_EMBEDDING_DIM, M_EMBEDDING_DIM, P_HIDDEN_DIM, M_HIDDEN_DIM, vocab_size, tagset_size, batch_size = batch_size)\n",
    "    loss_function = nn.NLLLoss(weight = newweights[0])\n",
    "    loss_function2 = nn.NLLLoss(weight = (newweights[1]))\n",
    "    loss_function3 = nn.NLLLoss(weight = (newweights[2]))\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.2)\n",
    "    \n",
    "    for epoch in range(ITER):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "        for i in data_loader:\n",
    "            # Step 1. Remember that Pytorch accumulates gradients.\n",
    "            # We need to clear them out before each instance\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Also, we need to clear out the hidden state of the LSTM,\n",
    "            # detaching it from its history on the last instance.\n",
    "            model.p_hidden = model.init_hidden(P_HIDDEN_DIM)\n",
    "            model.m_hidden = model.init_hidden(M_HIDDEN_DIM)\n",
    "\n",
    "            # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "            # Tensors of word indices.\n",
    "            p, m, l, mask = i['p'], i['m'], i['l'], i['mask']\n",
    "            #print(m)\n",
    "            tag_scores = model(p, m, mask)\n",
    "            # Step 3. Run our forward pass.\n",
    "\n",
    "            # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "            #  calling optimizer.step()\n",
    "            #print(targets[:1])\n",
    "            loss = 0\n",
    "\n",
    "            loss += loss_function(tag_scores[0], torch.t(l)[0])  \n",
    "            loss += 0.5 * loss_function2(tag_scores[1], torch.t(l)[1])\n",
    "            loss += 0.5 * loss_function3(tag_scores[2], torch.t(l)[2])   \n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            break\n",
    "        if(epoch%100 == 0): \n",
    "            print(epoch, loss)\n",
    "            accuracy = 0.0\n",
    "            c = 0\n",
    "            for j in range(2):\n",
    "                for i in data_loader:\n",
    "                    c+=1\n",
    "                    p, m, l, mask = i['p'], i['m'], i['l'], i['mask']\n",
    "                    tag_scores = model(p, m, mask)\n",
    "                    pred = tag_scores[0].max(1)[1].numpy()\n",
    "                    truth = torch.t(l)[0].numpy()\n",
    "                    print(pred[:20], truth[:20])\n",
    "                    accuracy += np.average(pred == truth)\n",
    "                    if (c>=1): break\n",
    "            print(\"accuracy:\", accuracy/c)\n",
    "\n",
    "    accuracy = 0.0\n",
    "    c = 0\n",
    "\n",
    "    for j in range(10):\n",
    "        for i in data_loader:\n",
    "            c+=1\n",
    "            p, m, l, mask = i['p'], i['m'], i['l'], i['mask']\n",
    "            tag_scores = model(p, m, mask)\n",
    "            pred = tag_scores[0].max(1)[1].numpy()\n",
    "            truth = torch.t(l)[0].numpy()\n",
    "            if(c<4): print(pred[:20], truth[:20])\n",
    "            accuracy += np.average(pred == truth)\n",
    "            if (c>=1): break\n",
    "    print(\"accuracy:\", accuracy/c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  6 10  5  8  3  6  6  8 10 11 11  8 10  1  7  0  6  8  8] [10  1 10 10  8  3 10  1  3  1 11  6  8 10  6 11 11  3  8  8]\n",
      "[ 1 10  6  2  2  3  5 10  8  6  6  1  6 11  1  6  8  8  6  6] [ 3  3  1  1 11  1  3  3  7  5 11  6  6  6  5 12  1  8  6 11]\n",
      "[ 8  5  1 10  8  1 12  5  5  4  9  6  1  1  8 10  5 12  1  3] [ 8 10  6 12 10  6  9  1 10  4  9  8  6  1  8  3 10  8  9 10]\n",
      "[ 6 10  8  7  8  8  3  8  8  6  1 11  4  6  2  2  1 10  6  8] [ 1  3  8 10  8  3 10  8  6 11  7  6  4  6  3 11  6  5 11  3]\n",
      "[ 1 10 10  5  8  4  4  6  1  5  1 10  6  8  7  1  4  8 12 10] [ 8  3  1  1  3  8  8  8  8  4  3  5 11  8 11  1  4  1  9  8]\n",
      "[ 9  4  1 10 10  1  5  4  1  6  0  2 11  9 10  3 10  8  1  5] [11  4  6  3  8  1  5 11  1  3  6  1 11  9  6 10  1  8  1 12]\n",
      "[11  5  5  3 10  4  8  1  2  6 11 12 11  6 10  8  6  6  4 11] [ 4  6  5 12 10  3  3  8  9  6  1 10  4 11 10  8  6  1  6  1]\n",
      "[ 4  1  8  3  4  6 10 11 10  6 11  2 10  8  1  7  8  5 11  1] [ 8  1  3  8 11  4  3  6  3 11 11  1 10  6  6  8  1 10  6  9]\n",
      "[ 6 11  5  5  1  2  5  1  3  3  1  6 11 11  5  8  6 12  9  6] [ 8 11  3  5  8 12 11  6  3  3  3  8  4  8  8  3  1 10  9  6]\n",
      "[ 1  5 11 12  8  1 11  4 10 10  6  8 10  1 10  1 11  9  6  4] [ 6  8 11  8  8  5  6  4  3 10  6  3  3  1  8  8  2  6  6  1]\n",
      "[11  5 11 10  8  6  8 11  5  1  1  4  1  6  8  5 10  6  3 11] [ 4  6  6  1  6  1  8  1  3  8  6 11  6  6 10  5 10  6  3 12]\n",
      "[ 1  5 11  2  1  8 11  6  3 11 10  5  1  9  8  1  8 10 11  8] [ 8  7  6  2  7  1 11  6  1  6  3  3  1  4  1  1  1  8  4  8]\n",
      "[ 1 11 10  2 11  9  8  5  2  8  6  0  6  5  4  8  3  1  1  7] [ 1 11 10 10  1  9  3 10  2  8  5  8 10 10  6  3  3  1  1  6]\n",
      "[ 5  2  9 12 10  3  4  6  8  7  6  6  2  6  3 11  7  6  4  0] [ 5  2  4  8  8  8  6  6  8  5 11  1 12  6  3 11 11  6  6  1]\n",
      "[ 3  6  4 11  1  8  1 10  6  6 11  3  8  8 10  5  1  1  6 10] [ 1 11 10  6  8  5  0  3 11  6 11  3  8  8 10  2  3  6 11  3]\n",
      "[ 6 10  6 11 10 12  6 11  8  1  1  2  9  5  4  3  4  8  9  1] [10  5 12 11 11 10  5 11  5  1  8  3  6 10 11  5  1  1  4  6]\n",
      "[ 1  6  8 10  8  8  1  8  6 11  2  1 11  2  5  1  8  6  1  3] [ 1  6  8 10  1  8  4  8  1  6  2  8  9  9  5  6 10 11  1 10]\n",
      "[ 9  1 10  6  5  1  8  9  6 10 10 10  3  5 11  1  7  8  6  8] [ 4  1 12 11  6 10  1  6 10 10 10  6  5  1  8  8  5 10 10 10]\n",
      "[ 1  8  3  1 10  3  1 11  1 11  8  4 12  1  1 10 10  4  6  5] [ 6  1  1  3  5  3  8 11  6 11  3  4  8  1  8 10  3  9  3  8]\n",
      "[ 7 10  4 10  3  6  3  2  1  8  1  3  6  6 11 12  2  3 10  6] [12 10  8  2 11  6 10  9  1  8  1 10  1  6  8  5  9  1 12  6]\n",
      "accuracy: 0.31279296875\n"
     ]
    }
   ],
   "source": [
    "\n",
    "accuracy = 0.0\n",
    "c = 0\n",
    "for j in range(20):\n",
    "    for i in data_loader:\n",
    "        c+=1\n",
    "        p, m, l, mask = i['p'], i['m'], i['l'], i['mask']\n",
    "        tag_scores = model(p, m, mask)\n",
    "        pred = tag_scores[0].max(1)[1].numpy()\n",
    "        truth = torch.t(l)[0].numpy()\n",
    "        print(pred[:20], truth[:20])\n",
    "        accuracy += np.average(pred==truth)\n",
    "        if (c>=1): break\n",
    "print(\"accuracy:\", accuracy/c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuloucn/anaconda3/envs/nlu/lib/python3.6/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type LSTMTagger. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  4  1 12  2  1  3  3  0  5  8  2  6  1 10 10  4  3  1  6] [ 6  4  1 12  4  1 10  4  0  5  8  4  1  1  3  3  4  8  1  1]\n",
      "[ 3  1  4  5  2  6 11 11 11 10 11  8  6  8  6 10  1  2  7  1] [ 1  1 11  9  2 11  6  1  1 10 11  3  6 11  6  1  3  1  6  8]\n",
      "[ 1  8  4 12  2  1  2  1  6  8  8  8  3  1  8  4  6  8 11  1] [ 1  3  9  4  9  1  2  6  6  1 12  1  6  1  8 11  8  1 11  1]\n",
      "[ 8  6  0 10  2  6 10  5 11 10  8  4  1  4 10  3  1 11  5  8] [ 8  6  8  1  5  2  3  8  4 10  3  9  8 11 11  3  6  6  5  1]\n",
      "[11  6  6 10  3 11  8  4  1  6  8  4  1  2  6  6 11 10  1  1] [ 6  1  6  8  3  6  4  1  1  8  8  3  6  9  1  8  4 10  5  9]\n",
      "[ 1  5  8 10  8  1  8  4  4  5  5  6 10  4  6  6 11  8  6  4] [ 8  5  8  3  8  1  3 11  9 12  3 11 12 11  1 11 11  8  8  8]\n",
      "[ 4  6  6  4  3  6 11  6 11  4 12  8 10  8  1  3 10  8  4 11] [ 4  6  6  4  3  6  7 11  9 11  2  8  3  8  1 10  3  1  6  1]\n",
      "[ 6  2  3 11 10  5  2  9  1  3 10  3  6 11  1 12  3  6  3  4] [ 1  6 12  8 10  5  7 11  1 12  3  3  6 11  1  2  3 10  8 11]\n",
      "[10  2  3  8  3  2  1 11  1  0 11  5 11  9  1  9  4  8  6  1] [10  1  3  8  4  2  0  8  3  6 11  8 11  2 11 12  4  8 11  8]\n",
      "[ 6 11  6  7  9  6  8 10 11  1 11  0  9  8  1 10  1  8  3 11] [ 6 11  6  1  9  6 10  3  9  1 11  0  6  8  8  4  1  8 10 11]\n",
      "[10  6  8  1  3 11  3 11  9  1 11 10  1 11  3  8  8  1 10 10] [12  6 10  8  1  2  5 11 11  8  6  3  8 11  9  3  8  3 10  5]\n",
      "[ 1  6  3  3  6  1  3  1  8  2  1 12  3  1  8 11 11  0  6  6] [ 8  6 10  5 10  1 10  1  3  4  3 10  6  6 10 11  6  8  6  3]\n",
      "[10  4 11  8  1 10  5 11  6  6 11  3 10  3  1  6  3  6 10  9] [ 6  4 11 10  1  3 10 11  8  1  6 10 10 10  8  3 10 11  4  2]\n",
      "[ 8  6  1  8  8 10  2  8  6  6  6  8 10  3  2  4 10  3  5 10] [ 8  6  8  8  8  8  7  3  1  1  1  1  2  3 10  4  3  3  5  5]\n",
      "[ 6 11  6  8  3  3  6 10  6 11  8  3  1  5  8 11  8  3  1  3] [ 1  1  1  3  8  5  3  5  6  1  1  3  1 12  3  6  8  3  1  5]\n",
      "[ 1  0  8 11  1  5  1  8  6  4  8 10 11  6  9  9  8  5  8  4] [ 1  6  8  6  3  1  1  8  6  1  6  3  6  6  9 11  8 10  8  8]\n",
      "[ 5 10  4  1  8  8  8  6  1  6  5  3  8  6  1  1  6  8  5  8] [ 5 10 11  1  8  1  8  3  1 10 10  6  1 11  1  4  8  1  5 10]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-292341e2589b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mc\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'p'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'l'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mtag_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthe_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtruth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlu/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-1d12c8e6a01f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, prev, melody, mask)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mp_lstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mm_lstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mp_fstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_fstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_lstm_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_lstm_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlu/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlu/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         )\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlu/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlu/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mnexth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvariable_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlu/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_directions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                 \u001b[0mhy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0mnext_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mall_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlu/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreverse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0;31m# hack to handle LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlu/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mLSTMCell\u001b[0;34m(input, hidden, w_ih, w_hh, b_ih, b_hh)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mgates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_ih\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_hh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_hh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mingate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforgetgate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcellgate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutgate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlu/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    990\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.save(model, \"/mnt/d/230/Iterations-blstm\")\n",
    "the_model = torch.load(\"/mnt/d/230/Iterations-blstm\")\n",
    "\n",
    "accuracy = 0.0\n",
    "c = 0\n",
    "for j in range(20):\n",
    "    for i in data_loader:\n",
    "        c+=1\n",
    "        p, m, l, mask = i['p'], i['m'], i['l'], i['mask']\n",
    "        tag_scores = the_model(p, m, mask)\n",
    "        pred = tag_scores[0].max(1)[1].numpy()\n",
    "        truth = torch.t(l)[0].numpy()\n",
    "        print(pred[:20], truth[:20])\n",
    "        accuracy += np.average(pred==truth)\n",
    "        if (c>=1): break\n",
    "print(\"accuracy:\", accuracy/c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model:\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
