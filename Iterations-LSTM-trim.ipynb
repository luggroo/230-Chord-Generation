{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f415c0d3ef0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Author: Yulou Zhou\n",
    "#Weight loss function by commonality (and normalize)\n",
    "#padded sequence\n",
    "#for loop to test parameters\n",
    "#for loop to get prev generated chord\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import csv\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from random import shuffle\n",
    "from MyDataset import MyDataset\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p:  tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0]])\n",
      "m:  tensor([[ 0,  0,  0,  0,  0,  0,  8,  8]])\n",
      "l:  tensor([[ 1,  4,  7]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "train_data = MyDataset('testgeneration', prevchord = 6)\n",
    "weights = train_data.stats()\n",
    "data_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
    "c=0\n",
    "for i in data_loader:\n",
    "    print(\"p: \", i['p'])\n",
    "    print(\"m: \", i['m'])\n",
    "    #print(\"mask: \", i['mask'])\n",
    "    print(\"l: \", i['l'])\n",
    "    c += 10\n",
    "    if c > 0: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(array):\n",
    "    return [i / sum(array) for i in array]\n",
    "newweights = []\n",
    "\n",
    "def weightloss(weights, eps):\n",
    "    for w in weights:\n",
    "        newweights.append(torch.FloatTensor( normalize([1/(i + eps) for i in w] ) ) )\n",
    "    #print(newweights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, p_embed_dim, m_embed_dim, p_hidden_dim, m_hidden_dim, vocab_size, tagset_size, batch_size = 1):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.p_embed_dim, self.m_embed_dim = p_embed_dim, m_embed_dim\n",
    "        #refer to https://discuss.pytorch.org/t/can-we-use-pre-trained-word-embeddings-for-weight-initialization-in-nn-embedding/1222/2\n",
    "        \n",
    "        self.p_embed = nn.Embedding(vocab_size, p_embed_dim)\n",
    "        self.m_embed = nn.Embedding(vocab_size, m_embed_dim)\n",
    "        self.p_embed.weight.data.copy_(torch.from_numpy(np.identity(vocab_size)))\n",
    "        self.m_embed.weight.data.copy_(torch.from_numpy(np.identity(vocab_size)))\n",
    "        \n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.p_lstm = nn.LSTM(p_embed_dim, p_hidden_dim, bidirectional = False)\n",
    "        self.m_lstm = nn.LSTM(m_embed_dim, m_hidden_dim, bidirectional = False)\n",
    "        \n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = nn.Linear((p_hidden_dim + m_hidden_dim) , tagset_size)\n",
    "        self.root2second = nn.Linear((p_hidden_dim + m_hidden_dim)  + 1, tagset_size)\n",
    "        self.root2third = nn.Linear((p_hidden_dim + m_hidden_dim)  + 1, tagset_size)\n",
    "        \n",
    "        self.p_hidden = self.init_hidden(p_hidden_dim)\n",
    "        self.m_hidden = self.init_hidden(m_hidden_dim)\n",
    "\n",
    "    def init_one_hot(self, vocab_size):\n",
    "        #initialize each embedding\n",
    "        #stack them together (or other ways to have  pretrained embeddings)\n",
    "        #pretrained_weight is a numpy matrix of shape (num_embeddings, embedding_dim)\n",
    "        #we should turn data into torch.from_numpy(pretrained_weight)\n",
    "        #embed.weight.data.copy_(torch.from_numpy(pretrained_weight))\n",
    "        \n",
    "        torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "        \n",
    "    \n",
    "    def init_hidden(self, hidden_dim):\n",
    "        # The axes semantics are (num_layers, minibatch_size, hidden_dim)\n",
    "        return (torch.zeros(1, self.batch_size, hidden_dim),\n",
    "                torch.zeros(1, self.batch_size, hidden_dim))\n",
    "\n",
    "    def forward(self, prev, melody, mask):\n",
    "        \n",
    "        prev_embeds = self.p_embed(prev)\n",
    "        x1 = torch.transpose(prev_embeds, 0, 1) #TODO: DEBUG THIS LINE (probably the last batch)\n",
    "        \n",
    "        #TODO: ensure that melody input is a tensor\n",
    "        \n",
    "        melody_embeds =  self.m_embed(melody) #Error here\n",
    "        #print(melody_embeds.size())\n",
    "        x2 = torch.transpose(melody_embeds, 0, 1)[:8]\n",
    "        \n",
    "        p_lstm_out, self.p_hidden = self.p_lstm(x1, self.p_hidden)\n",
    "        m_lstm_out, self.m_hidden = self.m_lstm(x2, self.m_hidden)      \n",
    "        \n",
    "        p_fstate, m_fstate = p_lstm_out[-1], m_lstm_out[-1]\n",
    "        \n",
    "\n",
    "        concat = torch.cat((p_fstate, m_fstate), 1)\n",
    "        #print(p_fstate.size(), m_fstate.size())\n",
    "        tag_space = self.hidden2tag(concat) #REASON: you only need the final state\n",
    "        tag_scores = F.log_softmax(tag_space, dim = 1)\n",
    "        \n",
    "\n",
    "        withroot = torch.cat((concat, tag_scores.max(1)[1].float().view(-1,1)), 1)\n",
    "        second = self.root2second(withroot)\n",
    "        third = self.root2third(withroot)\n",
    "        second_scores = F.log_softmax(second, dim=1)\n",
    "        third_scores = F.log_softmax(third, dim=1)\n",
    "        \n",
    "        #stacked = torch.stack([tag_scores, second_scores, third_scores], dim=0)\n",
    "\n",
    "        return [tag_scores, second_scores, third_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  iter:  12324   phid:  5   mhid:  40   eps:  0.029377359640038608\n",
      "0 tensor(4.0761)\n",
      "[11 11 11 11 12 12 11 11 12 12 11 11 12 12 12 11 12 11 11 11] [ 5  1  3  6  1  6  1  2 11 10  2  6  8  1  8  9  3  6 11  6]\n",
      "[12 11 12 12 11 11 12 11 12 12 12 11 12 12 11 12 12 12 11 11] [ 3  3  8  5 11 10  8  8  8 10  6  1 12 11 12 11  3  1 11  6]\n",
      "accuracy: 0.064453125\n",
      "5000 tensor(3.0368)\n",
      "[11  1  3  8  3  2  0  3  1  1  3  4  4  1  6  9  7  1  4  1] [11  8 10  1  1  6  1  5  1  6 10  8  4  1  3  3  3  8  6  5]\n",
      "[11  1 11  1  1  1  1 11  1  6  4  2  1  5  1  4 12  1  1  6] [11  1  6  1  1  8  1  1  6  5  1  3  1 10 10  6 12  3  3  1]\n",
      "accuracy: 0.26171875\n",
      "10000 tensor(2.4807)\n",
      "[ 1  4  3  6  4  8  1 11  0 10  8  6  2  1  4  3  8  4  1  4] [ 3  6  6  1  6  1  8  4  3 10  6  1  9  3  9  8  1  1  1  4]\n",
      "[ 3  3 12  6  2 10  8  1  1  1  3  5  6  4  6 11 12  9  9  4] [ 1  3 10  9  8 10  3  1  6  8 10  5  1  5 11 11  8  9  6  9]\n",
      "accuracy: 0.259765625\n",
      "[ 9 10  8  7 12  1  4  9  1  3 12  1  8  1  6  1 10  1  5  8] [ 8  3  1  1  3  1  6  9  1  7  5  8  1  6  1  8  3  3 12 10]\n",
      "[ 2 10  8 11 12  8  7 11  1 11  1  1 11  6  3  8 11  1 11  1] [ 2  3  8  6  3  8 12 11  1 11  1  7  6  6  1  3 11 11 11  9]\n",
      "[12  6 11  1  1  1  4 10  6  3  3  6  1  8  9  6  4  0  0  1] [ 3  1  4  6  8  6  1 10  3  3  5  6  1  1  4  6  1  1  1  9]\n",
      "accuracy: 0.2697265625\n",
      "269\n",
      "1  iter:  14996   phid:  26   mhid:  13   eps:  0.006968974668840531\n",
      "0 tensor(4.5993)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuloucn/anaconda3/envs/nlu/lib/python3.6/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type LSTMTagger. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12  8  5 12  5 12  5 12  5 10  5  5 12 12 12 10 12 10  6 10] [ 3  4  1  6 11  6 10  5  6  8 11  8  3  4  3  1  3  1  3 11]\n",
      "[12 12  5  5 12 12  5  6  8  6 12  8 12 12 12  8  5 12 12 12] [ 1  6 12  1  8  9  9  3 11 11  3 11  1  8 10 11  5 10  8  8]\n",
      "accuracy: 0.0556640625\n",
      "5000 tensor(2.3476)\n",
      "[11  2  8  8  8  9  9  1  3  4  3 11  7  7  2  0  7  6  1  1] [ 6  9  3 10 12  1  1  8 10  8  6 11  5  7  2  9  1  6  1  8]\n",
      "[ 8  6  0  8 12 10 11  3  2  6 11  6  9  1 11  9  1  1 11 11] [ 3  1 12  8  3 10  6  1  4  3 11  6  6  8  1  6  8  1  8  6]\n",
      "accuracy: 0.3037109375\n",
      "10000 tensor(2.3232)\n",
      "[ 7  5  9  9  1  0  4  3  8  8  1  0  1  8 10  1  6  5  6 10] [12  7  6  9 11  6  6  8  8  8  6  6  1  3  5  1 10  5  8  3]\n",
      "[ 6 12  6  6 11  4  1  9  5  3  5  4  3  9  1  6  6  6  1  6] [ 6  8  6  8  1  1  8 11  5  8  5 11 12  9  6  6  1  1  1  8]\n",
      "accuracy: 0.3095703125\n",
      "[ 7  9 12 11  9 10  9  3  2  8 12  6  6  6  4  8  6  4 11 11] [ 1  9  1  6  8  3  5  8  5  3 10  3  3  8 10  6  6  4  3  1]\n",
      "[ 3  4  9  8  6  6  4  2  4 11  3 10  6  9 11  2 11  4  6  3] [10  1 11  8  3  6  8  9  8 11  3  8  6  1  8  2 10 11  3 12]\n",
      "[11  1  7  1  4  0  6  4  1 11  0 11  5  7  6 11  5  3  3  4] [ 1  1  9  8  4  6  1 11  1  6  5  6  6  1  6  9  5  8  3  4]\n",
      "accuracy: 0.33125\n",
      "331\n",
      "2  iter:  13601   phid:  5   mhid:  7   eps:  0.08939214335745634\n",
      "0 tensor(4.2448)\n",
      "[2 8 6 8 8 2 2 8 8 8 2 2 8 2 8 2 2 8 8 8] [11  8 11  5  1  5  6 12  4  4  6  8  6  8 11  1 11  6  4  1]\n",
      "[8 2 8 8 8 8 2 8 8 2 8 8 2 8 8 2 8 8 8 2] [ 6  7 10  6  1  8  3 11  1  9  5  6 10 11 11  1  1  3  4  6]\n",
      "accuracy: 0.107421875\n",
      "5000 tensor(2.8312)\n",
      "[11  6  5 10  5 11  3  1 12  8  9  1  1 11 11  7 12  3 12  5] [ 6  6  6  6  5 11  3  1 10  1  6  6 10  1 11  9  3  8 10  1]\n",
      "[ 8  0  3  3  4  6  9  5  1  3  1  0  1  8  6  3 10  6  9 10] [ 3  6  3  3 11  6 11  6  6  1  1  0  1  1  8  3 10 11  4 12]\n",
      "accuracy: 0.3056640625\n",
      "10000 tensor(2.5675)\n",
      "[ 3  6  6  3  4 11  6  9  3  9  3  1 10  3 11  6  8  3  5  3] [ 3  3  8  3  4  4  8  1  3  6  3  1  5 10  6  6 11 10  5  1]\n",
      "[ 4  3  6  1  5  2  1 11  1  0  4 10  2  3  6 10  6  3  5  2] [ 2  3  6  6  5  5  8  6  6  0  4 10  9  3  6 12  1 10  3  9]\n",
      "accuracy: 0.3408203125\n",
      "[ 3  3  3  9  5 11  3  8  1 12  0 10  5 10  8 10  6 11  9 11] [ 6  3  3  6  8  3  3  1  1  5 10  6  8  3  7  3 10 11  2  3]\n",
      "[ 6 11  1  9  6  3  3  2  1 10  1  9  3  7 11 11 10  2 12  9] [ 6  1  8  9 10  1  8  7  8  8  6  8  3 12  8  3 10  2  5  2]\n",
      "[ 5  1  3  1 10  6  7  1  6 10  7  3  7 10 12  6  4  1  5  4] [ 5  1 10  3 11  6  2  6 11  5  7 12  3  8  2 10  8  3  3  4]\n",
      "accuracy: 0.2791015625\n",
      "279\n",
      "3  iter:  17145   phid:  5   mhid:  5   eps:  0.028175691533867547\n",
      "0 tensor(4.1066)\n",
      "[5 5 4 4 4 2 5 4 2 2 4 5 5 2 4 5 4 4 4 5] [ 1 11 11  3  8  6  3  1  8  9  2  8  9 10  6  6 10 11  1  8]\n",
      "[4 5 5 4 4 2 2 4 5 4 4 5 2 2 2 5 5 5 5 5] [ 8  1  5  6  8 10  8  9  3  2  1  6  1 11  6  6  5  8 10  6]\n",
      "accuracy: 0.0625\n",
      "5000 tensor(2.8724)\n",
      "[ 2  0  2 12 11  6  8  2  2  1  1  3  4 11  3  3  6  4  6  1] [ 1 11  7  5 11  1  8 12  1  8  8  8  9  1  3 10  8  6  3  1]\n",
      "[ 5  8  6  6  6 10 11  0  3  5 11  5  6  6  8  3  1  6 10 10] [12  5  8  1  8 11 11 11  3  8  8 12  3  1  1  6  7  6 10 10]\n",
      "accuracy: 0.259765625\n",
      "10000 tensor(2.6557)\n",
      "[ 8  1  7 11  8 10  5  1  8  4 11  0  3  3  6  8 11 12  3  7] [ 1  6  1  1  8  3  5  6  3 11 11  2  8 10  8  8 11  7  3 12]\n",
      "[ 4  8  6  8  8  6  9  6  7  4  3  6 11  3 11  1  7  6 12  7] [ 4  8  1  5  1  6  9  1  3  9  6 10  6  1  1  1 10  6 10  6]\n",
      "accuracy: 0.2685546875\n",
      "15000 tensor(2.6238)\n",
      "[ 4  0  7 11  7  6  2  4  0  0  7  4  3  4  6  1  3  4  6  4] [ 4  8 11 11 10  1  4  8  6  1  6  5  1  5  6 11  3  1  8  1]\n",
      "[ 7  1  8 11  3  6  3  1  6  6  3  3  8  8 11 10 11  3  9  8] [ 1  1  8  8  3  6 11  1  6  3  5  8  8  8  6  5 11  3  6  1]\n",
      "accuracy: 0.267578125\n",
      "[ 8 11  4  1  8  3  0 10  9  7 10  8  8 12  7  0 11  8  8  3] [ 3  3 11  8  3  3  3 10  9  7 10  8  8 12  5  6 11  8  1 10]\n",
      "[10  2  9  1  6 11  3  8  8  3  1  8  4  4  3  6 11  8  5 10] [12  7  4  1  6 11 10  3  1  1  6  8  1  8  3  3  6  1 10  5]\n",
      "[ 5  8  4  8  0  2  6  3  4 10  4  8  6  4 10 10  8  1  7  4] [12  8  6  1  1  9  6 12  9  5  9  8  6  6  3 10  8  6  6 11]\n",
      "accuracy: 0.281640625\n",
      "281\n",
      "4  iter:  16780   phid:  56   mhid:  37   eps:  0.11140234235688509\n",
      "0 tensor(4.0932)\n",
      "[2 1 1 6 1 1 1 6 1 1 1 1 2 2 6 6 6 1 1 1] [ 1  5  6  6 10 10  6  9  8  1  8  8  6  8  3  3  8  8  1  6]\n",
      "[1 1 1 6 1 1 6 1 1 1 1 1 1 1 6 1 1 1 6 1] [ 8 10 10  5  1  8 11  1 10  4  1  8  3  8  3 10  3  1  8  6]\n",
      "accuracy: 0.1708984375\n",
      "5000 tensor(2.3471)\n",
      "[ 8 10  3  5  3  3  6  9  6  8 12  8  3  9  6 10 11  5  0  8] [ 8 10 12  7  8  5  8 11  6  8 10  8 10  4  1 10  6  5 11  8]\n",
      "[11  1 12  1 11  3  3  8  8  5  6  3  9  1  6  4  1 11  1  4] [11  4 10  1  1  3  3 11  8  8  6  1  9  8 11  4  1 11  8  1]\n",
      "accuracy: 0.3017578125\n",
      "10000 tensor(2.1877)\n",
      "[10  4  3 11  2  4  4  0  1  4  2  7  6 10  4  5  6  2  4  8] [ 5  4  1  6  9  9  2  1  2 11  4  1  1  3 11  6  8  1  4  3]\n",
      "[10 11 11  1 12 10  8 12  1  1  0  2  6 10 11  3  0  3  5  1] [12 11 11  6  5 10  8 12  1  1  8  1  1 11  6 10  3  8 10  8]\n",
      "accuracy: 0.283203125\n",
      "15000 tensor(2.3078)\n",
      "[11 11  6  9  9 11  1  1  1 11  6 10  0  5  8 11 10 11  1  4] [ 1 11  1  8  9 10  3  8  1  8  6  3  6  5  8  4  6  9  8  6]\n",
      "[11  1  9  0  3  1  8 10  2  6  5  7  6  7  7  3  6  7  3  9] [11  1  6  3  8  1  8  3  9  6  1  3  6  5  8  3  8  4 10 11]\n",
      "accuracy: 0.263671875\n",
      "[ 6  8 11  1  1  6  3  4  1  1  4  1  1  4  8  5  5 10  6  9] [ 6  8  6  6  6 10  3  4  1  1 11  3  1  4  1  1  5  1  1  4]\n",
      "[ 3  1  8 11  7  3  9  1  3  1  6  5  5  6  1  5  5  3  4  2] [11  1  8  9  3 10 11  1  1  1 10  3  5  8 10  1  1 11  7  8]\n",
      "[ 1  9  9  6 10  3 11  6  6  5  6  1  8  2 10  1 10 11  4  6] [ 6  9  8  6  1  3  9  6 11  3  1  1  8 10  1  8 10  8  4  6]\n",
      "accuracy: 0.3005859375\n",
      "300\n",
      "5  iter:  16226   phid:  56   mhid:  21   eps:  0.09001790918486824\n",
      "0 tensor(4.1121)\n",
      "[4 4 4 4 4 4 4 4 4 4 4 3 4 4 4 4 4 4 4 4] [ 1  4  1  1  6 11  1  6  8  8  6  8 10  9  3  1  1  1 11 11]\n",
      "[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4] [ 5  1  6  3  6  4  9  8  1  1  6  4  1  6 10 10 10  9 11 11]\n",
      "accuracy: 0.0537109375\n",
      "5000 tensor(2.3814)\n",
      "[12  4 11 10  8  2  1  8  0  2  6  7  8  1  6 11  8  4  1  7] [12 11  6  3  3  1  1  8  1 11 10 12  1  6  1  6  8  4  1 10]\n",
      "[ 9  1  3  4  6  8  6  4  1  8  5  7 10  8  6  6  3  8  1  7] [ 9  3  3  1 11  1  6  4  6  8 10  8  1  5  6  8  3  3  1  6]\n",
      "accuracy: 0.3017578125\n",
      "10000 tensor(2.0626)\n",
      "[ 1  8 12 11 11  9 11  4  1 11  6  7  4  9  7  8 11  1  4 11] [ 1  8  8  6 11  4 11  1  1  6  6  5 11  9  2  3  6  6  1  4]\n",
      "[ 7  6  2  5  6 11  0  3  1 10  1  0  8  4  3 10  2  6 12 11] [ 3  1  1  7  9  6  3  3  1 10  3  1  8  8  8  3  5 11 12  6]\n",
      "accuracy: 0.310546875\n",
      "15000 tensor(1.9335)\n",
      "[ 1 10  8  3  1  9  8  2 10  5  8  6 10 12  3 12  7 10  3  9] [ 1  1 11  1  8 11  8 11 10 12  8  1  1  5  2  8  2 10  3  4]\n",
      "[11  6 11  6 10  6 11 11  5  9  1  0 11  5  1 12  9  1  2  1] [ 6 11  6 11  3  1 11  6 12  9  6  0  4  3  1  3  1  1  2  6]\n",
      "accuracy: 0.3076171875\n",
      "[ 5 12  9 11  1 11  1  1  9  6 10 12  5  6  3 12  9  6  8  7] [10  5  9  6  8  8  1 10  1  1 11  2  5  8  3  4  9  6 10  8]\n",
      "[12  2 11 11 11  9 11  5  4  4  2  5  8 10  5  2  3  3  5 12] [11  1  8 11  9  4  6  5  9  3  8  2  8  5  8 10 10 10 10 10]\n",
      "[10  9  4 11  0 12  5  6  1  1  6  2 11  0 10 10  1  9  7  3] [ 2  2  4  8  8 10  7  6  3 11  6  1 11  8  3  7 10  9 10  3]\n",
      "accuracy: 0.3046875\n",
      "304\n",
      "6  iter:  17380   phid:  76   mhid:  15   eps:  0.029844958734328728\n",
      "0 tensor(4.1871)\n",
      "[11  4 11 11 11 11 11  4 11  4 11 11 11 11 11 11  4 11  4 11] [ 4 11  3  3  8  6  2  3  8 11 10  3  3 10 10  4  2  3  6 10]\n",
      "[11 11  4 11 11 11 11 11  4 11  4  4 11  4 11 11 11  4 11 11] [ 1  8  3  6  8 12  6  6  5  3 11  8  6  3  8  2  3  1 10  1]\n",
      "accuracy: 0.05859375\n",
      "5000 tensor(2.4219)\n",
      "[ 0  3  0  5 11  8  6 11 12  1  4 11 11 11  9  2  7  1  6  5] [11  8  8 12  6  1  6  6 10  6  4  9  6  4  4 11  2  1  8  5]\n",
      "[ 1  3  3 12  8 11 12  8  1 10  1  4  6  6 11  5  2  7  4  6] [ 1 10  3  3 10  1  9  1  6  1  6  2  1  6  3  8 11  3  1  1]\n",
      "accuracy: 0.302734375\n",
      "10000 tensor(2.1465)\n",
      "[12 11  9  3  5  5  8  7  5 11  0  5  3 11 10  9 11  4  1 11] [ 2  4  4  8  5  3  2  6  5  2  6  5  3 11  3 11  8  8  6 11]\n",
      "[10  9  9 12  9  3  5  6  2  6  1  6 11  9  3  1 11  3  6 11] [ 1  1  1  3 10  3 10 11  1  1  6  9 11  4 10  6 11  3  1  6]\n",
      "accuracy: 0.2822265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000 tensor(1.7439)\n",
      "[ 6  5 12  8  3  6  6  8  3  3  1  1  4  6 11  9  0  3  0  4] [ 6  1  3 11  8  6  1  8  8  8  1  1  6  8  6  9 11  1  6  5]\n",
      "[ 1  1  3 11  1  6 11  2 10  6  3  6  6  3  5  4  3 10  8  8] [ 1  1  3  8  3 10  4  6  3  6  8 10  6  7 10  3  3  1  3  6]\n",
      "accuracy: 0.302734375\n",
      "[12  7  8  4  6  2  1  6 11  1  6 10  3  3 11  3 11  1 10  9] [12 10  1  1  8  3  1  3 11 10  6  1  6  8 10  8  8  1  0 11]\n",
      "[ 1  5  5  0 10  9  8  3 11  3  1  6 10  6  6  6  3  8  3 11] [ 2 10  6  1 10  4  6 11  5  3  1  1  3  6  6  1 11  8 10  4]\n",
      "[ 1 10 11 11  3  9 10  3  8  8  9 10  3  6  1 10  5  2  0  6] [ 8 10  4 11  3  9  5  8  8  8  9  6  6 10  5 10  5  1 11  1]\n",
      "accuracy: 0.3138671875\n",
      "313\n",
      "7  iter:  13648   phid:  5   mhid:  25   eps:  0.003146045623024015\n",
      "0 tensor(4.3888)\n",
      "[5 5 9 9 5 5 9 5 5 5 5 5 5 5 5 5 5 5 5 9] [ 6  1  1  1  6  5  2  8 10  6  1 10  8  2  1 10  6 10  8  6]\n",
      "[9 5 5 9 5 5 5 9 5 5 9 5 5 5 9 5 5 5 5 5] [ 4  6  6  6  8  1 11  8  6  1  7  3 10  1  5  1  3  1  3  1]\n",
      "accuracy: 0.0703125\n",
      "5000 tensor(2.6348)\n",
      "[ 7  3  4  5  6  6  2  1  6  2  1 11  1  1  1  4  4  1  6 11] [ 3  1  8 10  6  6  1  1 10  2  1  4  8  6 10  8  4  1  6  4]\n",
      "[12  8  6  5  5  2  1 12 11  8  5  6  5  6  6  1  6  6  6 11] [ 9  1  8  5 10 11  1  5 11  8 10  6 10  8  2  6  6  6  6 10]\n",
      "accuracy: 0.2958984375\n",
      "10000 tensor(2.8118)\n",
      "[ 6  4  6  1  3  8 11  2  3  1  5  0  1  1  9 10  8  3  8 11] [ 1  6  6  8  3  3  1  6  3  1 10  1  8  8  9  3  1 10  1 11]\n",
      "[ 6  6  1 11  1  5  1  1 12  3  4  8  1  3  3  6 12  3  8  6] [ 1  8  8  8  1  3  8  3  1  3  6 10  8  1  3  3 10  3  8  9]\n",
      "accuracy: 0.2744140625\n",
      "[ 4  3  7  6  0  3  3  4 10  2  3  5  3  1  3 10  6  1 12  5] [ 9  8  1  8  0  3  3  3  8  6  5 10  3  1  8 10  6  1  5  7]\n",
      "[ 6  1  8  8  6  6  2  3  3  4  1  1 10  1 11  1  3  3  3  1] [11  6 10  8  6  6  5  1 10  4  1  6  5  6  4  1  3  6  8  1]\n",
      "[ 0  7  6  7  8  0  7 12  3  8  3  3 10  7  3  1 10  8  3 11] [11 11  1 10  1  8  9 10  3 10  4  8  6 12  8  6  5 10 10  4]\n",
      "accuracy: 0.2732421875\n",
      "273\n",
      "8  iter:  17720   phid:  20   mhid:  60   eps:  0.10768843373218018\n",
      "0 tensor(4.1084)\n",
      "[8 3 3 3 3 3 3 3 8 8 3 3 3 8 3 8 8 3 3 3] [ 3 10 10 10  1 10  1  8  8 10  8 12  1  4  1  1  9 11  9  8]\n",
      "[3 3 8 3 3 3 8 3 3 3 3 3 3 8 3 8 3 3 3 3] [ 1  4  6  8 11  1  1  5  8 12 10  8 10 11  1 12  5  8 10  3]\n",
      "accuracy: 0.1337890625\n",
      "5000 tensor(2.9366)\n",
      "[10  9  5  1  8  6  6  8  5 10  6  8  1  1  0  6  3  3 10  3] [10 11  1  5  3  1 11  1  1 10  1  1  3  1  6  6  3  8  8  8]\n",
      "[ 3 10  1  9  0  0  0  4  8  8  5 11  3  1  6  1  6 12 12  3] [10 10  8  4  6 11  0  4  1  8  1  1  3 11  9  1  6  7  2  5]\n",
      "accuracy: 0.25390625\n",
      "10000 tensor(2.4983)\n",
      "[10 11  7  2  2  6 10 11  4  1  5  3  6  3  4  1 11  7  5  4] [ 8  1  7  2  1  1 10  6  1 10  3  3  6  6  4  1 11 10  8  4]\n",
      "[ 6  3  0  3 12  1  8 10  1  8  3  1  3 10 10  1  1  0  7  3] [ 1  8  3  8 10  1  3 10  3  8  3  6  3  8  6  1  1  6 12  8]\n",
      "accuracy: 0.29296875\n",
      "15000 tensor(2.2063)\n",
      "[12  7  2  1  6  7  6 11  6  1  1  5 11  3  3  8  1  1  3  8] [6 6 8 6 6 3 1 6 6 1 1 6 6 8 3 8 8 1 4 3]\n",
      "[12  1  2  6  6 12  8  8  1  4  7  1  6  9  5 12  3  3  1  7] [ 5 11  2 11  6  1 12  8  3  9 10  3  8  4  5  5  4  8  6  9]\n",
      "accuracy: 0.3115234375\n",
      "[ 8 11 10  7  6  5 11  3  4  7  3  6  2 11  3 10 11  3  0  4] [ 3 11  1 11 10  6  3  3  4  8  8  6 11 11  8 10  2  8  2  4]\n",
      "[ 6  6  1  9  9 12  8  6  6  7  3  6  6  9 10  1 10  8  8  4] [ 6  1  8  1  4 11  3  6  3  1 11  6  1 11  3  4  8  3  8  1]\n",
      "[ 1  1  8  3  3  7 10  9 11  1  6  7  1 12  3  6  6  8  5  4] [ 8  8 10  3  8  9 10  2  8 10  8  3  1  3  3 11  6  1  1 10]\n",
      "accuracy: 0.27890625\n",
      "278\n",
      "9  iter:  12167   phid:  5   mhid:  7   eps:  0.11173520989342027\n",
      "0 tensor(4.0951)\n",
      "[ 5  5  0  0  5  0  5  5  5  5  5  5  5  5  5  5  0  5 12 12] [ 1  8  1  3  6 10  1  6  1 11  4  6  1  3  5 10  3  9  4  1]\n",
      "[ 5  0  0 12 12 12  5  5  0  2  5  0 12  5  5  5 12  5  5  5] [ 1 10  6  3  1  6  6 11  8  6 11 10  1 11 11 10  3  3  1  1]\n",
      "accuracy: 0.037109375\n",
      "5000 tensor(2.8003)\n",
      "[ 1  3  3  8  6  6 11  4  5  6  8  9  1 12  6 11  3  6  9  4] [ 1  8  3 10 10  1 11  8  8  8  3  8 11  3  8  6 11  1  4 11]\n",
      "[ 5 10  4  4  2  8  4  5 11  4  1 11 11  7  4 10  8  6  6 11] [ 1 12 11  6 12  6 11  5  4 11  6 11  1  6  4 10  8  3  3  1]\n",
      "accuracy: 0.2529296875\n",
      "10000 tensor(2.7902)\n",
      "[ 6  0  4 11 11 11  6  6 10  5  5  3  5  3  5  8  8  7  8  1] [ 6  6 11  6  4  1  1  3  3  8  5  1  8 10  3  8  6  7  8  1]\n",
      "[ 4  6  3  6 11  4  3  3  3  6  3  5  3  7 11  3  1  7 11  8] [11  6  8  3 10 11 10 10  8  6  5 10 12  4  6 10  6  8 11  3]\n",
      "accuracy: 0.2763671875\n",
      "[12  9  8  1  5 12 11  2  4  8  9 12  4  1  6  6  0  1  6  4] [ 3  9  8  1  4 12  3  2  5  8  9  3  6  6  1  1  8  8  6  9]\n",
      "[12  9  6  3  0  2  8 11 11 10  4  1  3  4  3 10  8  9  6  5] [12  4  6  8  6  8 10  1  8 12  6  3  8  4  8 11 11  4  6 10]\n",
      "[ 3  4  8  4  1  5  1  3 11  4  3  3  3  5  0 11  1 12 12  7] [ 3  6  1 11  8  5  1  3  6  9  6  8  1  5  4 11  8  5  5  5]\n",
      "accuracy: 0.2783203125\n",
      "278\n",
      "10  iter:  19232   phid:  5   mhid:  5   eps:  0.0802504714622168\n",
      "0 tensor(4.3651)\n",
      "[6 6 6 6 6 4 8 6 6 6 0 4 6 6 4 0 6 6 6 6] [ 1  3 10  6 10  4 12  1  6  5  8  4  6  3 10  8  4  6  1  1]\n",
      "[6 4 6 0 0 0 2 2 6 2 6 6 6 2 6 6 6 6 6 6] [ 5  9  6  6  8  4  1 11  4  2 10  7 10 12  1  6  3  6  8  8]\n",
      "accuracy: 0.1533203125\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "for iteration in range(20):\n",
    "\n",
    "    P_HIDDEN_DIM = max(int(np.random.normal(20, 25)), 5)\n",
    "    M_HIDDEN_DIM = max(int(np.random.normal(20, 25)), 5)\n",
    "    vocab_size = 13\n",
    "    tagset_size = 13\n",
    "    EPS = random.uniform(0.001, 0.12)\n",
    "    ITER = max(8000, min(int(np.random.normal(15000, 3000)), 50000))\n",
    "    P_EMBEDDING_DIM = vocab_size\n",
    "    M_EMBEDDING_DIM = vocab_size\n",
    "\n",
    "    print(iteration, \" iter: \", ITER, \"  phid: \", P_HIDDEN_DIM, \"  mhid: \", M_HIDDEN_DIM, \"  eps: \", EPS)\n",
    "    newweishts = weightloss(weights, 0.005)\n",
    "    model = LSTMTagger(P_EMBEDDING_DIM, M_EMBEDDING_DIM, P_HIDDEN_DIM, M_HIDDEN_DIM, vocab_size, tagset_size, batch_size = batch_size)\n",
    "    loss_function = nn.NLLLoss(weight = newweights[0])\n",
    "    loss_function2 = nn.NLLLoss(weight = newweights[1])\n",
    "    loss_function3 = nn.NLLLoss(weight = newweights[2])\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.2)\n",
    "    \n",
    "    for epoch in range(ITER):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "        for i in data_loader:\n",
    "            # Step 1. Remember that Pytorch accumulates gradients.\n",
    "            # We need to clear them out before each instance\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Also, we need to clear out the hidden state of the LSTM,\n",
    "            # detaching it from its history on the last instance.\n",
    "            model.p_hidden = model.init_hidden(P_HIDDEN_DIM)\n",
    "            model.m_hidden = model.init_hidden(M_HIDDEN_DIM)\n",
    "\n",
    "            # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "            # Tensors of word indices.\n",
    "            p, m, l, mask = i['p'], i['m'], i['l'], i['mask']\n",
    "            #print(m)\n",
    "            tag_scores = model(p, m, mask)\n",
    "            # Step 3. Run our forward pass.\n",
    "\n",
    "            # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "            #  calling optimizer.step()\n",
    "            #print(targets[:1])\n",
    "            loss = 0\n",
    "\n",
    "            loss += loss_function(tag_scores[0], torch.t(l)[0])  \n",
    "            loss += 0.3 * loss_function2(tag_scores[1], torch.t(l)[1])\n",
    "            loss += 0.3 * loss_function3(tag_scores[2], torch.t(l)[2])   \n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            break\n",
    "        if(epoch%5000 == 0): \n",
    "            print(epoch, loss)\n",
    "            accuracy = 0.0\n",
    "            c = 0\n",
    "            for j in range(2):\n",
    "                for i in data_loader:\n",
    "                    c+=1\n",
    "                    p, m, l, mask = i['p'], i['m'], i['l'], i['mask']\n",
    "                    tag_scores = model(p, m, mask)\n",
    "                    pred = tag_scores[0].max(1)[1].numpy()\n",
    "                    truth = torch.t(l)[0].numpy()\n",
    "                    print(pred[:20], truth[:20])\n",
    "                    accuracy += np.average(pred == truth)\n",
    "                    if (c>=1): break\n",
    "            print(\"accuracy:\", accuracy/c)\n",
    "\n",
    "    accuracy = 0.0\n",
    "    c = 0\n",
    "\n",
    "    for j in range(10):\n",
    "        for i in data_loader:\n",
    "            c+=1\n",
    "            p, m, l, mask = i['p'], i['m'], i['l'], i['mask']\n",
    "            tag_scores = model(p, m, mask)\n",
    "            pred = tag_scores[0].max(1)[1].numpy()\n",
    "            truth = torch.t(l)[0].numpy()\n",
    "            if(c<4): print(pred[:20], truth[:20])\n",
    "            accuracy += np.average(pred == truth)\n",
    "            if (c>=1): break\n",
    "    print(\"accuracy:\", accuracy/c)\n",
    "    print(str(int(accuracy/c * 1000)))\n",
    "    \n",
    "    torch.save(model, \"/mnt/d/230/2-Iterations-lstm\" + str(iteration)+\"_\"+str(int(accuracy/c * 1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "accuracy = 0.0\n",
    "c = 0\n",
    "for j in range(20):\n",
    "    for i in data_loader:\n",
    "        c+=1\n",
    "        p, m, l, mask = i['p'], i['m'], i['l'], i['mask']\n",
    "        tag_scores = model(p, m, mask)\n",
    "        pred = tag_scores[0].max(1)[1].numpy()\n",
    "        truth = torch.t(l)[0].numpy()\n",
    "        print(pred[:20], truth[:20])\n",
    "        accuracy += np.average(pred==truth)\n",
    "        if (c>=1): break\n",
    "print(\"accuracy:\", accuracy/c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0] [1 4 7]\n",
      "[1 4 7] [1 4 7]\n",
      "[1 4 7] [1 4 7]\n",
      "[6 4 7] [6 4 7]\n",
      "[6 4 7] [6 4 7]\n",
      "[11  5  9] [11  5  9]\n",
      "[5 5 9] [5 5 9]\n",
      "[5 3 9] [5 3 9]\n",
      "[10  3  9] [1 4 7]\n",
      "accuracy: 0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "#torch.save(model, \"/mnt/d/230/2-Iterations-lstm\")\n",
    "\n",
    "batch_size = 1\n",
    "train_data = MyDataset('testgeneration', prevchord = 6)\n",
    "weights = train_data.stats()\n",
    "data_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
    "c=0\n",
    "\n",
    "model = torch.load(\"/mnt/d/230/2-Iterations-lstm1_331\")\n",
    "torch.save(model.state_dict(), \"../state\")\n",
    "model = LSTMTagger(13, 13, 26, 13, 13, 13, batch_size = 1)\n",
    "model.load_state_dict(torch.load(\"../state\"))\n",
    "\n",
    "accuracy = 0.0\n",
    "c = 0\n",
    "for j in range(1):\n",
    "    for i in data_loader:\n",
    "        c+=1\n",
    "        p, m, l, mask = i['p'], i['m'], i['l'], i['mask']\n",
    "        tag_scores = model(p, m, mask)\n",
    "        pred = np.asarray([tag_scores[0].max(1)[1],tag_scores[1].max(1)[1],tag_scores[2].max(1)[1]])\n",
    "        truth = np.asarray([torch.t(l)[0], torch.t(l)[1], torch.t(l)[2]])\n",
    "        print(pred, truth)\n",
    "        accuracy += np.average(pred==truth)\n",
    "print(\"accuracy:\", accuracy/c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model:\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
